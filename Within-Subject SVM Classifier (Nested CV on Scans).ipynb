{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arr(df):\n",
    "    \n",
    "    vals = []\n",
    "    for _, row in df.iterrows():\n",
    "        vals.extend(row.tolist())\n",
    "    return np.array([x for x in vals if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(path):\n",
    "    \n",
    "    '''\n",
    "    Gets a list of subject IDs and the file suffix, given a path to the data files. \n",
    "    \n",
    "    Note: subject ID must be only 2 characters for this to work, and all data files\n",
    "    must have same suffix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to the data files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of subject IDs\n",
    "    str\n",
    "        the suffix to the filenames\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    subjects = [f[:2] for f in files]\n",
    "    suffix = files[0][2:]\n",
    "        \n",
    "    subjects.sort()\n",
    "    \n",
    "    return subjects, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_labels(y_data):\n",
    "    \n",
    "    '''\n",
    "    Randomly selects half of the labels in the data to switch to the other class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data: array-like\n",
    "        label data to scramble\n",
    "    '''\n",
    "    \n",
    "    classes = list(set(y_data))\n",
    "    classes.sort()\n",
    "    \n",
    "    y_data_copy = y_data.copy()\n",
    "    \n",
    "    labels_0 = [i for i, x in enumerate(y_data) if x == classes[0]]\n",
    "    labels_1 = [i for i, x in enumerate(y_data) if x == classes[1]]\n",
    "    to_change = random.sample(labels_0, k=len(labels_0)//2)\n",
    "    to_change.extend(random.sample(labels_1, k=len(labels_1)//2))\n",
    "    \n",
    "    for index in to_change:\n",
    "        if y_data[index] == classes[0]:\n",
    "            y_data[index] = classes[1]\n",
    "        else:\n",
    "            y_data[index] = classes[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_run(x_train, y_train, x_test, y_test, kernels, gamma_range, C_range):\n",
    "    \n",
    "    '''\n",
    "    Gets best hyperparameters (kernel, C, and gamma values) that optimize SVM's predictions for given\n",
    "    x and y test dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train: array-like\n",
    "        dataset of block data used to train classifier\n",
    "    y_train: array-like\n",
    "        dataset of label data used to train classifier\n",
    "    x_test: array-like\n",
    "        testing dataset of block data used to optimize hyperparameters on\n",
    "    y_test: array-like\n",
    "        testing dataset of label data used to optimize hyperparameters on\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        best combination of parameters found from grid search\n",
    "    float\n",
    "        best accuracy obtained from testing\n",
    "    '''\n",
    "    \n",
    "    gamma_vals = np.logspace(gamma_range['start'], gamma_range['stop'], gamma_range['num'], base=gamma_range['base'])\n",
    "    C_vals = np.logspace(C_range['start'], C_range['stop'], C_range['num'], base=C_range['base'])\n",
    "\n",
    "    param_grid = ParameterGrid({'kernel': kernels, 'gamma': gamma_vals, 'C': C_vals})\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Tests each parameter combination to find best one for given testing data\n",
    "    for params in list(param_grid):\n",
    "        \n",
    "        svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "        svclassifier.fit(x_train, y_train)\n",
    "        \n",
    "        curr_acc = svclassifier.score(x_test, y_test)\n",
    "        \n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_params = params\n",
    "            \n",
    "    return best_params, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Within Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tr_subject_data(path, subject, suffix, roi, conds):\n",
    "    \n",
    "    '''\n",
    "    Extracts individual subject data from the .mat files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Lists of voxel data (x_data) separated by individual TRs and the corresponding labels (y_data)\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    path_to_file = path + subject + suffix\n",
    "    mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "    scan_indices = []\n",
    "    \n",
    "    # Extract all TR data from all blocks from all scans\n",
    "    for scan in range(len(mat[0])):\n",
    "\n",
    "        for cond in conds:\n",
    "            \n",
    "            for block in range(len(mat[0][scan][0][cond][0])):\n",
    "                \n",
    "                block_x_data = []\n",
    "                \n",
    "                for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "\n",
    "                    tr_data = mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist()\n",
    "                    block_x_data.extend(tr_data)\n",
    "                    \n",
    "                x_data.append(block_x_data)\n",
    "                y_data.append(mat[0][scan][1][cond][0].replace('_post', ''))\n",
    "                \n",
    "        scan_indices.append(len(x_data))\n",
    "    \n",
    "    # MinMaxScaler scales each feature to values between 0 and 1 among all x data\n",
    "    print(len(x_data))\n",
    "    for i in x_data:\n",
    "        print(len(i))\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_data = scaler.fit_transform(x_data)        \n",
    "    \n",
    "    x_data_by_scan = {}\n",
    "    y_data_by_scan = {}\n",
    "    for scan_id, idx in enumerate(scan_indices):\n",
    "        if idx == scan_indices[0]:\n",
    "            x_data_by_scan[scan_id] = x_data[0:idx]\n",
    "            y_data_by_scan[scan_id] = y_data[0:idx]\n",
    "        else:\n",
    "            x_data_by_scan[scan_id] = x_data[scan_indices[scan_id-1]:idx]\n",
    "            y_data_by_scan[scan_id] = y_data[scan_indices[scan_id-1]:idx]\n",
    "    \n",
    "    return x_data_by_scan, y_data_by_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_within_subjects_combined(data_params, grid_params, runs=50, scramble=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using SVMs. Combines post-training and pre-training\n",
    "    data for training and inner testing of SVM for comparison purposes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path_pre: str\n",
    "            the path to the pre-training data files\n",
    "        path_post: str\n",
    "            the path to the post-training data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)   \n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    runs: int\n",
    "        number of runs to test on for each subject\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer pre-training subject testing accuracy\n",
    "    DataFrame\n",
    "        data of outer post-training subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix_post = get_subjects(data_params['path_post'])\n",
    "    _, suffix_pre = get_subjects(data_params['path_pre'])\n",
    "    \n",
    "    inner_result = {}\n",
    "    outer_pre_result = {}\n",
    "    outer_post_result = {}\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        inner_result[subject] = []\n",
    "        outer_pre_result[subject] = []\n",
    "        outer_post_result[subject] = []\n",
    "        \n",
    "        print(f\"Currently on subject {subject}.\")\n",
    "        \n",
    "        x_data_pre, y_data_pre = extract_tr_subject_data(data_params['path_pre'], subject, suffix_pre, roi, conds)\n",
    "        x_data_post, y_data_post = extract_tr_subject_data(data_params['path_post'], subject, suffix_post, roi, conds)\n",
    "        \n",
    "        x_data = x_data_pre.copy()\n",
    "        y_data = y_data_pre.copy()\n",
    "        for x_val, y_val in zip(x_data_post.values(), y_data_post.values()):\n",
    "            x_data[len(x_data)] = x_val\n",
    "            y_data[len(y_data)] = y_val\n",
    "        \n",
    "        scans = x_data.keys()\n",
    "        for outer_scan in scans:\n",
    "            \n",
    "            inner_scans = [s for s in scans if s != outer_scan]\n",
    "            \n",
    "            opt_inner_acc = -1\n",
    "            opt_inner_params = None\n",
    "            for inner_scan in inner_scans:\n",
    "                \n",
    "                x_train, y_train, x_test, y_test = [], [], [], []\n",
    "                for scan in scans:\n",
    "                    if scan == inner_scan:\n",
    "                        x_test.extend(x_data[scan])\n",
    "                        y_test.extend(y_data[scan])\n",
    "                    elif scan != outer_scan:\n",
    "                        x_train.extend(x_data[scan])\n",
    "                        y_train.extend(y_data[scan])\n",
    "            \n",
    "                opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test, y_test, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "                if inner_acc > opt_inner_acc:\n",
    "                    opt_inner_acc = inner_acc\n",
    "                    opt_inner_params = opt_params\n",
    "                    \n",
    "                inner_result[subject].append(inner_acc)\n",
    "                    \n",
    "            x_train, y_train, x_test, y_test = [], [], [], []\n",
    "            for scan in scans:\n",
    "                if scan == outer_scan:\n",
    "                    x_test.extend(x_data[scan])\n",
    "                    y_test.extend(y_data[scan])\n",
    "                else:\n",
    "                    x_train.extend(x_data[scan])\n",
    "                    y_train.extend(y_data[scan])\n",
    "                    \n",
    "            svclassifier = SVC(kernel=opt_inner_params['kernel'], gamma=opt_inner_params['gamma'], C=opt_inner_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            outer_acc = svclassifier.score(x_test, y_test)\n",
    "            outer_result[subject].append(outer_acc)\n",
    "            \n",
    "    end_time = time.time()\n",
    "    exec_time = end_time - start_time\n",
    "    minutes = exec_time // 60\n",
    "    print(f\"Last turn took {round(minutes, 3)} minutes.\")\n",
    "\n",
    "    return inner_result, outer_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_within_subjects(data_params, grid_params, scramble=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using SVMs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)   \n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    runs: int\n",
    "        number of runs to test on for each subject\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    inner_result = {}\n",
    "    outer_result = {}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    subjects = ['CG']\n",
    "    for subject in subjects:\n",
    "        \n",
    "        inner_result[subject] = []\n",
    "        outer_result[subject] = []\n",
    "        \n",
    "        print(f\"Currently on subject {subject}.\")\n",
    "        \n",
    "        x_data, y_data = extract_tr_subject_data(path, subject, suffix, roi, conds)\n",
    "        scans = x_data.keys()\n",
    "        for outer_scan in scans:\n",
    "            \n",
    "            inner_scans = [s for s in scans if s != outer_scan]\n",
    "            \n",
    "            opt_inner_acc = -1\n",
    "            opt_inner_params = None\n",
    "            for inner_scan in inner_scans:\n",
    "                \n",
    "                x_train, y_train, x_test, y_test = [], [], [], []\n",
    "                for scan in scans:\n",
    "                    if scan == inner_scan:\n",
    "                        x_test.extend(x_data[scan])\n",
    "                        y_test.extend(y_data[scan])\n",
    "                    elif scan != outer_scan:\n",
    "                        x_train.extend(x_data[scan])\n",
    "                        y_train.extend(y_data[scan])\n",
    "            \n",
    "                opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test, y_test, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "                if inner_acc > opt_inner_acc:\n",
    "                    opt_inner_acc = inner_acc\n",
    "                    opt_inner_params = opt_params\n",
    "                    \n",
    "                inner_result[subject].append(inner_acc)\n",
    "                    \n",
    "            x_train, y_train, x_test, y_test = [], [], [], []\n",
    "            for scan in scans:\n",
    "                if scan == outer_scan:\n",
    "                    x_test.extend(x_data[scan])\n",
    "                    y_test.extend(y_data[scan])\n",
    "                else:\n",
    "                    x_train.extend(x_data[scan])\n",
    "                    y_train.extend(y_data[scan])\n",
    "                    \n",
    "            svclassifier = SVC(kernel=opt_inner_params['kernel'], gamma=opt_inner_params['gamma'], C=opt_inner_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            outer_acc = svclassifier.score(x_test, y_test)\n",
    "            outer_result[subject].append(outer_acc)\n",
    "            \n",
    "    end_time = time.time()\n",
    "    exec_time = end_time - start_time\n",
    "    minutes = exec_time // 60\n",
    "    print(f\"Last turn took {round(minutes, 3)} minutes.\")\n",
    "\n",
    "    return inner_result, outer_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on subject CG.\n",
      "12\n",
      "624\n",
      "624\n",
      "702\n",
      "702\n",
      "624\n",
      "624\n",
      "624\n",
      "624\n",
      "624\n",
      "624\n",
      "702\n",
      "702\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ba9ad29187e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgamma_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mC_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kernels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0minner_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouter_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_within_subjects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-fd05f00ca0ac>\u001b[0m in \u001b[0;36mtrain_within_subjects\u001b[0;34m(data_params, grid_params, scramble)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Currently on subject {subject}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_tr_subject_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mscans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mouter_scan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-11d202c2d7fe>\u001b[0m in \u001b[0;36mextract_tr_subject_data\u001b[0;34m(path, subject, suffix, roi, conds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mx_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mx_data_by_scan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'n_samples_seen_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         X = self._validate_data(X, reset=first_pass,\n\u001b[0m\u001b[1;32m    370\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                                 force_all_finite=\"allow-nan\")\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.0/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [0, 2]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train_within_subjects(data_params, grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CC': [0.0,\n",
       "  0.9,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'GD': [0.875, 0.0, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.25, 0.75, 0.0, 0.0],\n",
       " 'JM': [0.0, 0.75, 0.0, 0.0, 0.0, 0.75, 0.0, 0.0, 0.75, 0.0, 0.0, 0.0],\n",
       " 'JS': [0.0,\n",
       "  0.0,\n",
       "  0.1111111111111111,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.1111111111111111,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3333333333333333],\n",
       " 'NL': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " 'RK': [0.0,\n",
       "  0.875,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.375,\n",
       "  0.0,\n",
       "  0.375,\n",
       "  0.0,\n",
       "  0.625,\n",
       "  0.25,\n",
       "  0.125,\n",
       "  0.125],\n",
       " 'SC': [0.0,\n",
       "  0.6,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6,\n",
       "  0.4,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.2,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'YY': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_acc_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pre = r'scans/output/PRE/'\n",
    "path_post = r'scans/output/cp&ip/'\n",
    "roi = 0                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [0, 2]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path_pre': path_pre, 'path_post': path_post, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_acc_report, outer_acc_report_pre, outer_acc_report_post = train_within_subjects_combined(data_params, grid_params, runs=200)\n",
    "\n",
    "outer_acc_report_pre['Average'] = outer_acc_report_pre.mean(axis=1)\n",
    "outer_acc_report_pre.to_csv('output/post_cp/outer_accs_within_pre.csv')\n",
    "outer_acc_report_post['Average'] = outer_acc_report_post.mean(axis=1)\n",
    "outer_acc_report_post.to_csv('output/post_cp/outer_accs_within_post.csv')\n",
    "inner_acc_report['Average'] = inner_acc_report.mean(axis=1)\n",
    "inner_acc_report.to_csv('output/post_cp/inner_accs_within_combined.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_within_subjects(data_params, grid_params, inner_dist, outer_dist, runs=50, train_runs=100, history=True):\n",
    "    \n",
    "    '''\n",
    "    Performs a specified number of runs where data labels are scrambled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        contains specifications for data processing (see train method for documentation)\n",
    "    grid_params: dict\n",
    "        contains values for grid search (see train method for documentation)\n",
    "    inner_dist: list\n",
    "        holds accuracy values for individual inner subject tests\n",
    "    outer_dist: list\n",
    "        holds accuracy values for individual outer subject tests\n",
    "    runs: int\n",
    "        number of runs to perform, default is 50\n",
    "    train_runs: int\n",
    "        number of runs to train on each subject, default is 100\n",
    "    history: boolean\n",
    "        whether to track accuracy over runs and output permutation accuracy plot, \n",
    "        default is True\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    if history:\n",
    "        outer_sample_means = []\n",
    "        for i in range(len(outer_dist)//(len(subjects)*train_runs)):\n",
    "            outer_sample_means.append(np.mean(outer_dist[i*len(subjects)*train_runs:(i+1)*len(subjects)*train_runs]))\n",
    "        \n",
    "        x = [i for i in range(1, len(outer_sample_means)+1)]\n",
    "        if len(outer_sample_means) > 0:\n",
    "            y = [outer_sample_means[0]]\n",
    "            for i in range(2, len(outer_sample_means)+1):\n",
    "                y.append(np.mean(outer_sample_means[:i]))\n",
    "        else:\n",
    "            y = []\n",
    "        \n",
    "    for n in range(runs):\n",
    "        print(f'On run #{n+1} of {runs}.')\n",
    "        inner_accs, outer_accs = train_within_subjects(data_params, grid_params, runs=train_runs, scramble=True)\n",
    "        \n",
    "        inner_dist.extend(df_to_arr(inner_accs).tolist())\n",
    "        outer_dist.extend(df_to_arr(outer_accs).tolist())\n",
    "        \n",
    "        outer_sample_means.append(np.mean(df_to_arr(outer_accs)))\n",
    "        \n",
    "        if history:\n",
    "            y.append(np.mean(outer_sample_means))\n",
    "            x.append(len(y))\n",
    "\n",
    "            plt.plot(x, y)\n",
    "            plt.xlabel('Run')\n",
    "            plt.ylabel('Overall Mean Accuracy')\n",
    "            plt.title('Overall Outer Subject Accuracy')\n",
    "            plt.savefig(f\"output/cp/perm_hist.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_dist = []\n",
    "outer_dist = []\n",
    "permutation_within_subjects(data_params, grid_params, inner_dist, outer_dist, runs=10, train_runs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
