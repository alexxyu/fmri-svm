{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arr(df):\n",
    "    \n",
    "    vals = []\n",
    "    for column in df:\n",
    "        vals.extend(df[column].tolist())\n",
    "    return np.array([x for x in vals if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training Functions\n",
    "\n",
    "<a href=\"https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\">Guide to SVM Training</a>\n",
    "### To-do:\n",
    "<ul>\n",
    "    <li> Check ranking system and data standardization </li>\n",
    "    <li> Make data generation process more efficient/less redundant </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(path):\n",
    "    \n",
    "    '''\n",
    "    Gets a list of subject IDs and the file suffix, given a path to the data files. \n",
    "    \n",
    "    Note: subject ID must be only 2 characters for this to work, and all data files\n",
    "    must have same suffix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to the data files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of subject IDs\n",
    "    str\n",
    "        the suffix to the filenames\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    subjects = [f[:2] for f in files]\n",
    "    suffix = files[0][2:]\n",
    "        \n",
    "    subjects.sort()\n",
    "    \n",
    "    return subjects, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_labels(y_data, classes):\n",
    "    \n",
    "    '''\n",
    "    Randomly selects half of the labels in the data to switch to the other class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data: array-like\n",
    "        label data to scramble\n",
    "    classes: list\n",
    "        the two different classes of labels\n",
    "    '''\n",
    "    \n",
    "    y_data_copy = y_data.copy()\n",
    "    for index in np.nditer(np.random.choice(len(y_data), size=len(y_data)//2, replace=False)):\n",
    "        \n",
    "        if y_data[index] == classes[0]:\n",
    "            y_data[index] = classes[1]\n",
    "        else:\n",
    "            y_data[index] = classes[0]\n",
    "    \n",
    "    # Makes sure labels are scrambled properly\n",
    "    num_diff = sum(i != j for i, j in zip(y_data, y_data_copy))  \n",
    "    if num_diff != len(y_data)//2:\n",
    "        raise ValueError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Extracts individual subject data from the .mat files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)\n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject\n",
    "    shuffle: boolean\n",
    "        whether to randomize which block to use in rank-ordering\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of voxel data (x_data) separated by individual blocks and the corresponding labels (y_data)\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    path_to_file = path + subject + suffix\n",
    "    mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "    \n",
    "    ranked_indices = None\n",
    "    \n",
    "    for scan in range(len(mat[0])):\n",
    "            \n",
    "        for cond in conds:\n",
    "            \n",
    "            blocks = [x for x in range(len(mat[0][scan][0][cond][0]))]\n",
    "            if rank_first and shuffle:\n",
    "                random.shuffle(blocks)\n",
    "            for block in blocks:\n",
    "                block_data = []\n",
    "                for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "                    \n",
    "                    # Extract all voxel data from individual TRs\n",
    "                    block_data.extend(mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist())\n",
    "                    \n",
    "                if rank_first:\n",
    "                    if ranked_indices is None:\n",
    "                        ranked_indices = [i for i in (np.array(block_data)).argsort()[-block_length:]]\n",
    "                        ranked_indices = np.flip(ranked_indices)\n",
    "                    block_data = [block_data[i] if i < len(block_data) else 0 for i in ranked_indices]\n",
    "                else:\n",
    "                    # Filters for most active voxels in each block\n",
    "                    block_data.sort()\n",
    "                    block_data = block_data[-block_length:]\n",
    "                \n",
    "                x_data.append(block_data)\n",
    "                y_data.append(mat[0][scan][1][cond][0])\n",
    "    \n",
    "    data = {'x': x_data, 'y': y_data}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>614</th>\n",
       "      <th>615</th>\n",
       "      <th>616</th>\n",
       "      <th>617</th>\n",
       "      <th>618</th>\n",
       "      <th>619</th>\n",
       "      <th>620</th>\n",
       "      <th>621</th>\n",
       "      <th>622</th>\n",
       "      <th>623</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.052941</td>\n",
       "      <td>0.050193</td>\n",
       "      <td>0.050193</td>\n",
       "      <td>0.050193</td>\n",
       "      <td>0.040964</td>\n",
       "      <td>0.040619</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>0.037624</td>\n",
       "      <td>0.036750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.001088</td>\n",
       "      <td>-0.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003774</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.016153</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006061</td>\n",
       "      <td>-0.006276</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>-0.005181</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.004310</td>\n",
       "      <td>-0.003250</td>\n",
       "      <td>0.008734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.011407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005056</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.005160</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>-0.003222</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>-0.003250</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>-0.002110</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>-0.007254</td>\n",
       "      <td>0.015641</td>\n",
       "      <td>-0.005405</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>-0.005405</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.012101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003040</td>\n",
       "      <td>0.045802</td>\n",
       "      <td>0.022901</td>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>-0.004049</td>\n",
       "      <td>0.012517</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012397</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>-0.004016</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>-0.002105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.002183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.029630</td>\n",
       "      <td>-0.041420</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>-0.014815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>-0.026052</td>\n",
       "      <td>0.009655</td>\n",
       "      <td>-0.037328</td>\n",
       "      <td>0.014028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003899</td>\n",
       "      <td>-0.001030</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>-0.005005</td>\n",
       "      <td>-0.005045</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>-0.009585</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>-0.004396</td>\n",
       "      <td>-0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011407</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.041825</td>\n",
       "      <td>0.034221</td>\n",
       "      <td>-0.011407</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>0.048980</td>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.036290</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.016393</td>\n",
       "      <td>-0.001130</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>-0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.003745</td>\n",
       "      <td>-0.018072</td>\n",
       "      <td>-0.026217</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.026217</td>\n",
       "      <td>-0.034483</td>\n",
       "      <td>-0.010060</td>\n",
       "      <td>-0.002770</td>\n",
       "      <td>-0.005941</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001957</td>\n",
       "      <td>-0.016461</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.014228</td>\n",
       "      <td>-0.006303</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>-0.006303</td>\n",
       "      <td>-0.010965</td>\n",
       "      <td>0.009858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.014493</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>-0.007246</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.006289</td>\n",
       "      <td>0.011468</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.005513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.018182</td>\n",
       "      <td>-0.014749</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>-0.025455</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>-0.014028</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>-0.017544</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018573</td>\n",
       "      <td>-0.013584</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>-0.008547</td>\n",
       "      <td>-0.009646</td>\n",
       "      <td>-0.006410</td>\n",
       "      <td>-0.019694</td>\n",
       "      <td>-0.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.037594</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>-0.022403</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>0.026477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006897</td>\n",
       "      <td>-0.006329</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>-0.003052</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>0.014054</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>-0.002212</td>\n",
       "      <td>0.021135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.047273</td>\n",
       "      <td>-0.050147</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.032727</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>-0.006865</td>\n",
       "      <td>-0.018109</td>\n",
       "      <td>-0.002809</td>\n",
       "      <td>-0.042802</td>\n",
       "      <td>-0.010060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006938</td>\n",
       "      <td>-0.017727</td>\n",
       "      <td>-0.010262</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>0.007224</td>\n",
       "      <td>-0.016985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016985</td>\n",
       "      <td>-0.001110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.046699</td>\n",
       "      <td>0.046389</td>\n",
       "      <td>0.044371</td>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.041160</td>\n",
       "      <td>0.040953</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.037022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>0.008601</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.008551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.034115</td>\n",
       "      <td>0.041412</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.033573</td>\n",
       "      <td>0.033077</td>\n",
       "      <td>0.022055</td>\n",
       "      <td>0.047563</td>\n",
       "      <td>0.023421</td>\n",
       "      <td>0.028554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>-0.002440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.040805</td>\n",
       "      <td>0.057155</td>\n",
       "      <td>0.033630</td>\n",
       "      <td>0.029147</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.033318</td>\n",
       "      <td>0.051128</td>\n",
       "      <td>0.054514</td>\n",
       "      <td>0.029459</td>\n",
       "      <td>0.060234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.024588</td>\n",
       "      <td>0.008456</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>0.024497</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.006158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.038141</td>\n",
       "      <td>0.037460</td>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.026719</td>\n",
       "      <td>0.039478</td>\n",
       "      <td>0.029105</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.026317</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>0.011377</td>\n",
       "      <td>0.021682</td>\n",
       "      <td>-0.004750</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>0.020789</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>-0.003163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.024274</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>-0.003751</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>0.027619</td>\n",
       "      <td>0.023891</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.042453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.011265</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.015342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.010109</td>\n",
       "      <td>-0.013486</td>\n",
       "      <td>-0.010932</td>\n",
       "      <td>-0.013624</td>\n",
       "      <td>-0.002765</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>-0.011081</td>\n",
       "      <td>-0.004463</td>\n",
       "      <td>-0.006311</td>\n",
       "      <td>0.004278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007566</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>-0.033766</td>\n",
       "      <td>-0.007715</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>0.008369</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>-0.007343</td>\n",
       "      <td>-0.000729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015767</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.029744</td>\n",
       "      <td>0.017547</td>\n",
       "      <td>0.029668</td>\n",
       "      <td>0.021698</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.019265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>-0.004803</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>-0.001687</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>-0.004395</td>\n",
       "      <td>-0.008217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.001586</td>\n",
       "      <td>-0.008462</td>\n",
       "      <td>-0.016294</td>\n",
       "      <td>-0.009753</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-0.012835</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009745</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.017405</td>\n",
       "      <td>-0.000756</td>\n",
       "      <td>-0.004313</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>-0.005438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.029019</td>\n",
       "      <td>-0.045047</td>\n",
       "      <td>-0.014481</td>\n",
       "      <td>-0.007426</td>\n",
       "      <td>-0.022857</td>\n",
       "      <td>-0.024204</td>\n",
       "      <td>-0.033866</td>\n",
       "      <td>-0.022141</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>-0.023233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000981</td>\n",
       "      <td>-0.005344</td>\n",
       "      <td>-0.030710</td>\n",
       "      <td>-0.002563</td>\n",
       "      <td>-0.005086</td>\n",
       "      <td>-0.008428</td>\n",
       "      <td>-0.003922</td>\n",
       "      <td>-0.005514</td>\n",
       "      <td>-0.008110</td>\n",
       "      <td>-0.004795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.003718</td>\n",
       "      <td>-0.014473</td>\n",
       "      <td>-0.003947</td>\n",
       "      <td>-0.003548</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.000449</td>\n",
       "      <td>-0.009062</td>\n",
       "      <td>-0.002941</td>\n",
       "      <td>0.007318</td>\n",
       "      <td>-0.001149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>-0.002036</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.005019</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>-0.007816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>-0.002952</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>0.012482</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.014844</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>-0.001257</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.005179</td>\n",
       "      <td>-0.016537</td>\n",
       "      <td>-0.018399</td>\n",
       "      <td>-0.017365</td>\n",
       "      <td>-0.025350</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>-0.010431</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>-0.005298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>-0.002222</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.014324</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>-0.007490</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>-0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.036317</td>\n",
       "      <td>0.038287</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>0.023371</td>\n",
       "      <td>0.048169</td>\n",
       "      <td>0.028738</td>\n",
       "      <td>0.034882</td>\n",
       "      <td>0.050203</td>\n",
       "      <td>0.029575</td>\n",
       "      <td>0.060049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.045108</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.011782</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.018181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.021667</td>\n",
       "      <td>-0.033687</td>\n",
       "      <td>-0.005781</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>-0.007498</td>\n",
       "      <td>-0.023714</td>\n",
       "      <td>-0.032416</td>\n",
       "      <td>-0.024854</td>\n",
       "      <td>-0.018344</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013953</td>\n",
       "      <td>-0.001696</td>\n",
       "      <td>-0.029457</td>\n",
       "      <td>-0.010541</td>\n",
       "      <td>-0.011230</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>-0.006527</td>\n",
       "      <td>-0.018766</td>\n",
       "      <td>-0.016396</td>\n",
       "      <td>0.004612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.011354</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.031345</td>\n",
       "      <td>0.018872</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.018511</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>0.027653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>-0.002109</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>-0.005707</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.006778</td>\n",
       "      <td>0.010649</td>\n",
       "      <td>0.003973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.005163</td>\n",
       "      <td>-0.009833</td>\n",
       "      <td>-0.009237</td>\n",
       "      <td>-0.005286</td>\n",
       "      <td>0.021331</td>\n",
       "      <td>-0.010274</td>\n",
       "      <td>-0.012083</td>\n",
       "      <td>-0.016546</td>\n",
       "      <td>-0.001440</td>\n",
       "      <td>0.015647</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011931</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>-0.005419</td>\n",
       "      <td>-0.006101</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>-0.002158</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>-0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.051643</td>\n",
       "      <td>0.047091</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>-0.005429</td>\n",
       "      <td>-0.005435</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>-0.005479</td>\n",
       "      <td>-0.005825</td>\n",
       "      <td>-0.005831</td>\n",
       "      <td>-0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.022831</td>\n",
       "      <td>-0.013699</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>-0.016216</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.010811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>-0.018667</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008174</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>-0.004380</td>\n",
       "      <td>-0.008746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-0.023817</td>\n",
       "      <td>-0.035256</td>\n",
       "      <td>0.037520</td>\n",
       "      <td>-0.006566</td>\n",
       "      <td>-0.022703</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.005726</td>\n",
       "      <td>-0.040666</td>\n",
       "      <td>-0.005163</td>\n",
       "      <td>0.063640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>-0.004708</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.001450</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>-0.006504</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>-0.004933</td>\n",
       "      <td>-0.023038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-0.033904</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>-0.045990</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>0.004536</td>\n",
       "      <td>-0.011471</td>\n",
       "      <td>0.017905</td>\n",
       "      <td>0.028040</td>\n",
       "      <td>-0.065072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>-0.011592</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>-0.012432</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>-0.008211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.064639</td>\n",
       "      <td>0.047170</td>\n",
       "      <td>0.042980</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.041825</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.010504</td>\n",
       "      <td>0.010502</td>\n",
       "      <td>0.010477</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.010438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.007463</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.006928</td>\n",
       "      <td>0.022388</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.021008</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>0.024287</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.013670</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.005258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.010989</td>\n",
       "      <td>-0.029885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004587</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>-0.040293</td>\n",
       "      <td>-0.005714</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>-0.010225</td>\n",
       "      <td>-0.020690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.016913</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>-0.001161</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.005214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.033175</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.023061</td>\n",
       "      <td>0.023697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.023355</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.017199</td>\n",
       "      <td>0.033639</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.053061</td>\n",
       "      <td>0.035503</td>\n",
       "      <td>0.025253</td>\n",
       "      <td>0.035343</td>\n",
       "      <td>0.017199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>0.015169</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.013528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>-0.007229</td>\n",
       "      <td>0.026506</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.029070</td>\n",
       "      <td>0.040201</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>-0.003115</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>0.012579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>-0.020080</td>\n",
       "      <td>-0.014563</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>0.022005</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>-0.036145</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>-0.019417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.018824</td>\n",
       "      <td>-0.001047</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>-0.013174</td>\n",
       "      <td>-0.002092</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>0.002092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.054726</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>0.047146</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.026706</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011737</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.011567</td>\n",
       "      <td>0.026288</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>0.017838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-0.088889</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>-0.037209</td>\n",
       "      <td>-0.051163</td>\n",
       "      <td>-0.059259</td>\n",
       "      <td>-0.029070</td>\n",
       "      <td>-0.017370</td>\n",
       "      <td>-0.036145</td>\n",
       "      <td>-0.032407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017710</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>-0.021186</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.019277</td>\n",
       "      <td>0.014888</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>-0.008421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-0.026415</td>\n",
       "      <td>-0.009259</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>-0.021176</td>\n",
       "      <td>-0.021176</td>\n",
       "      <td>-0.011321</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>0.032922</td>\n",
       "      <td>-0.013889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021327</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.027719</td>\n",
       "      <td>0.021322</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.034115</td>\n",
       "      <td>0.017021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.049808</td>\n",
       "      <td>-0.011547</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>-0.011765</td>\n",
       "      <td>-0.030588</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.006085</td>\n",
       "      <td>-0.020785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.027219</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.014644</td>\n",
       "      <td>-0.001052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>0.031175</td>\n",
       "      <td>0.035971</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.067073</td>\n",
       "      <td>0.058228</td>\n",
       "      <td>0.052192</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.039521</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.054113</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.037513</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.070632</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.061152</td>\n",
       "      <td>0.059725</td>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.054808</td>\n",
       "      <td>0.054580</td>\n",
       "      <td>0.052634</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>0.050146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>0.046093</td>\n",
       "      <td>-0.002783</td>\n",
       "      <td>-0.007889</td>\n",
       "      <td>-0.014583</td>\n",
       "      <td>-0.053282</td>\n",
       "      <td>-0.002527</td>\n",
       "      <td>-0.015894</td>\n",
       "      <td>-0.045854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009143</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.008057</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.006882</td>\n",
       "      <td>0.007362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.043502</td>\n",
       "      <td>0.012212</td>\n",
       "      <td>-0.012238</td>\n",
       "      <td>-0.027194</td>\n",
       "      <td>-0.038215</td>\n",
       "      <td>0.055266</td>\n",
       "      <td>-0.025223</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>-0.038808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.032539</td>\n",
       "      <td>0.024407</td>\n",
       "      <td>0.033942</td>\n",
       "      <td>0.018115</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.013463</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.015550</td>\n",
       "      <td>0.018287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>-0.005993</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>-0.049724</td>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.004883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016862</td>\n",
       "      <td>-0.009949</td>\n",
       "      <td>0.015410</td>\n",
       "      <td>-0.017786</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>-0.016709</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.008191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.024574</td>\n",
       "      <td>-0.018422</td>\n",
       "      <td>0.021846</td>\n",
       "      <td>0.016788</td>\n",
       "      <td>-0.022650</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>-0.039560</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>-0.048938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008873</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>-0.001408</td>\n",
       "      <td>-0.009730</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.015558</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.003904</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>-0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.000785</td>\n",
       "      <td>-0.008580</td>\n",
       "      <td>-0.023574</td>\n",
       "      <td>-0.021061</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>0.027179</td>\n",
       "      <td>-0.005428</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.006734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011763</td>\n",
       "      <td>-0.020916</td>\n",
       "      <td>0.024245</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>0.014711</td>\n",
       "      <td>-0.011552</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.006156</td>\n",
       "      <td>-0.074583</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>0.052105</td>\n",
       "      <td>-0.034425</td>\n",
       "      <td>-0.047052</td>\n",
       "      <td>0.029644</td>\n",
       "      <td>0.041558</td>\n",
       "      <td>-0.005400</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012283</td>\n",
       "      <td>-0.010728</td>\n",
       "      <td>0.017312</td>\n",
       "      <td>-0.017354</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>-0.005792</td>\n",
       "      <td>-0.007599</td>\n",
       "      <td>-0.011460</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>0.004436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.004010</td>\n",
       "      <td>-0.010920</td>\n",
       "      <td>-0.020991</td>\n",
       "      <td>-0.034475</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.041860</td>\n",
       "      <td>-0.029237</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006650</td>\n",
       "      <td>0.017767</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>-0.003731</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>0.010177</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.015477</td>\n",
       "      <td>-0.085520</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.045454</td>\n",
       "      <td>-0.036491</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>-0.003602</td>\n",
       "      <td>-0.014891</td>\n",
       "      <td>-0.010218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005442</td>\n",
       "      <td>0.035744</td>\n",
       "      <td>-0.003915</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>-0.006599</td>\n",
       "      <td>-0.002439</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.004714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-0.020677</td>\n",
       "      <td>-0.035670</td>\n",
       "      <td>-0.004570</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>-0.029617</td>\n",
       "      <td>0.028573</td>\n",
       "      <td>-0.014480</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014791</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009922</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>0.016127</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>-0.005684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.022849</td>\n",
       "      <td>-0.013404</td>\n",
       "      <td>0.025592</td>\n",
       "      <td>0.039892</td>\n",
       "      <td>-0.051162</td>\n",
       "      <td>0.032708</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>-0.004492</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>-0.043143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003416</td>\n",
       "      <td>-0.023384</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.010371</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.007927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>-0.007760</td>\n",
       "      <td>-0.018455</td>\n",
       "      <td>-0.017921</td>\n",
       "      <td>0.084563</td>\n",
       "      <td>0.013530</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>0.020024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010852</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.007934</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>-0.001715</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.003219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-0.048414</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>-0.052648</td>\n",
       "      <td>-0.033930</td>\n",
       "      <td>0.059949</td>\n",
       "      <td>-0.030285</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>-0.036465</td>\n",
       "      <td>-0.002859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010340</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>-0.011938</td>\n",
       "      <td>0.012684</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.010799</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-0.031530</td>\n",
       "      <td>-0.045062</td>\n",
       "      <td>-0.071883</td>\n",
       "      <td>-0.010080</td>\n",
       "      <td>-0.073369</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>-0.024001</td>\n",
       "      <td>-0.023704</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>-0.010435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009917</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>-0.004631</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.005304</td>\n",
       "      <td>0.012411</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>-0.006423</td>\n",
       "      <td>-0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.017383</td>\n",
       "      <td>-0.013761</td>\n",
       "      <td>-0.032802</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>-0.017550</td>\n",
       "      <td>-0.036302</td>\n",
       "      <td>-0.061282</td>\n",
       "      <td>-0.074852</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>-0.050163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021605</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.010076</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>-0.003027</td>\n",
       "      <td>-0.010006</td>\n",
       "      <td>-0.009754</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>-0.001816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.029857</td>\n",
       "      <td>-0.020352</td>\n",
       "      <td>-0.058222</td>\n",
       "      <td>0.032241</td>\n",
       "      <td>-0.033755</td>\n",
       "      <td>-0.016764</td>\n",
       "      <td>-0.011958</td>\n",
       "      <td>-0.025882</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>-0.022423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018410</td>\n",
       "      <td>-0.014451</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>0.032862</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>-0.002684</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>-0.001732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.073359  0.052941  0.050193  0.050193  0.050193  0.040964  0.040619   \n",
       "1   -0.003774  0.002933  0.033962  0.033962  0.026415  0.011820  0.003846   \n",
       "2    0.044776  0.031700 -0.007463  0.037313  0.029851  0.004739  0.034221   \n",
       "3    0.022556  0.000000  0.030075  0.030075  0.022556  0.018868  0.011494   \n",
       "4    0.000000 -0.003040  0.045802  0.022901  0.038168  0.033019 -0.004049   \n",
       "5   -0.029630 -0.041420  0.014815 -0.014815  0.000000  0.006928 -0.026052   \n",
       "6    0.011407  0.030488  0.041825  0.034221 -0.011407  0.033019  0.048980   \n",
       "7   -0.003745 -0.018072 -0.026217  0.003745  0.026217 -0.034483 -0.010060   \n",
       "8   -0.014493 -0.023810 -0.007246  0.028986 -0.043478  0.013825  0.008097   \n",
       "9   -0.018182 -0.014749  0.010909  0.018182 -0.025455  0.015945 -0.014028   \n",
       "10  -0.037594  0.006098  0.022556  0.045113  0.015038  0.009302 -0.022403   \n",
       "11  -0.047273 -0.050147 -0.040000 -0.032727  0.010909 -0.006865 -0.018109   \n",
       "12   0.052387  0.046699  0.046389  0.044371  0.041589  0.041160  0.040953   \n",
       "13   0.034115  0.041412  0.005271  0.009515  0.033573  0.033077  0.022055   \n",
       "14   0.040805  0.057155  0.033630  0.029147  0.048800  0.033318  0.051128   \n",
       "15   0.038141  0.037460  0.018153  0.013947  0.026719  0.039478  0.029105   \n",
       "16   0.024274  0.005120 -0.003751  0.017273  0.017196  0.027619  0.023891   \n",
       "17  -0.010109 -0.013486 -0.010932 -0.013624 -0.002765 -0.005299 -0.011081   \n",
       "18   0.015767  0.030303  0.029744  0.017547  0.029668  0.021698  0.013452   \n",
       "19  -0.001586 -0.008462 -0.016294 -0.009753  0.002833  0.001386 -0.012835   \n",
       "20  -0.029019 -0.045047 -0.014481 -0.007426 -0.022857 -0.024204 -0.033866   \n",
       "21  -0.003718 -0.014473 -0.003947 -0.003548  0.000282 -0.000449 -0.009062   \n",
       "22   0.007905  0.005406 -0.002952  0.005394  0.030683  0.009887  0.001057   \n",
       "23  -0.005179 -0.016537 -0.018399 -0.017365 -0.025350  0.003933 -0.010431   \n",
       "24   0.036317  0.038287  0.024338  0.023371  0.048169  0.028738  0.034882   \n",
       "25  -0.021667 -0.033687 -0.005781 -0.000705 -0.007498 -0.023714 -0.032416   \n",
       "26   0.011354  0.009311  0.008251  0.003301  0.031345  0.018872  0.010025   \n",
       "27  -0.005163 -0.009833 -0.009237 -0.005286  0.021331 -0.010274 -0.012083   \n",
       "28   0.070423  0.070423  0.069767  0.052632  0.051643  0.047091  0.046512   \n",
       "29  -0.022831 -0.013699 -0.011364 -0.016216  0.013699  0.010811  0.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "138 -0.023817 -0.035256  0.037520 -0.006566 -0.022703  0.005601  0.005726   \n",
       "139 -0.033904  0.008291 -0.045990  0.007706 -0.000777  0.004536 -0.011471   \n",
       "140  0.064639  0.047170  0.042980  0.042056  0.042056  0.041825  0.041176   \n",
       "141  0.007463 -0.009302  0.019830  0.006928  0.006928  0.022388  0.008850   \n",
       "142  0.010989 -0.029885  0.000000 -0.004587  0.022936 -0.040293 -0.005714   \n",
       "143  0.045455  0.033175  0.022599  0.023474  0.037559  0.015152  0.020408   \n",
       "144  0.053061  0.017199  0.033639  0.019512  0.039024  0.053061  0.035503   \n",
       "145  0.032000  0.004854  0.034056 -0.007229  0.026506  0.008000  0.029070   \n",
       "146 -0.020080 -0.014563  0.018634  0.022005  0.002445 -0.036145  0.035088   \n",
       "147  0.057377  0.054726  0.050955  0.027295  0.047146  0.040984  0.026706   \n",
       "148 -0.088889 -0.009259 -0.031056 -0.037209 -0.051163 -0.059259 -0.029070   \n",
       "149 -0.026415 -0.009259  0.012500 -0.021176 -0.021176 -0.011321  0.048193   \n",
       "150 -0.049808 -0.011547  0.006289 -0.011765 -0.030588 -0.057471  0.005952   \n",
       "151  0.062500  0.042056  0.041009  0.031175  0.035971  0.062500  0.067073   \n",
       "152  0.070632  0.066053  0.061152  0.059725  0.059054  0.054808  0.054580   \n",
       "153 -0.014374 -0.026901  0.046093 -0.002783 -0.007889 -0.014583 -0.053282   \n",
       "154 -0.043502  0.012212 -0.012238 -0.027194 -0.038215  0.055266 -0.025223   \n",
       "155  0.018474  0.040032  0.015954  0.019995 -0.005993  0.006313  0.025485   \n",
       "156 -0.024574 -0.018422  0.021846  0.016788 -0.022650  0.018371  0.005300   \n",
       "157 -0.000785 -0.008580 -0.023574 -0.021061  0.005922  0.027179 -0.005428   \n",
       "158  0.006156 -0.074583  0.003649  0.052105 -0.034425 -0.047052  0.029644   \n",
       "159 -0.004010 -0.010920 -0.020991 -0.034475 -0.000818 -0.041860 -0.029237   \n",
       "160 -0.015477 -0.085520  0.000815 -0.045454 -0.036491  0.006276 -0.004732   \n",
       "161 -0.020677 -0.035670 -0.004570  0.019544 -0.029617  0.028573 -0.014480   \n",
       "162  0.022849 -0.013404  0.025592  0.039892 -0.051162  0.032708  0.011429   \n",
       "163  0.018589  0.002902 -0.007760 -0.018455 -0.017921  0.084563  0.013530   \n",
       "164 -0.048414  0.004974 -0.052648 -0.033930  0.059949 -0.030285  0.003009   \n",
       "165 -0.031530 -0.045062 -0.071883 -0.010080 -0.073369  0.018892 -0.024001   \n",
       "166 -0.017383 -0.013761 -0.032802  0.003895 -0.017550 -0.036302 -0.061282   \n",
       "167 -0.029857 -0.020352 -0.058222  0.032241 -0.033755 -0.016764 -0.011958   \n",
       "\n",
       "          7         8         9    ...       614       615       616  \\\n",
       "0    0.038806  0.037624  0.036750  ...  0.000000  0.000000  0.000000   \n",
       "1    0.016153  0.003953  0.026923  ...  0.006061 -0.006276  0.010169   \n",
       "2    0.010309  0.033268  0.011407  ...  0.005056 -0.004193  0.000000   \n",
       "3    0.023599  0.005894  0.022989  ...  0.010204 -0.002110  0.005714   \n",
       "4    0.012517  0.002012  0.016194  ...  0.000000 -0.012397  0.001125   \n",
       "5    0.009655 -0.037328  0.014028  ... -0.003899 -0.001030  0.006787   \n",
       "6    0.028011  0.036290  0.028571  ...  0.000979 -0.016393 -0.001130   \n",
       "7   -0.002770 -0.005941  0.006036  ... -0.001957 -0.016461  0.011287   \n",
       "8    0.008357  0.001972  0.008097  ... -0.001953 -0.006289  0.011468   \n",
       "9    0.012552 -0.017544  0.010020  ... -0.018573 -0.013584 -0.005714   \n",
       "10   0.005618 -0.016000  0.026477  ... -0.006897 -0.006329  0.022989   \n",
       "11  -0.002809 -0.042802 -0.010060  ... -0.006938 -0.017727 -0.010262   \n",
       "12   0.037203  0.037132  0.037022  ...  0.008670  0.008664  0.008656   \n",
       "13   0.047563  0.023421  0.028554  ...  0.002980  0.007046  0.000804   \n",
       "14   0.054514  0.029459  0.060234  ...  0.013070  0.002843  0.024588   \n",
       "15   0.029110  0.026317  0.043537  ... -0.001879  0.011377  0.021682   \n",
       "16   0.022432  0.009683  0.042453  ...  0.006068  0.004334  0.003681   \n",
       "17  -0.004463 -0.006311  0.004278  ... -0.007566  0.009381 -0.033766   \n",
       "18   0.010905 -0.001101  0.019265  ...  0.002442 -0.004803 -0.008311   \n",
       "19  -0.002817  0.011340  0.005824  ... -0.009745  0.007353  0.017405   \n",
       "20  -0.022141  0.005087 -0.023233  ... -0.000981 -0.005344 -0.030710   \n",
       "21  -0.002941  0.007318 -0.001149  ... -0.004776  0.001386 -0.008138   \n",
       "22   0.012482  0.012526  0.022085  ...  0.000173 -0.002169 -0.014844   \n",
       "23   0.000960  0.003307 -0.005298  ... -0.005764 -0.002222  0.004888   \n",
       "24   0.050203  0.029575  0.060049  ...  0.004319  0.009668  0.045108   \n",
       "25  -0.024854 -0.018344  0.003820  ... -0.013953 -0.001696 -0.029457   \n",
       "26   0.018511  0.012414  0.027653  ...  0.004959 -0.002109  0.009171   \n",
       "27  -0.016546 -0.001440  0.015647  ... -0.011931  0.001862 -0.005419   \n",
       "28   0.042254  0.041551  0.041551  ... -0.005236 -0.005371 -0.005376   \n",
       "29   0.013699  0.027027  0.016216  ...  0.009174 -0.004274 -0.018667   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "138 -0.040666 -0.005163  0.063640  ...  0.001856 -0.004708  0.002551   \n",
       "139  0.017905  0.028040 -0.065072  ...  0.006021 -0.005111 -0.011592   \n",
       "140  0.038961  0.037975  0.037736  ...  0.010526  0.010526  0.010504   \n",
       "141  0.023499  0.021008  0.004651  ...  0.018779  0.009390  0.024287   \n",
       "142  0.005051 -0.010225 -0.020690  ...  0.012835  0.005834  0.016913   \n",
       "143  0.031250  0.023061  0.023697  ...  0.012987  0.022432  0.010616   \n",
       "144  0.025253  0.035343  0.017199  ...  0.012835  0.015169  0.019937   \n",
       "145  0.040201  0.018405  0.000000  ...  0.016355  0.009346 -0.003115   \n",
       "146  0.017544  0.008163 -0.019417  ...  0.023529  0.018824 -0.001047   \n",
       "147  0.020202  0.022774  0.014925  ...  0.011737  0.018779  0.011567   \n",
       "148 -0.017370 -0.036145 -0.032407  ... -0.017710  0.010626 -0.021186   \n",
       "149  0.022556  0.032922 -0.013889  ...  0.021327  0.014218  0.027719   \n",
       "150  0.010000 -0.006085 -0.020785  ...  0.014019  0.014019  0.020191   \n",
       "151  0.058228  0.052192  0.009346  ...  0.017964  0.039521  0.030303   \n",
       "152  0.052634  0.052405  0.050146  ...  0.004601  0.004596  0.004591   \n",
       "153 -0.002527 -0.015894 -0.045854  ... -0.009143  0.001768  0.002462   \n",
       "154 -0.000369  0.027073 -0.038808  ...  0.003109  0.032539  0.024407   \n",
       "155 -0.049724 -0.017675 -0.004883  ... -0.016862 -0.009949  0.015410   \n",
       "156 -0.039560  0.004366 -0.048938  ... -0.008873  0.000563 -0.001408   \n",
       "157  0.005763  0.027026  0.006734  ... -0.011763 -0.020916  0.024245   \n",
       "158  0.041558 -0.005400  0.054299  ...  0.012283 -0.010728  0.017312   \n",
       "159 -0.014140  0.014339  0.009628  ... -0.006650  0.017767  0.011142   \n",
       "160 -0.003602 -0.014891 -0.010218  ... -0.005442  0.035744 -0.003915   \n",
       "161 -0.008983  0.014791  0.011224  ... -0.009922 -0.002833 -0.009132   \n",
       "162 -0.004492  0.022902 -0.043143  ... -0.003416 -0.023384 -0.000817   \n",
       "163  0.004375  0.009849  0.020024  ... -0.010852  0.002943  0.015214   \n",
       "164  0.004421 -0.036465 -0.002859  ... -0.010340  0.015749 -0.011938   \n",
       "165 -0.023704  0.003924 -0.010435  ... -0.009917 -0.003184 -0.002481   \n",
       "166 -0.074852  0.007270 -0.050163  ... -0.021605  0.010233  0.007359   \n",
       "167 -0.025882  0.018301 -0.022423  ... -0.018410 -0.014451 -0.006028   \n",
       "\n",
       "          617       618       619       620       621       622       623  \n",
       "0    0.000000 -0.001038 -0.001081 -0.001081 -0.001081 -0.001088 -0.001100  \n",
       "1   -0.005181  0.004158  0.000000  0.003202 -0.004310 -0.003250  0.008734  \n",
       "2   -0.005160  0.001032 -0.003222  0.005405  0.001074 -0.003250  0.001103  \n",
       "3   -0.007254  0.015641 -0.005405  0.011866 -0.005405  0.004376  0.012101  \n",
       "4   -0.004016  0.006122 -0.002105  0.000000  0.000000  0.003300  0.002183  \n",
       "5   -0.005005 -0.005045  0.001054 -0.009585  0.007376 -0.004396 -0.001091  \n",
       "6    0.012121  0.000000 -0.001056  0.004283  0.007392  0.007701 -0.001098  \n",
       "7   -0.010000 -0.014228 -0.006303  0.016043 -0.006303 -0.010965  0.009858  \n",
       "8   -0.001007  0.001021  0.001072  0.000000 -0.001072  0.005599  0.005513  \n",
       "9   -0.006036 -0.017189 -0.008547 -0.009646 -0.006410 -0.019694 -0.017621  \n",
       "10  -0.003052  0.008214 -0.001079  0.014054  0.001079 -0.002212  0.021135  \n",
       "11  -0.002045  0.007224 -0.016985  0.000000 -0.016985 -0.001110  0.000000  \n",
       "12   0.008655  0.008651  0.008601  0.008600  0.008585  0.008562  0.008551  \n",
       "13   0.004909 -0.000792  0.011385  0.003690  0.011994  0.011460 -0.002440  \n",
       "14   0.008456  0.009426  0.024497  0.004657  0.023855  0.006859  0.006158  \n",
       "15  -0.004750 -0.006067  0.020789  0.004613  0.011707  0.001799 -0.003163  \n",
       "16   0.012901  0.002300  0.011265  0.001546 -0.001652  0.006765  0.015342  \n",
       "17  -0.007715  0.006458 -0.001309  0.008369  0.002711 -0.007343 -0.000729  \n",
       "18   0.003695 -0.001687 -0.000323  0.006152  0.000410 -0.004395 -0.008217  \n",
       "19  -0.000756 -0.004313  0.001339  0.000460  0.005621  0.011688 -0.005438  \n",
       "20  -0.002563 -0.005086 -0.008428 -0.003922 -0.005514 -0.008110 -0.004795  \n",
       "21   0.002750 -0.002036  0.002117  0.008172  0.005019  0.011219 -0.007816  \n",
       "22  -0.002891 -0.000252  0.014111 -0.001257  0.001980  0.002672  0.004251  \n",
       "23  -0.000836  0.002885  0.014324  0.004847 -0.007490  0.006203 -0.001571  \n",
       "24   0.012745  0.011782  0.024203  0.003135  0.013708  0.028746  0.018181  \n",
       "25  -0.010541 -0.011230  0.005140 -0.006527 -0.018766 -0.016396  0.004612  \n",
       "26   0.006057  0.004759 -0.005707  0.000595  0.006778  0.010649  0.003973  \n",
       "27  -0.006101  0.001718 -0.002158  0.000307  0.002930  0.002184 -0.002008  \n",
       "28  -0.005429 -0.005435 -0.005479 -0.005479 -0.005825 -0.005831 -0.005848  \n",
       "29   0.003250  0.002725  0.000000 -0.008174  0.013699 -0.004380 -0.008746  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "138 -0.000036 -0.001450  0.005611 -0.006504 -0.008220 -0.004933 -0.023038  \n",
       "139  0.002447  0.009339 -0.012432  0.000764  0.001427  0.006355 -0.008211  \n",
       "140  0.010504  0.010502  0.010477  0.010438  0.010438  0.010438  0.010438  \n",
       "141  0.015839  0.012987 -0.009302  0.013670  0.005258  0.009464  0.005258  \n",
       "142  0.021142 -0.001161  0.002326 -0.001043  0.001043  0.007299  0.005214  \n",
       "143  0.023355  0.007109  0.011682  0.006276  0.008368  0.028451  0.006276  \n",
       "144  0.024134  0.012776  0.004796 -0.001041  0.005203  0.014583  0.013528  \n",
       "145  0.005192  0.011710  0.001200  0.006289  0.000000  0.006263  0.012579  \n",
       "146 -0.005236  0.033998 -0.013174 -0.002092  0.002092  0.019854  0.002092  \n",
       "147  0.026288  0.014085  0.000000  0.009444  0.005247  0.024134  0.017838  \n",
       "148  0.002119  0.019277  0.014888 -0.006316  0.006316  0.003168 -0.008421  \n",
       "149  0.021322  0.032413  0.009877  0.014894  0.010638  0.034115  0.017021  \n",
       "150  0.018066  0.027219  0.004914  0.001052  0.003155  0.014644 -0.001052  \n",
       "151  0.054113  0.018182  0.012315  0.021277  0.021277  0.037513  0.021277  \n",
       "152  0.004587  0.004572  0.004568  0.004566  0.004559  0.004555  0.004554  \n",
       "153  0.008057  0.003854  0.007901  0.003479 -0.005284 -0.006882  0.007362  \n",
       "154  0.033942  0.018115  0.008331  0.013463  0.021971  0.015550  0.018287  \n",
       "155 -0.017786  0.008920  0.008043 -0.016709  0.004280  0.007854  0.008191  \n",
       "156 -0.009730  0.004391  0.015558  0.009896  0.003904  0.010196 -0.000853  \n",
       "157  0.007614  0.008143  0.014711 -0.011552  0.000164  0.003847  0.003482  \n",
       "158 -0.017354  0.010971 -0.005792 -0.007599 -0.011460 -0.005375  0.004436  \n",
       "159 -0.003731 -0.003729  0.004724  0.010177  0.023160  0.006602  0.000529  \n",
       "160  0.005278 -0.006599 -0.002439  0.001264  0.002981  0.005011  0.004714  \n",
       "161  0.016127  0.001403  0.001087  0.015054 -0.002699  0.006247 -0.005684  \n",
       "162  0.035964  0.010371  0.010858 -0.000210  0.006225  0.000695  0.007927  \n",
       "163  0.002222  0.001147  0.007934  0.008278 -0.001715 -0.000027  0.003219  \n",
       "164  0.012684  0.006020 -0.000925  0.004718  0.010799  0.002837  0.002259  \n",
       "165 -0.004631  0.005290 -0.005304  0.012411 -0.000778 -0.006423 -0.000195  \n",
       "166  0.010076  0.010228 -0.003027 -0.010006 -0.009754  0.007181 -0.001816  \n",
       "167  0.032862  0.000059 -0.000299  0.000309 -0.002684  0.004283 -0.001732  \n",
       "\n",
       "[168 rows x 624 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "subjects, suffix = get_subjects(path)\n",
    "columns = [x for x in range(624)]\n",
    "blocks = pd.DataFrame(columns = columns)\n",
    "\n",
    "x_train, _, x_inner, _, x_outer, _ = generate_data(subjects, [subjects[0]], subjects[1], path, suffix, roi, conds, block_length, True, False)\n",
    "for b in x_inner:\n",
    "    blocks.loc[len(blocks)] = b\n",
    "for b in x_outer:\n",
    "    blocks.loc[len(blocks)] = b    \n",
    "for b in x_train:\n",
    "    blocks.loc[len(blocks)] = b\n",
    "blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generates training and testing data.\n",
    "'''\n",
    "def generate_data(subjects, inner_test_subjects, outer_test_subject, path, suffix, roi, conds, block_length, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Generates training and testing data, which is separated into training data, inside testing data,\n",
    "    and outside testind data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subjects: list\n",
    "        a list of subject IDs to extract data from\n",
    "    inner_test_subject: list\n",
    "        list of subject IDs of the inner test subjects\n",
    "    outer_test_subject: str\n",
    "        the ID of the outer test subject\n",
    "    path: str\n",
    "        the path to the data files\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject\n",
    "    shuffle: boolean\n",
    "        whether to randomize which block to use in rank-ordering\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        blocks of voxel data for training use\n",
    "    list\n",
    "        training labels\n",
    "    list\n",
    "        inner test subject blocks of voxel data for testing use\n",
    "    list \n",
    "        testing labels for inner test subject\n",
    "    list\n",
    "        outer test subject blocks of voxel data for testing use\n",
    "    list\n",
    "        testing labels for outer test subject\n",
    "    '''\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    x_test_inner = []\n",
    "    y_test_inner = []\n",
    "    \n",
    "    x_test_outer = []\n",
    "    y_test_outer = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        subject_data = extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle)\n",
    "        if subject == outer_test_subject:\n",
    "            x_test_outer.extend(subject_data['x'])\n",
    "            y_test_outer.extend(subject_data['y'])\n",
    "        elif subject in inner_test_subjects:\n",
    "            x_test_inner.extend(subject_data['x'])\n",
    "            y_test_inner.extend(subject_data['y'])\n",
    "        else:\n",
    "            x_train.extend(subject_data['x'])\n",
    "            y_train.extend(subject_data['y'])\n",
    "    \n",
    "    x_train_len = len(x_train)\n",
    "    x_test_outer_len = len(x_test_outer)\n",
    "    \n",
    "    data.extend(x_train)\n",
    "    data.extend(x_test_outer)\n",
    "    data.extend(x_test_inner)\n",
    "    \n",
    "    # MinMaxScaler scales each feature to values between 0 and 1 among all x data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_standardized = scaler.fit_transform(data)\n",
    "    x_train, x_test_outer, x_test_inner = x_standardized[:x_train_len], x_standardized[x_train_len:x_train_len+x_test_outer_len], x_standardized[x_train_len+x_test_outer_len:]\n",
    "\n",
    "    y_train = np.stack(y_train, axis=0)\n",
    "    \n",
    "    return x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_run(x_train, y_train, x_test, y_test, kernels, gamma_range, C_range):\n",
    "    \n",
    "    '''\n",
    "    Gets best hyperparameters (kernel, C, and gamma values) that optimize SVM's predictions for given\n",
    "    x and y test dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train: array-like\n",
    "        dataset of block data used to train classifier\n",
    "    y_train: array-like\n",
    "        dataset of label data used to train classifier\n",
    "    x_test: array-like\n",
    "        testing dataset of block data used to optimize hyperparameters on\n",
    "    y_test: array-like\n",
    "        testing dataset of label data used to optimize hyperparameters on\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        best combination of parameters found from grid search\n",
    "    float\n",
    "        best accuracy obtained from testing\n",
    "    '''\n",
    "    \n",
    "    gamma_vals = np.logspace(gamma_range['start'], gamma_range['stop'], gamma_range['num'], base=gamma_range['base'])\n",
    "    C_vals = np.logspace(C_range['start'], C_range['stop'], C_range['num'], base=C_range['base'])\n",
    "\n",
    "    param_grid = ParameterGrid({'kernel': kernels, 'gamma': gamma_vals, 'C': C_vals})\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Tests each parameter combination to find best one for given testing data\n",
    "    for params in list(param_grid):\n",
    "        \n",
    "        svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "        svclassifier.fit(x_train, y_train)\n",
    "        \n",
    "        curr_acc = svclassifier.score(x_test, y_test)\n",
    "        \n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_params = params\n",
    "            \n",
    "    return best_params, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_params, grid_params, num_inner=1, scramble=False, classes=None, rank_first=True, shuffle=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "        block_length: int\n",
    "            the number of voxels to standardize every block in the dataset to\n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    num_inner: int\n",
    "        number of inner subjects to test classifier on,\n",
    "        default is 1\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "    classes: list, optional if scramble is False but required if scramble is True\n",
    "        label classes for the data (should be length of 2)\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject,\n",
    "        default is True\n",
    "    shuffle: boolean\n",
    "        whether to randomize which block to use in rank-ordering, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    \n",
    "    cols = []\n",
    "    for combo in itertools.combinations(range(len(subjects)), num_inner):\n",
    "        col = ''\n",
    "        for subject in combo:\n",
    "            col += '/' + subjects[subject]\n",
    "        cols.append(col[1:])\n",
    "\n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for outer_subject in subjects:\n",
    "        \n",
    "        print(\"Currently on outer subject #%i.\" % (subjects.index(outer_subject)+1))\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        inner_subjects = [s for s in subjects if s != outer_subject]\n",
    "        for inner_subject_test in itertools.combinations((inner_subjects), num_inner):\n",
    "            \n",
    "            inner_subject_test = list(inner_subject_test)\n",
    "\n",
    "            col = ''\n",
    "            for subject in inner_subject_test:\n",
    "                col += '/' + subject\n",
    "            col = col[1:]\n",
    "            # print(\"Currently on combination of %s.\" % (col))    \n",
    "            \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = generate_data(subjects, inner_subject_test, outer_subject, data_params['path'], suffix, data_params['roi'], data_params['conds'], data_params['block_length'], rank_first, shuffle)\n",
    "            if scramble:\n",
    "                scramble_labels(y_train, classes)\n",
    "                \n",
    "            # gets optimal params for training dataset from grid search\n",
    "            opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test_inner, y_test_inner, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "\n",
    "            # train model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=opt_params['kernel'], gamma=opt_params['gamma'], C=opt_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            \n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # logs inner and outer subject accuracy data in dataframe\n",
    "            inner_acc_report.at[outer_subject, col] = inner_acc\n",
    "            outer_acc_report.at[outer_subject, col] = outer_acc\n",
    "\n",
    "        # clear_output()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print('Last turn took %i minutes and %f seconds.' % (minutes, seconds))\n",
    "    \n",
    "    clear_output()\n",
    "    return inner_acc_report, outer_acc_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier/Visualizing Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Rank-Order Robustness\n",
    "\n",
    "True accuracy of rank-order appears to lie around 0.533. <br>\n",
    "For reference, using first block in rank-order produced accuracy of 0.540."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle which block is used to rank other blocks within subject\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 16, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 16, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_samples = []\n",
    "outer_samples = []\n",
    "for runs in range(10):\n",
    "    print(f'On run {runs+1}.')\n",
    "    \n",
    "    inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=1, rank_first=True)\n",
    "    inner_samples.append(df_to_arr(inner_accs))\n",
    "    outer_samples.append(df_to_arr(outer_accs))\n",
    "    \n",
    "#inner_accs.to_csv('output/rank/inner_accs16_bshuff.csv')\n",
    "#outer_accs.to_csv('output/rank/outer_accs16_bshuff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folds Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=2, rank_first=True)\n",
    "\n",
    "inner_accs.to_csv('output/rank/inner_accs32_2inner.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs32_2inner.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Original GS64 Run\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 64, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 64, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs64.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs64.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded GS32 Run\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 5, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -5, 'stop': 15, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs32_more.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs32_more.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking validity of ranking system\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 16, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 16, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs16_testrank.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs16_testrank.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -11, 'stop': 3, 'num': 15, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 15, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': r'scans/output/PRE/', 'roi': 1, 'conds': [1, 3], 'block_length': 624}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, num_inner=1, rank_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': r'scans/output/PRE/', 'roi': 1, 'conds': [1, 3], 'block_length': 624}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_samples = []\n",
    "outer_samples = []\n",
    "for runs in range(10):\n",
    "    print(f'On run {runs+1}.')\n",
    "    \n",
    "    inner_accs, outer_accs = train(data_params, grid_params, num_inner=1, rank_first=True, shuffle=True)\n",
    "    inner_samples.append(df_to_arr(inner_accs))\n",
    "    outer_samples.append(df_to_arr(outer_accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.793102297008547"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(inner_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(data_params, grid_params, inner_dist, outer_dist, runs, classes=None):\n",
    "    \n",
    "    '''\n",
    "    Runs several runs of SVM training and testing using shuffled (randomized) labeled data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "        block_length: int\n",
    "            the number of voxels to standardize every block in the dataset to\n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    inner_dist: list\n",
    "        stores the inner accuracy test subject values\n",
    "    outer_dist: list\n",
    "        sotres the outer accuracy test subject values\n",
    "    runs: int\n",
    "        how many runs to perform\n",
    "    classes: list\n",
    "        the two different labels of data to use\n",
    "    '''\n",
    "    \n",
    "    for n in range(runs):\n",
    "        print(f'On run #{n+1}.')\n",
    "        inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=1, scramble=True, classes=classes, rank_first=True)\n",
    "        \n",
    "        vals = []\n",
    "        for column in inner_accs:\n",
    "            vals.extend(inner_accs[column].tolist())\n",
    "        vals = [x for x in vals if str(x) != 'nan']\n",
    "        inner_dist.extend(vals)\n",
    "        \n",
    "        vals = []\n",
    "        for column in outer_accs:\n",
    "            vals.extend(outer_accs[column].tolist())\n",
    "        vals = [x for x in vals if str(x) != 'nan']\n",
    "        outer_dist.extend(vals)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "inner_dist = []\n",
    "outer_dist = []\n",
    "\n",
    "permutation(path, roi, conds, block_length, kernels, gamma_range, C_range, inner_dist, outer_dist, 10, classes)\n",
    "\n",
    "np.save('output/permutations/outer_dist32.npy', outer_dist)\n",
    "np.save('output/permutations/inner_dist32.npy', inner_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_with_all(path, roi, conds, block_length, kernels, gamma_range, C_range, scramble=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using entire dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        the path to the data files\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(path)\n",
    "    \n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=subjects)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=subjects)\n",
    "    \n",
    "    for outer_subject in range(len(subjects)):\n",
    "        \n",
    "        print(\"Currently on outer subject #%i.\" % (outer_subject+1))\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for inner_subject in range(len(subjects)):\n",
    "\n",
    "            if inner_subject == outer_subject:\n",
    "                continue\n",
    "\n",
    "            print(\"Currently on inner subject #%i.\" % (inner_subject+1))    \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = generate_data(subjects, inner_subject, outer_subject, path, suffix, roi, conds, block_length)\n",
    "            \n",
    "            x_whole = np.vstack((x_train, x_test_inner, x_test_outer))\n",
    "            y_whole = np.concatenate((y_train, y_test_inner, y_test_outer))\n",
    "            \n",
    "            if scramble:\n",
    "                scramble_labels(y_train, classes)\n",
    "                \n",
    "            # gets optimal params for training dataset from grid search\n",
    "            params, inner_acc = get_optimal_run(x_whole, y_whole, x_test_inner, y_test_inner, kernels, gamma_range, C_range) \n",
    "            print('Found best params for current inner subject.')\n",
    "            \n",
    "            # train model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_whole, y_whole)\n",
    "            \n",
    "            print('Testing outer subject...')\n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # logs inner and outer subject accuracy data in dataframe\n",
    "            index = subjects[outer_subject]\n",
    "            col = subjects[inner_subject]\n",
    "            \n",
    "            inner_acc_report.at[index, col] = inner_acc\n",
    "            outer_acc_report.at[index, col] = outer_acc\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print('Last turn took %i minutes and %f seconds.' % (minutes, seconds))\n",
    "    \n",
    "    clear_output()\n",
    "    return inner_acc_report, outer_acc_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train_with_all(path, roi, conds, block_length, kernels, gamma_range, C_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
