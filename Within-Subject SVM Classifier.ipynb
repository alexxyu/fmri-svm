{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arr(df):\n",
    "    \n",
    "    vals = []\n",
    "    for _, row in df.iterrows():\n",
    "        vals.extend(row.tolist())\n",
    "    return np.array([x for x in vals if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(path):\n",
    "    \n",
    "    '''\n",
    "    Gets a list of subject IDs and the file suffix, given a path to the data files. \n",
    "    \n",
    "    Note: subject ID must be only 2 characters for this to work, and all data files\n",
    "    must have same suffix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to the data files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of subject IDs\n",
    "    str\n",
    "        the suffix to the filenames\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    subjects = [f[:2] for f in files]\n",
    "    suffix = files[0][2:]\n",
    "        \n",
    "    subjects.sort()\n",
    "    \n",
    "    return subjects, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_labels(y_data):\n",
    "    \n",
    "    '''\n",
    "    Randomly selects half of the labels in the data to switch to the other class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data: array-like\n",
    "        label data to scramble\n",
    "    '''\n",
    "    \n",
    "    classes = list(set(y_data))\n",
    "    classes.sort()\n",
    "    \n",
    "    y_data_copy = y_data.copy()\n",
    "    for index in np.nditer(np.random.choice(len(y_data), size=len(y_data)//2, replace=False)):\n",
    "        \n",
    "        if y_data[index] == classes[0]:\n",
    "            y_data[index] = classes[1]\n",
    "        else:\n",
    "            y_data[index] = classes[0]\n",
    "    \n",
    "    # Makes sure labels are scrambled properly\n",
    "    num_diff = sum(i != j for i, j in zip(y_data, y_data_copy))  \n",
    "    if num_diff != len(y_data)//2:\n",
    "        raise ValueError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_run(x_train, y_train, x_test, y_test, kernels, gamma_range, C_range):\n",
    "    \n",
    "    '''\n",
    "    Gets best hyperparameters (kernel, C, and gamma values) that optimize SVM's predictions for given\n",
    "    x and y test dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train: array-like\n",
    "        dataset of block data used to train classifier\n",
    "    y_train: array-like\n",
    "        dataset of label data used to train classifier\n",
    "    x_test: array-like\n",
    "        testing dataset of block data used to optimize hyperparameters on\n",
    "    y_test: array-like\n",
    "        testing dataset of label data used to optimize hyperparameters on\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        best combination of parameters found from grid search\n",
    "    float\n",
    "        best accuracy obtained from testing\n",
    "    '''\n",
    "    \n",
    "    gamma_vals = np.logspace(gamma_range['start'], gamma_range['stop'], gamma_range['num'], base=gamma_range['base'])\n",
    "    C_vals = np.logspace(C_range['start'], C_range['stop'], C_range['num'], base=C_range['base'])\n",
    "\n",
    "    param_grid = ParameterGrid({'kernel': kernels, 'gamma': gamma_vals, 'C': C_vals})\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Tests each parameter combination to find best one for given testing data\n",
    "    for params in list(param_grid):\n",
    "        \n",
    "        svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "        svclassifier.fit(x_train, y_train)\n",
    "        \n",
    "        curr_acc = svclassifier.score(x_test, y_test)\n",
    "        \n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_params = params\n",
    "            \n",
    "    return best_params, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Within Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tr_subject_data(path, subject, suffix, roi, conds):\n",
    "    \n",
    "    '''\n",
    "    Extracts individual subject data from the .mat files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Lists of voxel data (x_data) separated by individual TRs and the corresponding labels (y_data)\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    path_to_file = path + subject + suffix\n",
    "    mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "    \n",
    "    test_TRs = []\n",
    "    \n",
    "    for scan in range(len(mat[0])):\n",
    "\n",
    "        for cond in conds:\n",
    "            \n",
    "            for block in range(len(mat[0][scan][0][cond][0])):\n",
    "                \n",
    "                for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "\n",
    "                    tr_data = mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist()\n",
    "                    \n",
    "                    if tr == 0 or tr == len(mat[0][scan][0][cond][0][block][0]) - 1:\n",
    "                        test_TRs.append(len(x_data))\n",
    "                        \n",
    "                    x_data.append(tr_data)\n",
    "                    y_data.append(mat[0][scan][1][cond][0].replace('_post', ''))\n",
    "                               \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_standardized = scaler.fit_transform(x_data)        \n",
    "    \n",
    "    test_x_data = []\n",
    "    test_y_data = []\n",
    "    for i in test_TRs:\n",
    "        test_x_data.append(x_standardized[i])\n",
    "        test_y_data.append(y_data[i])\n",
    "    \n",
    "    train_x_data = []\n",
    "    train_y_data = []\n",
    "    for i in range(len(x_standardized)):\n",
    "        if i not in test_TRs:\n",
    "            train_x_data.append(x_standardized[i])\n",
    "            train_y_data.append(y_data[i])\n",
    "    \n",
    "    data = {'train_x': train_x_data, 'train_y': train_y_data, 'test_x': test_x_data, 'test_y': test_y_data}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tr_dataset(data, scramble):\n",
    "    \n",
    "    '''\n",
    "    Splits the TR dataset into inner testing, outer testing, and training folds.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: dict\n",
    "        dictionary that contains data split into training and testing partition\n",
    "    scramble: boolean\n",
    "        whether or not to scramble the labels when training\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        TR voxel data for training use\n",
    "    list\n",
    "        TR voxel data for inner fold testing use\n",
    "    list\n",
    "        TR voxel data for outer fold testing use\n",
    "    list \n",
    "        labels for training use\n",
    "    list\n",
    "        labels for inner fold testing use\n",
    "    list\n",
    "        labels for outer fold testing use\n",
    "    '''\n",
    "    \n",
    "    train_x, inner_test_x, outer_test_x, train_y, inner_test_y, outer_test_y = [], [], [], [], [], []\n",
    "    \n",
    "    test_indices = [i for i in range(len(data['test_x']))]\n",
    "    test_indices, outer_test_indices, test_y, outer_test_y = train_test_split(test_indices, data['test_y'], test_size=2, stratify=data['test_y'])\n",
    "\n",
    "    for i in outer_test_indices:\n",
    "        if i%2 == 0:\n",
    "            index_to_remove = test_indices.index(i+1)\n",
    "            del test_y[index_to_remove]\n",
    "            del test_indices[index_to_remove]\n",
    "            train_x.append(data['test_x'][index_to_remove])\n",
    "            train_y.append(data['test_y'][index_to_remove])\n",
    "        else:\n",
    "            index_to_remove = test_indices.index(i-1)\n",
    "            del test_y[index_to_remove]\n",
    "            del test_indices[index_to_remove]\n",
    "            train_x.append(data['test_x'][index_to_remove])\n",
    "            train_y.append(data['test_y'][index_to_remove])\n",
    "\n",
    "    train_indices, inner_test_indices, _, inner_test_y = train_test_split(test_indices, test_y, test_size=6, stratify=test_y)\n",
    "    \n",
    "    outer_test_x = [data['test_x'][i] for i in outer_test_indices]\n",
    "    inner_test_x = [data['test_x'][i] for i in inner_test_indices]\n",
    "    \n",
    "    train_x.extend([data['test_x'][i] for i in train_indices])\n",
    "    train_x.extend(data['train_x'])\n",
    "    train_y.extend([data['test_y'][i] for i in train_indices])\n",
    "    train_y.extend(data['train_y'])\n",
    "\n",
    "    if scramble:\n",
    "        scramble_labels(train_y)\n",
    "    \n",
    "    return train_x, inner_test_x, outer_test_x, train_y, inner_test_y, outer_test_y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_within_subjects(data_params, grid_params, runs=50, scramble=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using SVMs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)   \n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    runs: int\n",
    "        number of runs to test on for each subject\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    \n",
    "    # Sets up DataFrames used to track inner and outer subject test accuracies\n",
    "    cols = [n for n in range(runs)]\n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        print(f\"Currently on subject {subject}.\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        subject_data = extract_tr_subject_data(path, subject, suffix, roi, conds)\n",
    "        x_train, x_test_inner, x_test_outer, y_train, y_test_inner, y_test_outer = split_tr_dataset(subject_data, scramble)\n",
    "        print(f\"Training data size: {len(x_train)}\")\n",
    "        print(f\"Inner testing data size: {len(x_test_inner)}\")\n",
    "        print(f\"Outer testing data size: {len(x_test_outer)}\")\n",
    "              \n",
    "        for run in range(runs):\n",
    "            \n",
    "            if (run+1) % 10 == 0:\n",
    "                print(f\"On run #{run+1} of {runs}.\")\n",
    "            x_train, x_test_inner, x_test_outer, y_train, y_test_inner, y_test_outer = split_tr_dataset(subject_data, scramble)\n",
    "            \n",
    "            # Gets optimal params for training dataset from grid search\n",
    "            opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test_inner, y_test_inner, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "\n",
    "            # Trains model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=opt_params['kernel'], gamma=opt_params['gamma'], C=opt_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            \n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # Logs inner and outer subject accuracy data in DataFrame\n",
    "            inner_acc_report.at[subject, run] = inner_acc\n",
    "            outer_acc_report.at[subject, run] = outer_acc\n",
    "            \n",
    "        clear_output()\n",
    "        \n",
    "        # Prints how long it took for last outer subject test\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print(f\"Last turn took {minutes} minutes and {seconds} seconds.\")\n",
    "        \n",
    "    return inner_acc_report, outer_acc_report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_within_subjects_combined(data_params, grid_params, runs=50, scramble=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using SVMs. Combines post-training and pre-training\n",
    "    data for training and inner testing of SVM for comparison purposes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path_pre: str\n",
    "            the path to the pre-training data files\n",
    "        path_post: str\n",
    "            the path to the post-training data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)   \n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    runs: int\n",
    "        number of runs to test on for each subject\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer pre-training subject testing accuracy\n",
    "    DataFrame\n",
    "        data of outer post-training subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix_post = get_subjects(data_params['path_post'])\n",
    "    _, suffix_pre = get_subjects(data_params['path_pre'])\n",
    "    \n",
    "    # Sets up DataFrames used to track inner and outer subject test accuracies\n",
    "    cols = [n for n in range(runs)]\n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report_post = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report_pre = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        print(f\"Currently on subject {subject}.\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        subject_data_pre = extract_tr_subject_data(data_params['path_pre'], subject, suffix_pre, roi, conds)\n",
    "        subject_data_post = extract_tr_subject_data(data_params['path_post'], subject, suffix_post, roi, conds)\n",
    "        \n",
    "        x_train_pre, x_test_inner_pre, x_test_outer_pre, y_train_pre, y_test_inner_pre, y_test_outer_pre = split_tr_dataset(subject_data_pre, scramble)\n",
    "        x_train_post, x_test_inner_post, x_test_outer_post, y_train_post, y_test_inner_post, y_test_outer_post = split_tr_dataset(subject_data_post, scramble)\n",
    "        \n",
    "        x_train = x_train_pre + x_train_post\n",
    "        x_test_inner = x_test_inner_pre + x_test_inner_post\n",
    "        x_test_outer = x_test_outer_pre + x_test_outer_post\n",
    "        y_train = y_train_pre + y_train_post\n",
    "        y_test_inner = y_test_inner_pre + y_test_inner_post\n",
    "        y_test_outer = y_test_outer_pre + y_test_outer_post\n",
    "        \n",
    "        print(f\"Training data size: {len(x_train)}\")\n",
    "        print(f\"Inner testing data size: {len(x_test_inner)}\")\n",
    "        print(f\"Outer testing data size: {len(x_test_outer)}\")\n",
    "              \n",
    "        for run in range(runs):\n",
    "            \n",
    "            if (run+1) % 10 == 0:\n",
    "                print(f\"On run #{run+1} of {runs}.\")\n",
    "                \n",
    "            x_train_pre, x_test_inner_pre, x_test_outer_pre, y_train_pre, y_test_inner_pre, y_test_outer_pre = split_tr_dataset(subject_data_pre, scramble)\n",
    "            x_train_post, x_test_inner_post, x_test_outer_post, y_train_post, y_test_inner_post, y_test_outer_post = split_tr_dataset(subject_data_post, scramble)\n",
    "\n",
    "            # Combine data for training and inner testing\n",
    "            x_train = x_train_pre + x_train_post\n",
    "            x_test_inner = x_test_inner_pre + x_test_inner_post\n",
    "            y_train = y_train_pre + y_train_post\n",
    "            y_test_inner = y_test_inner_pre + y_test_inner_post\n",
    "            \n",
    "            # Gets optimal params for training dataset from grid search\n",
    "            opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test_inner, y_test_inner, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "\n",
    "            # Trains model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=opt_params['kernel'], gamma=opt_params['gamma'], C=opt_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            \n",
    "            outer_acc_pre = svclassifier.score(x_test_outer_pre, y_test_outer_pre)\n",
    "            outer_acc_post = svclassifier.score(x_test_outer_post, y_test_outer_post)\n",
    "            \n",
    "            # Logs inner and outer subject accuracy data in DataFrame\n",
    "            inner_acc_report.at[subject, run] = inner_acc\n",
    "            outer_acc_report_pre.at[subject, run] = outer_acc_pre\n",
    "            outer_acc_report_post.at[subject, run] = outer_acc_post\n",
    "            \n",
    "        clear_output()\n",
    "        \n",
    "        # Prints how long it took for last outer subject test\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print(f\"Last turn took {minutes} minutes and {seconds} seconds.\")\n",
    "        \n",
    "    return inner_acc_report, outer_acc_report_pre, outer_acc_report_post\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [0, 2]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_acc_report, outer_acc_report = train_within_subjects(data_params, grid_params, runs=200)\n",
    "\n",
    "#outer_acc_report['Average'] = outer_acc_report.mean(axis=1)\n",
    "#outer_acc_report.to_csv('output/post_cp/outer_accs_within.csv')\n",
    "#inner_acc_report['Average'] = inner_acc_report.mean(axis=1)\n",
    "#inner_acc_report.to_csv('output/post_cp/inner_accs_within.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last turn took 66.0 minutes and 55.70770287513733 seconds.\n"
     ]
    }
   ],
   "source": [
    "path_pre = r'scans/output/PRE/'\n",
    "path_post = r'scans/output/cp&ip/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [0, 2]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path_pre': path_pre, 'path_post': path_post, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_acc_report, outer_acc_report_pre, outer_acc_report_post = train_within_subjects_combined(data_params, grid_params, runs=200)\n",
    "\n",
    "outer_acc_report_pre['Average'] = outer_acc_report_pre.mean(axis=1)\n",
    "outer_acc_report_pre.to_csv('output/post_cp/outer_accs_within_pre.csv')\n",
    "outer_acc_report_post['Average'] = outer_acc_report_post.mean(axis=1)\n",
    "outer_acc_report_post.to_csv('output/post_cp/outer_accs_within_post.csv')\n",
    "inner_acc_report['Average'] = inner_acc_report.mean(axis=1)\n",
    "inner_acc_report.to_csv('output/post_cp/inner_accs_within_combined.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_within_subjects(data_params, grid_params, inner_dist, outer_dist, runs=50, train_runs=100, history=True):\n",
    "    \n",
    "    '''\n",
    "    Performs a specified number of runs where data labels are scrambled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        contains specifications for data processing (see train method for documentation)\n",
    "    grid_params: dict\n",
    "        contains values for grid search (see train method for documentation)\n",
    "    inner_dist: list\n",
    "        holds accuracy values for individual inner subject tests\n",
    "    outer_dist: list\n",
    "        holds accuracy values for individual outer subject tests\n",
    "    runs: int\n",
    "        number of runs to perform, default is 50\n",
    "    train_runs: int\n",
    "        number of runs to train on each subject, default is 100\n",
    "    history: boolean\n",
    "        whether to track accuracy over runs and output permutation accuracy plot, \n",
    "        default is True\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    if history:\n",
    "        outer_sample_means = []\n",
    "        for i in range(len(outer_dist)//(len(subjects)*train_runs)):\n",
    "            outer_sample_means.append(np.mean(outer_dist[i*len(subjects)*train_runs:(i+1)*len(subjects)*train_runs]))\n",
    "        \n",
    "        x = [i for i in range(1, len(outer_sample_means)+1)]\n",
    "        if len(outer_sample_means) > 0:\n",
    "            y = [outer_sample_means[0]]\n",
    "            for i in range(2, len(outer_sample_means)+1):\n",
    "                y.append(np.mean(outer_sample_means[:i]))\n",
    "        else:\n",
    "            y = []\n",
    "        \n",
    "    for n in range(runs):\n",
    "        print(f'On run #{n+1} of {runs}.')\n",
    "        inner_accs, outer_accs = train_within_subjects(data_params, grid_params, runs=train_runs, scramble=True)\n",
    "        \n",
    "        inner_dist.extend(df_to_arr(inner_accs).tolist())\n",
    "        outer_dist.extend(df_to_arr(outer_accs).tolist())\n",
    "        \n",
    "        outer_sample_means.append(np.mean(df_to_arr(outer_accs)))\n",
    "        \n",
    "        if history:\n",
    "            y.append(np.mean(outer_sample_means))\n",
    "            x.append(len(y))\n",
    "\n",
    "            plt.plot(x, y)\n",
    "            plt.xlabel('Run')\n",
    "            plt.ylabel('Overall Mean Accuracy')\n",
    "            plt.title('Overall Outer Subject Accuracy')\n",
    "            plt.savefig(f\"output/cp/perm_hist.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_dist = []\n",
    "outer_dist = []\n",
    "permutation_within_subjects(data_params, grid_params, inner_dist, outer_dist, runs=10, train_runs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
