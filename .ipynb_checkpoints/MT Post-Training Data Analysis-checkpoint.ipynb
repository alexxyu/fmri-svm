{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arr(df):\n",
    "    \n",
    "    vals = []\n",
    "    for _, row in df.iterrows():\n",
    "        vals.extend(row.tolist())\n",
    "    return np.array([x for x in vals if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IP Significance Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=5.783750166175165, pvalue=0.0006746564191637951)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrambled_data = np.load('output/mt/post_ip/outer_dist.npy')\n",
    "avgs_scrambled = []\n",
    "\n",
    "num_subjects = 8\n",
    "run_size = num_subjects * (num_subjects-1)\n",
    "sub_num_per_run=num_subjects-1\n",
    "num_runs = len(scrambled_data) // run_size\n",
    "for i in range(num_subjects):\n",
    "    \n",
    "    subj_vals = []\n",
    "    for j in range(num_runs):\n",
    "        subj_vals.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avgs_scrambled.append(np.mean(subj_vals))\n",
    "\n",
    "unscrambled_data = df_to_arr(pd.read_csv('output/mt/post_ip/outer_accs_avg.csv', index_col=0))\n",
    "avgs_unscrambled = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_unscrambled.append(np.mean(unscrambled_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=5.937645068229241, pvalue=0.0005771811012027926)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgs_unscrambled = [0.5459,0.5740,0.5183,0.5610,0.5805,0.5568,0.5479,0.5783]\n",
    "avgs_scrambled = [0.5205,0.5238,0.5082,0.5145,0.4996,0.5037,0.5118,0.5222]\n",
    "\n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP Significance Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=2.3677509073005094, pvalue=0.049770580175924554)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrambled_data = np.load('output/mt/post_cp/outer_dist.npy')\n",
    "avgs_scrambled = []\n",
    "\n",
    "num_subjects = 8\n",
    "run_size = num_subjects * (num_subjects-1)\n",
    "sub_num_per_run=num_subjects-1\n",
    "num_runs = len(scrambled_data) // run_size\n",
    "for i in range(num_subjects):\n",
    "    \n",
    "    subj_vals = []\n",
    "    for j in range(num_runs):\n",
    "        subj_vals.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avgs_scrambled.append(np.mean(subj_vals))\n",
    "\n",
    "unscrambled_data = df_to_arr(pd.read_csv('output/mt/post_cp/outer_accs_avg.csv', index_col=0))\n",
    "avgs_unscrambled = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_unscrambled.append(np.mean(unscrambled_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.354533202256509, pvalue=0.0121750088869859)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgs_unscrambled = [0.5257,0.5035,0.5129,0.5134,0.4911,0.5144,0.5286,0.5000]\n",
    "avgs_scrambled = [0.5027,0.4941,0.4965,0.4985,0.4932,0.5019,0.4969,0.4999]\n",
    "\n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Significance Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Results (Whole Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=0.8755831015892016, pvalue=0.4067766185349132)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrambled_data = np.load('output/mt/small/outer_dist.npy')\n",
    "avgs_scrambled = []\n",
    "\n",
    "num_subjects = 9\n",
    "run_size = num_subjects * (num_subjects-1)\n",
    "sub_num_per_run=num_subjects-1\n",
    "num_runs = len(scrambled_data) // run_size\n",
    "for i in range(num_subjects):\n",
    "    \n",
    "    subj_vals = []\n",
    "    for j in range(num_runs):\n",
    "        subj_vals.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avgs_scrambled.append(np.mean(subj_vals))\n",
    "\n",
    "unscrambled_data = df_to_arr(pd.read_csv('output/mt/small/outer_accs_avg.csv', index_col=0))\n",
    "avgs_unscrambled = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_unscrambled.append(np.mean(unscrambled_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Results (Whole Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=1.7565249580048952, pvalue=0.11706455272883576)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgs_unscrambled = [0.5139,0.5127,0.5182,0.4898,0.4982,0.4961,0.5117,0.5042,0.5046]\n",
    "avgs_scrambled = [0.5015,0.4999,0.5037,0.4943,0.4964,0.5018,0.5041,0.5018,0.5056]\n",
    "\n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=10.782519903289767, pvalue=4.823434670337424e-06)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_runs = 30\n",
    "sub_num_per_run = 200\n",
    "num_subjects = 9\n",
    "\n",
    "scrambled_data = np.load('output/mt/small/outer_dist_within.npy')\n",
    "avg_data_unscrambled = pd.read_csv('output/mt/small/outer_accs_within.csv', index_col=0)['Average'].tolist()\n",
    "\n",
    "avg_data_scrambled = []\n",
    "for i in range(num_subjects):\n",
    "    subj_data = []\n",
    "    for j in range(num_runs):\n",
    "        subj_data.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avg_data_scrambled.append(np.mean(subj_data))\n",
    "    \n",
    "stats.ttest_rel(avg_data_unscrambled, avg_data_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Significance Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Results (Whole Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.978115131730314, pvalue=0.004072418856974415)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrambled_data = np.load('output/mt/large/outer_dist.npy')\n",
    "avgs_scrambled = []\n",
    "\n",
    "num_subjects = 9\n",
    "run_size = num_subjects * (num_subjects-1)\n",
    "sub_num_per_run=num_subjects-1\n",
    "num_runs = len(scrambled_data) // run_size\n",
    "for i in range(num_subjects):\n",
    "    \n",
    "    subj_vals = []\n",
    "    for j in range(num_runs):\n",
    "        subj_vals.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avgs_scrambled.append(np.mean(subj_vals))\n",
    "\n",
    "unscrambled_data = df_to_arr(pd.read_csv('output/mt/large/outer_accs_avg.csv', index_col=0))\n",
    "avgs_unscrambled = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_unscrambled.append(np.mean(unscrambled_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Results (Whole Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.8048397038119477, pvalue=0.005200693878333446)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgs_unscrambled = [0.5104,0.4984,0.5089,0.5435,0.5971,0.5812,0.5508,0.5501,0.5742]\n",
    "avgs_scrambled = [0.5101,0.4900,0.5047,0.5230,0.5384,0.5362,0.5283,0.5217,0.5254]\n",
    "\n",
    "stats.ttest_rel(avgs_unscrambled, avgs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=11.182995663807834, pvalue=3.6623270569514005e-06)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_runs = 30\n",
    "sub_num_per_run = 200\n",
    "num_subjects = 9\n",
    "\n",
    "scrambled_data = np.load('output/mt/large/outer_dist_within.npy')\n",
    "avg_data_unscrambled = pd.read_csv('output/mt/large/outer_accs_within.csv', index_col=0)['Average'].tolist()\n",
    "\n",
    "avg_data_scrambled = []\n",
    "for i in range(num_subjects):\n",
    "    subj_data = []\n",
    "    for j in range(num_runs):\n",
    "        subj_data.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avg_data_scrambled.append(np.mean(subj_data))\n",
    "    \n",
    "stats.ttest_rel(avg_data_unscrambled, avg_data_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Training Unpermuted vs. Permuted CP/IP (Within)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=8.291285936877607, pvalue=7.248954911277882e-05)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_runs = 30\n",
    "sub_num_per_run = 200\n",
    "num_subjects = 8\n",
    "\n",
    "scrambled_data = np.load('output/mt/post_ip/outer_dist_within.npy')\n",
    "avg_data_unscrambled = pd.read_csv('output/mt/post_ip/outer_accs_within.csv', index_col=0)['Average'].tolist()\n",
    "\n",
    "avg_data_scrambled = []\n",
    "for i in range(num_subjects):\n",
    "    subj_data = []\n",
    "    for j in range(num_runs):\n",
    "        subj_data.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avg_data_scrambled.append(np.mean(subj_data))\n",
    "    \n",
    "stats.ttest_rel(avg_data_unscrambled, avg_data_scrambled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=10.188705603879967, pvalue=1.8911032085980464e-05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_runs = 30\n",
    "sub_num_per_run = 200\n",
    "num_subjects = 8\n",
    "\n",
    "scrambled_data = np.load('output/mt/post_cp/outer_dist_within.npy')\n",
    "avg_data_unscrambled = pd.read_csv('output/mt/post_cp/outer_accs_within.csv', index_col=0)['Average'].tolist()\n",
    "\n",
    "avg_data_scrambled = []\n",
    "for i in range(num_subjects):\n",
    "    subj_data = []\n",
    "    for j in range(num_runs):\n",
    "        subj_data.extend(scrambled_data[sub_num_per_run*num_subjects*j+sub_num_per_run*i:sub_num_per_run*num_subjects*j+sub_num_per_run*(i+1)])\n",
    "    avg_data_scrambled.append(np.mean(subj_data))\n",
    "    \n",
    "stats.ttest_rel(avg_data_unscrambled, avg_data_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Training vs. Pre-Training CP/IP (Whole Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-3.9155834478374847, pvalue=0.0028869847738991787)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_subjects = 11\n",
    "sub_num_per_run=num_subjects-1\n",
    "post_data = df_to_arr(pd.read_csv('output/mt/cp_combined_split/outer_accs_post_avg.csv', index_col=0).drop(['CG', 'TP']).drop(['CG', 'TP'], axis=1)) \n",
    "avgs_post = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_post.append(np.mean(post_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "\n",
    "pre_data = df_to_arr(pd.read_csv('output/mt/cp_combined_split/outer_accs_pre_avg.csv', index_col=0).drop(['CG', 'TP']).drop(['CG', 'TP'], axis=1))\n",
    "avgs_pre = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_pre.append(np.mean(pre_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_post, avgs_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-1.9971335696937247, pvalue=0.07373936543536179)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_subjects = 11\n",
    "sub_num_per_run=num_subjects-1\n",
    "post_data = df_to_arr(pd.read_csv('output/v1/cp_combined_split/outer_accs_post_avg.csv', index_col=0).drop(['CG', 'TP']).drop(['CG', 'TP'], axis=1)) \n",
    "avgs_post = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_post.append(np.mean(post_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "\n",
    "pre_data = df_to_arr(pd.read_csv('output/v1/cp_combined_split/outer_accs_pre_avg.csv', index_col=0).drop(['CG', 'TP']).drop(['CG', 'TP'], axis=1))\n",
    "avgs_pre = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_pre.append(np.mean(pre_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_post, avgs_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-3.1414724667379588, pvalue=0.016345530710807247)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_subjects = 8\n",
    "sub_num_per_run=num_subjects-1\n",
    "post_data = df_to_arr(pd.read_csv('output/mt/ip_combined_split/outer_accs_post_avg.csv', index_col=0).drop(['AT', 'CG', 'JR', 'ML', 'TP']).drop(['AT', 'CG', 'JR', 'ML', 'TP'], axis=1)) \n",
    "avgs_post = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_post.append(np.mean(post_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "\n",
    "pre_data = df_to_arr(pd.read_csv('output/mt/ip_combined_split/outer_accs_pre_avg.csv', index_col=0).drop(['AT', 'CG', 'JR', 'ML', 'TP']).drop(['AT', 'CG', 'JR', 'ML', 'TP'], axis=1))\n",
    "avgs_pre = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_pre.append(np.mean(pre_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_post, avgs_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-3.5849061991281754, pvalue=0.008917551710804685)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_subjects = 8\n",
    "sub_num_per_run=num_subjects-1\n",
    "post_data = df_to_arr(pd.read_csv('output/v1/ip_combined_split/outer_accs_post_avg.csv', index_col=0).drop(['AT', 'CG', 'JR', 'ML', 'TP']).drop(['AT', 'CG', 'JR', 'ML', 'TP'], axis=1)) \n",
    "avgs_post = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_post.append(np.mean(post_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "\n",
    "pre_data = df_to_arr(pd.read_csv('output/v1/ip_combined_split/outer_accs_pre_avg.csv', index_col=0).drop(['AT', 'CG', 'JR', 'ML', 'TP']).drop(['AT', 'CG', 'JR', 'ML', 'TP'], axis=1))\n",
    "avgs_pre = []\n",
    "for i in range(num_subjects):\n",
    "    avgs_pre.append(np.mean(pre_data[i*sub_num_per_run:(i+1)*sub_num_per_run]))\n",
    "    \n",
    "stats.ttest_rel(avgs_post, avgs_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Training vs. Pre-Training CP/IP (Within)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-1.1968580969476674, pvalue=0.2703186955294861)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data = pd.read_csv('output/mt/pre_ip/outer_accs_within.csv', index_col=0)\n",
    "post_data = pd.read_csv('output/mt/post_ip/outer_accs_within.csv', index_col=0)\n",
    "common = post_data.index.intersection(pre_data.index)\n",
    "\n",
    "avg_data_post = post_data['Average'].tolist()\n",
    "avg_data_pre = pre_data.loc[common]['Average'].tolist()\n",
    "\n",
    "stats.ttest_rel(avg_data_post, avg_data_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.4713472158564054, pvalue=0.042748522816239705)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data = pd.read_csv('output/mt/pre_cp/outer_accs_within.csv', index_col=0)\n",
    "post_data = pd.read_csv('output/mt/post_cp/outer_accs_within.csv', index_col=0)\n",
    "common = post_data.index.intersection(pre_data.index)\n",
    "\n",
    "avg_data_post = post_data['Average'].tolist()\n",
    "avg_data_pre = pre_data.loc[common]['Average'].tolist()\n",
    "\n",
    "stats.ttest_rel(avg_data_post, avg_data_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-1.0653611089770083, pvalue=0.32207416102741493)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data = pd.read_csv('output/mt/post_ip/outer_accs_within_pre.csv', index_col=0)\n",
    "post_data = pd.read_csv('output/mt/post_ip/outer_accs_within_post.csv', index_col=0)\n",
    "\n",
    "avg_data_post = post_data['Average'].tolist()\n",
    "avg_data_pre = pre_data.loc[common]['Average'].tolist()\n",
    "\n",
    "stats.ttest_rel(avg_data_post, avg_data_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=0.2788760494354379, pvalue=0.7883989671364511)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data = pd.read_csv('output/mt/post_cp/outer_accs_within_pre.csv', index_col=0)\n",
    "post_data = pd.read_csv('output/mt/post_cp/outer_accs_within_post.csv', index_col=0)\n",
    "\n",
    "avg_data_post = post_data['Average'].tolist()\n",
    "avg_data_pre = pre_data.loc[common]['Average'].tolist()\n",
    "\n",
    "stats.ttest_rel(avg_data_post, avg_data_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
