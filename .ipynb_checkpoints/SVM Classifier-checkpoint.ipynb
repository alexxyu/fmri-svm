{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arr(df):\n",
    "    \n",
    "    vals = []\n",
    "    for column in df:\n",
    "        vals.extend(df[column].tolist())\n",
    "    return np.array([x for x in vals if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_int(labels, classes):\n",
    "    return np.array([0 if label == classes[1] else 1 for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training Methods\n",
    "\n",
    "<a href=\"https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\">Guide to SVM Training</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(path):\n",
    "    \n",
    "    '''\n",
    "    Gets a list of subject IDs and the file suffix, given a path to the data files. \n",
    "    \n",
    "    Note: subject ID must be only 2 characters for this to work, and all data files\n",
    "    must have same suffix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to the data files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of subject IDs\n",
    "    str\n",
    "        the suffix to the filenames\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    subjects = [f[:2] for f in files]\n",
    "    suffix = files[0][2:]\n",
    "        \n",
    "    subjects.sort()\n",
    "    \n",
    "    return subjects, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_labels(y_data, classes):\n",
    "    \n",
    "    '''\n",
    "    Randomly selects half of the labels in the data to switch to the other class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data: array-like\n",
    "        label data to scramble\n",
    "    classes: list\n",
    "        the two different classes of labels\n",
    "    '''\n",
    "    \n",
    "    y_data_copy = y_data.copy()\n",
    "    for index in np.nditer(np.random.choice(len(y_data), size=len(y_data)//2, replace=False)):\n",
    "        \n",
    "        if y_data[index] == classes[0]:\n",
    "            y_data[index] = classes[1]\n",
    "        else:\n",
    "            y_data[index] = classes[0]\n",
    "    \n",
    "    # Makes sure labels are scrambled properly\n",
    "    num_diff = sum(i != j for i, j in zip(y_data, y_data_copy))  \n",
    "    if num_diff != len(y_data)//2:\n",
    "        raise ValueError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Extracts individual subject data from the .mat files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)\n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject\n",
    "    shuffle: boolean\n",
    "        whether to shuffle order of voxels entirely\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of voxel data (x_data) separated by individual blocks and the corresponding labels (y_data)\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    path_to_file = path + subject + suffix\n",
    "    mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "    \n",
    "    ranked_indices = None\n",
    "    \n",
    "    for scan in range(len(mat[0])):\n",
    "            \n",
    "        for cond in conds:\n",
    "            \n",
    "            blocks = [x for x in range(len(mat[0][scan][0][cond][0]))]\n",
    "            if shuffle and rank_first:\n",
    "                random.shuffle(blocks)\n",
    "            for block in blocks:\n",
    "                block_data = []\n",
    "                for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "                    \n",
    "                    # Extract all voxel data from individual TRs\n",
    "                    block_data.extend(mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist())\n",
    "                    \n",
    "                if rank_first:\n",
    "                    # Rank-orders a given subject's block based on the order of its first encountered block\n",
    "                    if ranked_indices is None:\n",
    "                        ranked_indices = [i for i in (np.array(block_data)).argsort()[-block_length:]]\n",
    "                        ranked_indices = np.flip(ranked_indices)\n",
    "                    block_data = [block_data[i] if i < len(block_data) else 0 for i in ranked_indices]\n",
    "                else:\n",
    "                    # Filters for most active voxels in each block\n",
    "                    block_data.sort()\n",
    "                    block_data = block_data[-block_length:]\n",
    "                \n",
    "                x_data.append(block_data)\n",
    "                y_data.append(mat[0][scan][1][cond][0])\n",
    "    \n",
    "    data = {'x': x_data, 'y': y_data}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(subjects, path, suffix, roi, conds, block_length, scramble, classes, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Generates entire dataset from subject list, partitioned by subject.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subjects: list\n",
    "        a list of subject IDs to extract data from\n",
    "    path: str\n",
    "        the path to the data files\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject\n",
    "    shuffle: boolean\n",
    "        whether to shuffle order of voxels entirely\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        voxel data with subject key\n",
    "    dict\n",
    "        label data with subject key\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    \n",
    "    x_data_indices = []\n",
    "    y_data_by_subject = dict()\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        subject_data = extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle)\n",
    "        x_data_indices.append(len(x_data))\n",
    "        y_data_by_subject[subject] = subject_data['y']\n",
    "        \n",
    "        x_data.extend(subject_data['x'])\n",
    "    \n",
    "    # MinMaxScaler scales each feature to values between 0 and 1 among all x data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_standardized = scaler.fit_transform(x_data)\n",
    "    \n",
    "    # Sorts voxel data into respective subject\n",
    "    x_data_by_subject = dict()\n",
    "    for i in range(len(subjects)):\n",
    "        subject = subjects[i]\n",
    "        start_index = x_data_indices[i]\n",
    "        end_index = x_data_indices[i+1] if i+1 < len(x_data_indices) else len(x_data)\n",
    "        \n",
    "        x_data_by_subject[subject] = x_data[start_index:end_index]\n",
    "    \n",
    "    # Generates scrambled label data if specified\n",
    "    y_data_scrambled = None\n",
    "    if scramble:\n",
    "        y_data_scrambled = copy.deepcopy(y_data_by_subject)\n",
    "        for label_data in y_data_scrambled.values():\n",
    "            scramble_labels(label_data, classes)\n",
    "    \n",
    "    return x_data_by_subject, y_data_by_subject, y_data_scrambled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_run(x_train, y_train, x_test, y_test, kernels, gamma_range, C_range):\n",
    "    \n",
    "    '''\n",
    "    Gets best hyperparameters (kernel, C, and gamma values) that optimize SVM's predictions for given\n",
    "    x and y test dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train: array-like\n",
    "        dataset of block data used to train classifier\n",
    "    y_train: array-like\n",
    "        dataset of label data used to train classifier\n",
    "    x_test: array-like\n",
    "        testing dataset of block data used to optimize hyperparameters on\n",
    "    y_test: array-like\n",
    "        testing dataset of label data used to optimize hyperparameters on\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        best combination of parameters found from grid search\n",
    "    float\n",
    "        best accuracy obtained from testing\n",
    "    '''\n",
    "    \n",
    "    gamma_vals = np.logspace(gamma_range['start'], gamma_range['stop'], gamma_range['num'], base=gamma_range['base'])\n",
    "    C_vals = np.logspace(C_range['start'], C_range['stop'], C_range['num'], base=C_range['base'])\n",
    "\n",
    "    param_grid = ParameterGrid({'kernel': kernels, 'gamma': gamma_vals, 'C': C_vals})\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Tests each parameter combination to find best one for given testing data\n",
    "    for params in list(param_grid):\n",
    "        \n",
    "        svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "        svclassifier.fit(x_train, y_train)\n",
    "        \n",
    "        curr_acc = svclassifier.score(x_test, y_test)\n",
    "        \n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_params = params\n",
    "            \n",
    "    return best_params, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x_data, y_data, inner_subjects, outer_subject, y_data_scrambled=None):\n",
    "    \n",
    "    '''\n",
    "    Splits voxel and label data into appropriate testing and training data for nested\n",
    "    cross-validation with SVM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_data: dict\n",
    "        voxel data with subject key\n",
    "    y_data: dict\n",
    "        label data with subject key\n",
    "    inner_subjects: list\n",
    "        list of subject IDs of the inner test subjects\n",
    "    outer_subject: str\n",
    "        the ID of the outer test subject\n",
    "    y_data_scrambled: dict\n",
    "        scrambled label data with subject key, default is False (indicating no scrambling)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        blocks of voxel data for training use\n",
    "    list\n",
    "        training labels for respective blocks\n",
    "    list\n",
    "        blocks of voxel data from inner test subject(s) for testing use\n",
    "    list \n",
    "        labels for inner test subject(s)\n",
    "    list\n",
    "        blocks of voxel data from outer test subject for testing use\n",
    "    list\n",
    "        labels for outer test subject    \n",
    "    '''\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    x_test_inner = []\n",
    "    y_test_inner = []\n",
    "    \n",
    "    x_test_outer = []\n",
    "    y_test_outer = []\n",
    "    \n",
    "    for subject in x_data.keys():\n",
    "        if subject == outer_subject:\n",
    "            x_test_outer.extend(x_data[subject])\n",
    "            y_test_outer.extend(y_data[subject])\n",
    "        elif subject in inner_subjects:\n",
    "            x_test_inner.extend(x_data[subject])\n",
    "            y_test_inner.extend(y_data[subject])\n",
    "        else:\n",
    "            x_train.extend(x_data[subject])\n",
    "            if y_data_scrambled is None:\n",
    "                y_train.extend(y_data[subject])\n",
    "            else:\n",
    "                y_train.extend(y_data_scrambled[subject])\n",
    "            \n",
    "    return x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_params, grid_params, num_inner=1, scramble=False, classes=None, rank_first=True, shuffle=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "        block_length: int\n",
    "            the number of voxels to standardize every block in the dataset to\n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    num_inner: int\n",
    "        number of inner subjects to test classifier on,\n",
    "        default is 1\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "    classes: list, optional if scramble is False but required if scramble is True\n",
    "        label classes for the data (should be length of 2)\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject,\n",
    "        default is True\n",
    "    shuffle: boolean\n",
    "        whether to randomize which block to use in rank-ordering, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    if scramble and classes is None:\n",
    "        print('You must pass a list of label classes if scrambling the label data!')\n",
    "        raise ValueError\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    x_data, y_data, y_data_scrambled = generate_dataset(subjects, data_params['path'], suffix, data_params['roi'], data_params['conds'], data_params['block_length'], scramble, classes, rank_first, shuffle)\n",
    "    \n",
    "    # Sets up DataFrames used to track inner and outer subject test accuracies\n",
    "    cols = []\n",
    "    for combo in itertools.combinations(range(len(subjects)), num_inner):\n",
    "        col = ''\n",
    "        for subject in combo:\n",
    "            col += '/' + subjects[subject]\n",
    "        cols.append(col[1:])\n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for outer_subject in subjects:\n",
    "        \n",
    "        print(f\"Currently on outer subject #{subjects.index(outer_subject)+1}.\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        inner_subjects = [s for s in subjects if s != outer_subject]\n",
    "        for inner_test_subjects in itertools.combinations((inner_subjects), num_inner):\n",
    "            \n",
    "            inner_test_subjects = list(inner_test_subjects)\n",
    "            \n",
    "            col = ''\n",
    "            for subject in inner_test_subjects:\n",
    "                col += '/' + subject\n",
    "            col = col[1:]\n",
    "            print(f\"Currently on combination of {col}.\")    \n",
    "            \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = split_dataset(x_data, y_data, outer_subject, inner_test_subjects, y_data_scrambled)\n",
    "                \n",
    "            # Gets optimal params for training dataset from grid search\n",
    "            opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test_inner, y_test_inner, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "\n",
    "            # Trains model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=opt_params['kernel'], gamma=opt_params['gamma'], C=opt_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            \n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # Logs inner and outer subject accuracy data in DataFrame\n",
    "            inner_acc_report.at[outer_subject, col] = inner_acc\n",
    "            outer_acc_report.at[outer_subject, col] = outer_acc\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        # Prints how long it took for last outer subject test\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print(f\"Last turn took {minutes} minutes and {seconds} seconds.\")\n",
    "    \n",
    "    clear_output()\n",
    "    return inner_acc_report, outer_acc_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last turn took 2 minutes and 8.069294 seconds.\n",
      "Currently on outer subject #8.\n",
      "Currently on combination of AT.\n"
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -11, 'stop': 3, 'num': 15, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 15, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': r'scans/output/PRE/', 'roi': 1, 'conds': [1, 3], 'block_length': 624}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Rank-Order Robustness\n",
    "\n",
    "True accuracy of rank-order appears to lie around 0.533. <br>\n",
    "For reference, using first block in rank-order produced accuracy of 0.540."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle which block is used to rank other blocks within subject\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 16, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 16, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds, 'block_length': block_length}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_samples = []\n",
    "outer_samples = []\n",
    "for runs in range(10):\n",
    "    print(f'On run {runs+1}.')\n",
    "    \n",
    "    inner_accs, outer_accs = train(data_params, grid_params, rank_first=True, shuffle=True)\n",
    "    inner_samples.append(df_to_arr(inner_accs))\n",
    "    outer_samples.append(df_to_arr(outer_accs))\n",
    "    \n",
    "#inner_accs.to_csv('output/rank/inner_accs16_bshuff.csv')\n",
    "#outer_accs.to_csv('output/rank/outer_accs16_bshuff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests with Different Number of Inner Subjects Per Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds, 'block_length': block_length}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, num_inner=2, rank_first=True)\n",
    "\n",
    "inner_accs.to_csv('output/rank/inner_accs32_2inner.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs32_2inner.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Original GS64 Run\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 64, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 64, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds, 'block_length': block_length}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=False)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs64.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs64.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded GS32 Run\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 5, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -5, 'stop': 15, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds, 'block_length': block_length}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=False)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs32_more.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs32_more.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danny's grid search\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -11, 'stop': 3, 'num': 15, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 15, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds, 'block_length': block_length}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(data_params, grid_params, inner_dist, outer_dist, classes, runs=30):\n",
    "    \n",
    "    '''\n",
    "    Performs a specified number of runs where data labels are scrambled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        contains specifications for data processing (see train method for documentation)\n",
    "    grid_params: dict\n",
    "        contains values for grid search (see train method for documentation)\n",
    "    inner_dist: list\n",
    "        holds accuracy values for individual inner subject tests\n",
    "    outer_dist: list\n",
    "        holds accuracy values for individual outer subject tests\n",
    "    classes: list\n",
    "        label classes for the data (should be length of 2)\n",
    "    runs: int\n",
    "        number of runs to perform, default is 30\n",
    "    '''\n",
    "    \n",
    "    for n in range(runs):\n",
    "        print(f'On run #{n+1}.')\n",
    "        inner_accs, outer_accs = train(data_params, grid_params, scramble=True, classes=classes, rank_first=True)\n",
    "        \n",
    "        vals = []\n",
    "        for column in inner_accs:\n",
    "            vals.extend(inner_accs[column].tolist())\n",
    "        vals = [x for x in vals if str(x) != 'nan']\n",
    "        inner_dist.extend(vals)\n",
    "        \n",
    "        vals = []\n",
    "        for column in outer_accs:\n",
    "            vals.extend(outer_accs[column].tolist())\n",
    "        vals = [x for x in vals if str(x) != 'nan']\n",
    "        outer_dist.extend(vals)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds, 'block_length': block_length}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_dist = []\n",
    "outer_dist = []\n",
    "permutation(data_params, grid_params, inner_dist, outer_dist, classes, runs=20)\n",
    "\n",
    "np.save('output/permutations/outer_dist32.npy', outer_dist)\n",
    "np.save('output/permutations/inner_dist32.npy', inner_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -5, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds, 'block_length': block_length}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_dist = []\n",
    "outer_dist = []\n",
    "permutation(data_params, grid_params, inner_dist, outer_dist, classes, runs=20)\n",
    "\n",
    "np.save('output/permutations/outer_dist19.npy', outer_dist)\n",
    "np.save('output/permutations/inner_dist19.npy', inner_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7377470619658119"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(inner_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Neural Network\n",
    "\n",
    "DNN Guides:\n",
    "<br><a href=\"https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/\">Optimizers</a>\n",
    "<br><a href=\"https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-i-hyper-parameter-8129009f131b\">DNN Layers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNN(data_params, classes, epochs=20, layer_size=256, num_inner=1, scramble=False, rank_first=True, shuffle=False):\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    \n",
    "    cols = []\n",
    "    for combo in itertools.combinations(range(len(subjects)), num_inner):\n",
    "        col = ''\n",
    "        for subject in combo:\n",
    "            col += '/' + subjects[subject]\n",
    "        cols.append(col[1:])\n",
    "\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    val_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for outer_subject in subjects:\n",
    "        \n",
    "        print(f\"Currently on outer subject #{subjects.index(outer_subject)+1}.\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        inner_subjects = [s for s in subjects if s != outer_subject]\n",
    "        for inner_subject_test in itertools.combinations((inner_subjects), num_inner):\n",
    "            \n",
    "            inner_subject_test = list(inner_subject_test)\n",
    "\n",
    "            col = ''\n",
    "            for subject in inner_subject_test:\n",
    "                col += '/' + subject\n",
    "            col = col[1:]\n",
    "            print(f\"Currently on combination of {col}.\")    \n",
    "            \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = generate_data(subjects, inner_subject_test, outer_subject, data_params['path'], suffix, data_params['roi'], data_params['conds'], data_params['block_length'], rank_first, shuffle)\n",
    "            if scramble:\n",
    "                scramble_labels(y_train, classes)\n",
    "            \n",
    "            y_train = labels_to_int(y_train, classes)\n",
    "            y_test_inner = labels_to_int(y_test_inner, classes)\n",
    "            y_test_outer = labels_to_int(y_test_outer, classes)\n",
    "            \n",
    "            model = Sequential([\n",
    "                    layers.Dense(layer_size, input_shape=(data_params['block_length'],), activation=\"relu\"),\n",
    "                    layers.Dense(1, activation=\"sigmoid\")\n",
    "            ])\n",
    "\n",
    "            optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "            model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test_inner, y_test_inner), verbose=0)\n",
    "            outer_loss, outer_acc = model.evaluate(x_test_outer, y_test_outer, verbose=0)\n",
    "            val_loss, val_acc = model.evaluate(x_test_inner, y_test_inner, verbose=0)\n",
    "                \n",
    "            # logs inner and outer subject accuracy data in dataframe\n",
    "            outer_acc_report.at[outer_subject, col] = outer_acc\n",
    "            val_acc_report.at[outer_subject, col] = val_acc\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print(f\"Last turn took {minutes} minutes and {seconds} seconds.\")\n",
    "    \n",
    "    clear_output()\n",
    "    return outer_acc_report, val_acc_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer accuracy mean: 0.5588942170143127\n",
      "Validation accuracy mean: 0.5518162846565247\n"
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "data_params = {'path': r'scans/output/PRE/', 'roi': 1, 'conds': [1, 3], 'block_length': 624}\n",
    "classes = ['untrained_ip', 'trained_ip']\n",
    "\n",
    "'''\n",
    "outer_accs, val_accs = []\n",
    "for i in range(5):\n",
    "    print(f'On run {i+1}.')\n",
    "    outer_acc_report, val_accs = trainNN(data_params, classes, layer_size=256, scramble=False)\n",
    "    outer_accs.extend(df_to_arr(outer_acc_report))\n",
    "'''\n",
    "\n",
    "outer_accs, val_accs = trainNN(data_params, classes, layer_size=256, scramble=False)\n",
    "\n",
    "#np.mean(outer_acccs)\n",
    "print(f\"Outer accuracy mean: {np.mean(df_to_arr(outer_accs))}\")\n",
    "print(f\"Validation accuracy mean: {np.mean(df_to_arr(val_accs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last turn took 0 minutes and 26.890951 seconds.\n",
      "Currently on outer subject #9.\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 271us/sample - loss: 0.7288 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 224us/sample - loss: 0.7058 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 486us/sample - loss: 0.7230 - accuracy: 0.4375\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 314us/sample - loss: 0.7092 - accuracy: 0.4375\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 364us/sample - loss: 0.6799 - accuracy: 0.7500\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 222us/sample - loss: 0.8044 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 991us/sample - loss: 0.7276 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 243us/sample - loss: 0.6953 - accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "data_params = {'path': r'scans/output/PRE/', 'roi': 1, 'conds': [1, 3], 'block_length': 624}\n",
    "classes = ['untrained_ip', 'trained_ip']\n",
    "\n",
    "outer_accs_unscrambled = []\n",
    "for _ in range(20):\n",
    "    outer_acc_report, vals_accs = trainNN(data_params, classes, scramble=False)\n",
    "    outer_accs_unscrambled.extend(df_to_arr(outer_acc_report))\n",
    "    np.save('output/nn_outer.npy', outer_accs_unscrambled)\n",
    "    \n",
    "outer_accs_scrambled = []\n",
    "for _ in range(20):\n",
    "    outer_acc_report, val_accs = trainNN(data_params, classes, scramble=True)\n",
    "    outer_accs_scrambled.extend(df_to_arr(outer_acc_report))\n",
    "    np.save('output/nn_outer_s.npy', outer_accs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Testing One Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "subjects, suffix = get_subjects(path)\n",
    "\n",
    "x_data, y_data, y_data_scrambled = generate_dataset(subjects, path, suffix, roi, conds, block_length, True, classes, True, False)\n",
    "x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = split_dataset(x_data, y_data, [subjects[1]], subject[0], y_data_scrambled)\n",
    "\n",
    "y_train = labels_to_int(y_train, classes)\n",
    "y_test_inner = labels_to_int(y_test_inner, classes)\n",
    "y_test_outer = labels_to_int(y_test_outer, classes)\n",
    "\n",
    "model = Sequential([\n",
    "        layers.Dense(256, input_shape=(block_length,), activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, validation_data=(x_test_inner, y_test_inner), verbose=2)\n",
    "#outer_test_loss, outer_test_acc = model.evaluate(x_test_outer, y_test_outer)\n",
    "print(model.predict(x_test_outer))\n",
    "print(y_test_outer)\n",
    "\n",
    "#print(f\"Test loss: {outer_test_loss}\")\n",
    "#print(f\"Test accuracy: {outer_test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
