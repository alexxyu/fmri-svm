{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_arr(df):\n",
    "    \n",
    "    vals = []\n",
    "    for _, row in df.iterrows():\n",
    "        vals.extend(row.tolist())\n",
    "    return np.array([x for x in vals if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_int(labels, classes):\n",
    "    return np.array([0 if label == classes[1] else 1 for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training Methods\n",
    "\n",
    "<a href=\"https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\">Guide to SVM Training</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(path):\n",
    "    \n",
    "    '''\n",
    "    Gets a list of subject IDs and the file suffix, given a path to the data files. \n",
    "    \n",
    "    Note: subject ID must be only 2 characters for this to work, and all data files\n",
    "    must have same suffix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to the data files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of subject IDs\n",
    "    str\n",
    "        the suffix to the filenames\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    subjects = [f[:2] for f in files]\n",
    "    suffix = files[0][2:]\n",
    "        \n",
    "    subjects.sort()\n",
    "    \n",
    "    return subjects, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_labels(y_data, classes):\n",
    "    \n",
    "    '''\n",
    "    Randomly selects half of the labels in the data to switch to the other class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data: array-like\n",
    "        label data to scramble\n",
    "    classes: list\n",
    "        the two different classes of labels\n",
    "    '''\n",
    "    \n",
    "    y_data_copy = y_data.copy()\n",
    "    for index in np.nditer(np.random.choice(len(y_data), size=len(y_data)//2, replace=False)):\n",
    "        \n",
    "        if y_data[index] == classes[0]:\n",
    "            y_data[index] = classes[1]\n",
    "        else:\n",
    "            y_data[index] = classes[0]\n",
    "    \n",
    "    # Makes sure labels are scrambled properly\n",
    "    num_diff = sum(i != j for i, j in zip(y_data, y_data_copy))  \n",
    "    if num_diff != len(y_data)//2:\n",
    "        raise ValueError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max_block_length(path, subjects, suffix, roi, conds):\n",
    "    \n",
    "    '''\n",
    "    Gets the minimum and maximum lengths of the blocks in the data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        minimum block length\n",
    "    int\n",
    "        maxmimum block length\n",
    "    '''\n",
    "    \n",
    "    min_bl, max_bl = math.inf, 0\n",
    "    for subject in subjects:\n",
    "        \n",
    "        path_to_file = path + subject + suffix\n",
    "        mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "\n",
    "        for scan in range(len(mat[0])):\n",
    "            for cond in conds:\n",
    "                for block in range(len(mat[0][scan][0][cond][0])):\n",
    "        \n",
    "                    block_data = []\n",
    "                    for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "                        block_data.extend(mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist())\n",
    "                    \n",
    "                    min_bl = min(min_bl, len(block_data))\n",
    "                    max_bl = max(max_bl, len(block_data))\n",
    "                    \n",
    "    print(f\"Min block length: {min_bl}\")\n",
    "    print(f\"Max block length: {max_bl}\")\n",
    "\n",
    "    return min_bl, max_bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Extracts individual subject data from the .mat files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)\n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject\n",
    "    shuffle: boolean\n",
    "        whether to shuffle order of voxels entirely\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of voxel data (x_data) separated by individual blocks and the corresponding labels (y_data)\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    path_to_file = path + subject + suffix\n",
    "    mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "    \n",
    "    ranked_indices = None\n",
    "    \n",
    "    for scan in range(len(mat[0])):\n",
    "            \n",
    "        for cond in conds:\n",
    "            \n",
    "            blocks = [x for x in range(len(mat[0][scan][0][cond][0]))]\n",
    "            if shuffle and rank_first:\n",
    "                random.shuffle(blocks)\n",
    "            for block in blocks:\n",
    "                block_data = []\n",
    "                for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "                    # Extract all voxel data from individual TRs\n",
    "                    block_data.extend(mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist())\n",
    "                    \n",
    "                if rank_first:\n",
    "                    # Rank-orders a given subject's block based on the order of its first encountered block\n",
    "                    if ranked_indices is None:\n",
    "                        ranked_indices = [i for i in (np.array(block_data)).argsort()[-block_length:]]\n",
    "                        ranked_indices = np.flip(ranked_indices)\n",
    "                    block_data = [block_data[i] if i < len(block_data) else 0.0 for i in ranked_indices]\n",
    "                else:\n",
    "                    # Filters for most active voxels in each block\n",
    "                    block_data.sort()\n",
    "                    block_data = block_data[-block_length:]\n",
    "                \n",
    "                x_data.append(block_data)\n",
    "                y_data.append(mat[0][scan][1][cond][0])\n",
    "    \n",
    "    data = {'x': x_data, 'y': y_data}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(subjects, path, suffix, roi, conds, block_length, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Generates entire dataset from subject list, partitioned by subject.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subjects: list\n",
    "        a list of subject IDs to extract data from\n",
    "    path: str\n",
    "        the path to the data files\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject\n",
    "    shuffle: boolean\n",
    "        whether to shuffle order of voxels entirely\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        voxel data with subject key\n",
    "    dict\n",
    "        label data with subject key\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    \n",
    "    x_data_indices = []\n",
    "    y_data_by_subject = dict()\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        subject_data = extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle)\n",
    "        x_data_indices.append(len(x_data))\n",
    "        y_data_by_subject[subject] = subject_data['y']\n",
    "        \n",
    "        x_data.extend(subject_data['x'])\n",
    "    \n",
    "    # MinMaxScaler scales each feature to values between 0 and 1 among all x data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_standardized = scaler.fit_transform(x_data)\n",
    "    \n",
    "    # Sorts block data into respective subject\n",
    "    x_data_by_subject = dict()\n",
    "    for i in range(len(subjects)):\n",
    "        subject = subjects[i]\n",
    "        start_index = x_data_indices[i]\n",
    "        end_index = x_data_indices[i+1] if i+1 < len(x_data_indices) else len(x_data)\n",
    "        \n",
    "        x_data_by_subject[subject] = x_standardized[start_index:end_index]\n",
    "    \n",
    "    return x_data_by_subject, y_data_by_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_run(x_train, y_train, x_test, y_test, kernels, gamma_range, C_range):\n",
    "    \n",
    "    '''\n",
    "    Gets best hyperparameters (kernel, C, and gamma values) that optimize SVM's predictions for given\n",
    "    x and y test dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train: array-like\n",
    "        dataset of block data used to train classifier\n",
    "    y_train: array-like\n",
    "        dataset of label data used to train classifier\n",
    "    x_test: array-like\n",
    "        testing dataset of block data used to optimize hyperparameters on\n",
    "    y_test: array-like\n",
    "        testing dataset of label data used to optimize hyperparameters on\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        best combination of parameters found from grid search\n",
    "    float\n",
    "        best accuracy obtained from testing\n",
    "    '''\n",
    "    \n",
    "    gamma_vals = np.logspace(gamma_range['start'], gamma_range['stop'], gamma_range['num'], base=gamma_range['base'])\n",
    "    C_vals = np.logspace(C_range['start'], C_range['stop'], C_range['num'], base=C_range['base'])\n",
    "\n",
    "    param_grid = ParameterGrid({'kernel': kernels, 'gamma': gamma_vals, 'C': C_vals})\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Tests each parameter combination to find best one for given testing data\n",
    "    for params in list(param_grid):\n",
    "        \n",
    "        svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "        svclassifier.fit(x_train, y_train)\n",
    "        \n",
    "        curr_acc = svclassifier.score(x_test, y_test)\n",
    "        \n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_params = params\n",
    "            \n",
    "    return best_params, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x_data, y_data, inner_subjects, outer_subject, scramble, classes):\n",
    "    \n",
    "    '''\n",
    "    Splits voxel and label data into appropriate testing and training data for nested\n",
    "    cross-validation with SVM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_data: dict\n",
    "        voxel data with subject key\n",
    "    y_data: dict\n",
    "        label data with subject key\n",
    "    inner_subjects: list\n",
    "        list of subject IDs of the inner test subjects\n",
    "    outer_subject: str\n",
    "        the ID of the outer test subject\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "    classes: list, required if scramble is True\n",
    "        label classes for the data (should be length of 2)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        blocks of voxel data for training use\n",
    "    list\n",
    "        training labels for respective blocks\n",
    "    list\n",
    "        blocks of voxel data from inner test subject(s) for testing use\n",
    "    list \n",
    "        labels for inner test subject(s)\n",
    "    list\n",
    "        blocks of voxel data from outer test subject for testing use\n",
    "    list\n",
    "        labels for outer test subject    \n",
    "    '''\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    x_test_inner = []\n",
    "    y_test_inner = []\n",
    "    \n",
    "    x_test_outer = []\n",
    "    y_test_outer = []\n",
    "    \n",
    "    for subject in x_data.keys():\n",
    "        if subject == outer_subject:\n",
    "            x_test_outer.extend(x_data[subject])\n",
    "            y_test_outer.extend(y_data[subject])\n",
    "        elif subject in inner_subjects:\n",
    "            x_test_inner.extend(x_data[subject])\n",
    "            y_test_inner.extend(y_data[subject])\n",
    "        else:\n",
    "            x_train.extend(x_data[subject])\n",
    "            if scramble:\n",
    "                y_scrambled = y_data[subject].copy()\n",
    "                scramble_labels(y_scrambled, classes)\n",
    "                y_train.extend(y_scrambled)\n",
    "            else:\n",
    "                y_train.extend(y_data[subject])\n",
    "            \n",
    "    return x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_params, grid_params, num_inner=1, scramble=False, classes=None, rank_first=True, shuffle=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using SVMs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)   \n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    num_inner: int\n",
    "        number of inner subjects to test classifier on,\n",
    "        default is 1\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "    classes: list, required if scramble is True\n",
    "        label classes for the data (should be length of 2)\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject,\n",
    "        default is True\n",
    "    shuffle: boolean\n",
    "        whether to randomize which block to use in rank-ordering, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    if scramble and classes is None:\n",
    "        print('You must pass a list of label classes if scrambling the label data!')\n",
    "        raise ValueError\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    \n",
    "    bmin, bmax = get_min_max_block_length(data_params['path'], subjects, suffix, data_params['roi'], data_params['conds'])\n",
    "    block_length = bmin\n",
    "    x_data, y_data = generate_dataset(subjects, data_params['path'], suffix, data_params['roi'], data_params['conds'], block_length, rank_first, shuffle)\n",
    "    \n",
    "    # Sets up DataFrames used to track inner and outer subject test accuracies\n",
    "    cols = []\n",
    "    for combo in itertools.combinations(range(len(subjects)), num_inner):\n",
    "        col = ''\n",
    "        for subject in combo:\n",
    "            col += '/' + subjects[subject]\n",
    "        cols.append(col[1:])\n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for outer_subject in subjects:\n",
    "        \n",
    "        print(f\"Currently on outer subject #{subjects.index(outer_subject)+1}.\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        inner_subjects = [s for s in subjects if s != outer_subject]\n",
    "        for inner_test_subjects in itertools.combinations((inner_subjects), num_inner):\n",
    "            \n",
    "            inner_test_subjects = list(inner_test_subjects)\n",
    "            \n",
    "            col = ''\n",
    "            for subject in inner_test_subjects:\n",
    "                col += '/' + subject\n",
    "            col = col[1:]\n",
    "            print(f\"Currently on combination of {col}.\")    \n",
    "            \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = split_dataset(x_data, y_data, inner_test_subjects, outer_subject, scramble, classes)\n",
    "            \n",
    "            # Gets optimal params for training dataset from grid search\n",
    "            opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test_inner, y_test_inner, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "\n",
    "            # Trains model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=opt_params['kernel'], gamma=opt_params['gamma'], C=opt_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            \n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # Logs inner and outer subject accuracy data in DataFrame\n",
    "            inner_acc_report.at[outer_subject, col] = inner_acc\n",
    "            outer_acc_report.at[outer_subject, col] = outer_acc\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        # Prints how long it took for last outer subject test\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print(f\"Last turn took {minutes} minutes and {seconds} seconds.\")\n",
    "    \n",
    "    clear_output()\n",
    "    return inner_acc_report, outer_acc_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Rank-Order Robustness\n",
    "\n",
    "True accuracy of rank-order appears to lie around 0.533. <br>\n",
    "For reference, using first block in rank-order produced accuracy of 0.540."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle which block is used to rank other blocks within subject\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 16, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 16, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_samples = []\n",
    "outer_samples = []\n",
    "for runs in range(10):\n",
    "    print(f'On run {runs+1}.')\n",
    "    \n",
    "    inner_accs, outer_accs = train(data_params, grid_params, rank_first=True, shuffle=True)\n",
    "    inner_samples.append(df_to_arr(inner_accs))\n",
    "    outer_samples.append(df_to_arr(outer_accs))\n",
    "    \n",
    "inner_accs.to_csv('output/rank/inner_accs16_bshuff.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs16_bshuff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests with Different Number of Inner Subjects Per Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, num_inner=2, rank_first=True)\n",
    "\n",
    "inner_accs.to_csv('output/rank/inner_accs32_2inner.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs32_2inner.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Original GS64 Run\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 64, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 64, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=False)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs64.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs64.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded GS32 Run\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 5, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -5, 'stop': 15, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=False)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs32_more.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs32_more.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner accuracy: 0.7789797008547008\n",
      "Outer accuracy: 0.5387286324786326\n"
     ]
    }
   ],
   "source": [
    "# Danny's grid search\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -11, 'stop': 3, 'num': 15, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 15, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=True)\n",
    "print(f\"Inner accuracy: {np.mean(df_to_arr(inner_accs))}\")\n",
    "print(f\"Outer accuracy: {np.mean(df_to_arr(outer_accs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner accuracy: 0.7845886752136751\n",
      "Outer accuracy: 0.5556891025641025\n"
     ]
    }
   ],
   "source": [
    "# GS19 (Based on SVM Guide)\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 38, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 38, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=True)\n",
    "print(f\"Inner accuracy: {np.mean(df_to_arr(inner_accs))}\")\n",
    "print(f\"Outer accuracy: {np.mean(df_to_arr(outer_accs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inner accuracy: 0.7288995726495727\n",
      "Outer accuracy: 0.5430021367521368\n"
     ]
    }
   ],
   "source": [
    "# GS19 (Based on SVM Guide)\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [0, 2]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_accs, outer_accs = train(data_params, grid_params, rank_first=True)\n",
    "print(f\"Inner accuracy: {np.mean(df_to_arr(inner_accs))}\")\n",
    "print(f\"Outer accuracy: {np.mean(df_to_arr(outer_accs))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(data_params, grid_params, inner_dist, outer_dist, classes, runs=30, history=True):\n",
    "    \n",
    "    '''\n",
    "    Performs a specified number of runs where data labels are scrambled.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        contains specifications for data processing (see train method for documentation)\n",
    "    grid_params: dict\n",
    "        contains values for grid search (see train method for documentation)\n",
    "    inner_dist: list\n",
    "        holds accuracy values for individual inner subject tests\n",
    "    outer_dist: list\n",
    "        holds accuracy values for individual outer subject tests\n",
    "    classes: list\n",
    "        label classes for the data (should be length of 2)\n",
    "    runs: int\n",
    "        number of runs to perform, default is 30\n",
    "    history: boolean\n",
    "        whether to track accuracy over runs and output permutation accuracy plot, \n",
    "        default is True\n",
    "    '''\n",
    "    \n",
    "    if history:\n",
    "        outer_sample_means = []\n",
    "        for i in range(len(outer_dist)//156):\n",
    "            outer_sample_means.append(np.mean(outer_dist[i*156:(i+1)*156]))\n",
    "        \n",
    "        x = [i for i in range(1, len(outer_sample_means)+1)]\n",
    "        if len(outer_sample_means) > 0:\n",
    "            y = [outer_sample_means[0]]\n",
    "            for i in range(2, len(outer_sample_means)+1):\n",
    "                y.append(np.mean(outer_sample_means[:i]))\n",
    "        else:\n",
    "            y = []\n",
    "        \n",
    "    for n in range(runs):\n",
    "        print(f'On run #{n+1} of {runs}.')\n",
    "        inner_accs, outer_accs = train(data_params, grid_params, scramble=True, classes=classes, rank_first=True)\n",
    "        \n",
    "        inner_dist.extend(df_to_arr(inner_accs).tolist())\n",
    "        outer_dist.extend(df_to_arr(outer_accs).tolist())\n",
    "        \n",
    "        outer_sample_means.append(np.mean(df_to_arr(outer_accs)))\n",
    "        \n",
    "        if history:\n",
    "            y.append(np.mean(outer_sample_means))\n",
    "            x.append(len(y))\n",
    "\n",
    "            plt.plot(x, y)\n",
    "            plt.xlabel('Run')\n",
    "            plt.ylabel('Overall Mean Accuracy')\n",
    "            plt.title('Overall Outer Subject Accuracy')\n",
    "            plt.savefig(f\"output/permutations/perm_hist.png\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3hUZfbA8e9JI6SH3glNBAuICCio6LqIDQsWLAgqdnTV9efa1gK2ta1lFVcRRVkFC7qoIGIXVKR3BELvIT0kpJ7fH/fGHWPKBKYlOZ/nuQ8z99733jOTYc7c975FVBVjjDHGW2HBDsAYY0zdYonDGGNMrVjiMMYYUyuWOIwxxtSKJQ5jjDG1YonDGGNMrVjiMCFLRB4SkSnu4xQRURGJCHZcgSIi34rImCq2dRCRPBEJD3RcxljiML8jIqNFZIWI5IvIbhGZICJJwY7LG4cau4hsFpHTfBzTIBH5UUSyRSRDROaJyHGHelxV3aqqcapaeojxefWaRaSTiJSJyIRDOZ+pHyxxmN+IyF+BfwD/ByQCA4COwBwRifLxuXx65RDI2Ks4v4hIWIV1CcCnwItAE6At8DBQ6O94/OBKIBO4REQaBfLEDekqs85QVVtsAUgA8oCLK6yPA9KAq4E2QAHQxGP7McA+INJ9fjWwBudLZjbQ0WNfBW4G1gOb3HXPA9uAHGARcKLH/g8BU9zHKW75iIOJ3X3+JvCIx/bBwHb38dtAmfv68oC73PUDgB+BLGAZMNij/LfAo8A8t1zXCufvC2RV857/9voqe43u8R8HfnHfn/+Wv/eV7JsIvA7sAnYAjwDhHse+1v275AKrgT5VveZK4hQgFbgR2ANcWGH7EcAcIMPdfq+7Phy41y2b6/5921f2t3Rf6xj38Wj3Pf0nkO6+li7A1+7zfcB/gCSP8u2B6e7fOx34FxDlxnSUx34tgHygebD/z9Xlxa44TLkTgGic/3y/UdU8YCbwZ1XdCfwEDPfY5TLgA1UtFpFzcb4oLgCaAz8A71Y4z3lAf6Cn+3wB0BvnF/k7wPsiEu3r2Gs6gKqOBLYC56hTBfSkiLQFPsP54moC3Al8KCLNPYqOBK4D4oEtFQ67DigVkckicoaIJNfydYHzS/9qoDVQArxQxX5vutu74iTzIcAYABG5CCdJXYmTZIcB6ZW95iqOPQhoB0wF3gNGlW8QkXjgS+BznB8WXYGv3M13AJcCZ7rnvRrnS9sb/YGNQEuc5Cw4SbQN0AMnUTzkxhCOc2W3BScptQWmqmqRG/MVHse9FPhKVdO8jMNUwhKHKdcM2KeqJZVs2+VuB+fL/VJwqmeAEe46gBuAx1V1jXucx4DeItLR41iPq2qGqhYAqOoUVU1X1RJVfQZoBHT3U+y1dQUwU1VnqmqZqs4BFuJ8EZZ7U1VXufEXexZW1RycL10FXgPSRGSGiLSsRQxvq+pKVd0P/B24uOINcfd4ZwK3qep+Vd2L82t9hLvLGOBJVV2gjg2qWjHJVWcUMEtVM3H+1kNFpIW77Wxgt6o+o6oHVDVXVed7nPd+Vf3VPe8yVU338pw7VfVF930tcGOeo6qF7pf+s8DJ7r79cBLK/7mv/4CqznW3TQYudT+r4CT6t2vx2k0lLHGYcvuAZlXUJ7d2twN8CBwvIq2Bk3CqOn5wt3UEnheRLBHJwqkmEJxfgOW2eR5YRO4UkTXuzeMsnCqX2n7Rext7bXUELip/PW58g9xjlttWeVGHm0RHq2o74EicL7jnahGD5/G3AJH88f3p6K7f5RHnv3GqZcD5dZ5ai3P+RkQaAxfhVA2hqj/hXKVc5sWxD/q8/PFz0lJEporIDhHJAabwv/ehPbClsh8ObhLLBwaLyOE4V0QzDjIm47LEYcr9hHPT9gLPlSISB5yBW/3g/ur8ArgE58tjqqqWD7G8DbheVZM8lsaq+qPHIdXj2CcCdwEXA8mqmgRk4yQbn8cO7AdiPHZpVeE4FYeK3obzi9/z9cSq6hPVlKmSqq7FqVI60st4wPlSLNcBKOaPiXAbzutv5hFngqoe4bG9S1Vh1RD2+TjVTC+7LdV24/wQKK+u2gZ0rqJsVefd7/5bm7/FY+66o1Q1AedqsPxzsg3oUM1N9Mnu/iNxqlUPVLGf8ZIlDgOAqmbjtPh5UUSGikikiKTg1Glv5/eX9+/g1JdfyP+qqQBeAe4RkSMARCTRrV+vSjxOvXwaECEiD+B8Sfkr9qXAmSLSRERaAbdVONQefv8lOAU4R0ROF5FwEYkWkcEi0s6buETkcBH5a/n+ItIep5rvZ494TnL7ZCQC91RymCtEpKeIxADjcL74ftcEV1V34STzZ0QkQUTCRKSLiJRX5UwE7hSRY93WX109qg8rvuaKRgGTgKNw7kX1BgYCvUTkKJx7C61F5DYRaSQi8SLS3+O840Wkm3veo0WkqVvVtMN9beEicjVVJ7Zy8Tg38LPde0//57HtF5wqySdEJNb9Ow302D4FJwFeAbxVw3mMN4J9d96W0FqAa4CVOC1t9uBUeSRX2KcxTiuZVZWUHwmswGkFtA2Y5LFN8Wh5hNPqZpK77y6cq4/NwGnu9ofwolWVt7Hj3ECf5p5vOXA7bqsqd/u5ONUwWcCd7rr+wHc41W5pODfLO7jbvsVtCVRFPG1xktcOnF/ZO9yYEjz2eck93waclk/Vtar6BOeq4g/vB04V3wScRJkNLAFGeJznBuBXnC/flcAxVb3mCvGX4NEqyWPbTOBp9/GROFd1mcBu4G6Pv+/9wCb387IAaOduO8NdnwU8477Hnq2q5lY43xE4rbLycBLuXyv87ToAH/O/VlcvVCj/Jc5nS4L9f6w+LOK+qcaYOkREOuO02opU+09cIxGZhHPD/f5gx1IfWMcaY+qmI3FuCFvSqIFbbXkBTjNl4wN2j8OYOkZE7gBeBe4OdiyhTkTG41TNPaWqm4IdT31hVVXGGGNqxa44jDHG1EqDuMfRrFkzTUlJCXYYxhhTpyxatGifqjavuL5BJI6UlBQWLlwY7DCMMaZOEZFKh6axqipjjDG1YonDGGNMrVjiMMYYUyuWOIwxxtSKJQ5jjDG1YonDGGNMrVjiMMYYUyuWOKoxdsrT3DXxsWCHYYwxIaVBdAA8WPNbdSepJCfYYRhjTEixK45qJJXkkBURH+wwjDEmpFjiqEZiUT5ZYYnBDsMYY0KKJY5qJBbmkyuJLJj7ZbBDMcaYkGGJoxoJ+w8AMG/+90GOxBhjQocljmrEuYkj25oQGGPMbyxxVCP2QDEAebHRQY7EGGNChyWOanRu1hqAXEscxhjzG0sc1fjz2SOI0gPkNG4c7FCMMSZkWOKoRnLTpiRrFllRMcEOxRhjQoYljhokleaQHRkX7DCMMSZkWOKoQWJxHllhCcEOwxhjQoYljhokFRaQJcns3bkt2KEYY0xIsMRRg4SCAkolgv9+/HawQzHGmJBgiaMG8XlOJ8A9BwqCHIkxxoQGSxw1iM13Ekd+TFSQIzHGmNDg18QhIkNF5FcR2SAid1eyfbSIpInIUncZ47FtlIisd5dRHusvFZEVIrJcRD4XkWb+fA1NwxsB1gnQGGPK+S1xiEg48BJwBtATuFREelay6zRV7e0uE92yTYAHgf5AP+BBEUkWkQjgeeAUVT0aWA6M9ddrADjjrIsJ01JyYqwToDHGgH+vOPoBG1R1o6oWAVOBc70sezowR1UzVDUTmAMMBcRdYkVEgARgp+9D/5+ULt1J1CyyG1niMMYY8G/iaAt4tmHd7q6raLhb7fSBiLSvrqyqFgM3AitwEkZP4PXKTi4i14nIQhFZmJaWdkgvJKksh+zI2EM6hjHG1BfBvjn+CZDiVjvNASZXt7OIROIkjmOANjhVVfdUtq+qvqqqfVW1b/PmzQ8pyKSSXLIirBOgMcaAfxPHDqC9x/N27rrfqGq6qha6TycCx9ZQtrdbLlVVFXgPOMH3of9eYmE+mZLk79MYY0yd4M/EsQDoJiKdRCQKGAHM8NxBRFp7PB0GrHEfzwaGuDfEk4Eh7rodQE8RKb+E+LNHGb9JPFDAAYlhxrSJ/j6VMcaEPL/NbaeqJSIyFucLPxyYpKqrRGQcsFBVZwC3isgwoATIAEa7ZTNEZDxO8gEYp6oZACLyMPC9iBQDW8rL+FP5FLJrt29mmL9PZowxIc6vk6Kq6kxgZoV1D3g8voeq71FMAiZVsv4V4BXfRlq92P1ObVpedGQgT2uMMSEp2DfH64TEohIA8mIbBTkSY4wJPkscXujT+zgA6wRojDFY4vDKyaedS6zmkh1tw44YY4wlDi8ll2WRHWWdAI0xxhKHl5xOgPHBDsMYY4LOEoeXEov3kxWWGOwwjDEm6CxxeCnxQAE5ksTSX34IdijGGBNUlji8lOBO6PTtD18GORJjjAkuSxxeinMTR06EBjkSY4wJLkscXoor7z0eY01yjTENmyUOL3VIcsZVzI2zxGGMadgscXjpjPNHEqWF5ERb73FjTMNmicNLyU2bkmRTyBpjjCWO2kgqzSErIi7YYRhjTFBZ4qiFpOI8ssKtE6AxpmGzxFELiYX5ZEkSmenpwQ7FGGOCxhJHLSQUHKBEIvn4/deDHYoxxgSNJY5aiHenkN2ZnxPkSIwxJnhqTBwiMl1EzhKRBp9kYt3Ekd84KsiRGGNM8HiTDF4GLgPWi8gTItLdzzGFrGQJByA3zprkGmMarhoTh6p+qaqXA32AzcCXIvKjiFwlIpH+DjCUDD39AkRLyWlsvceNMQ2XV9VPItIUGA2MAZYAz+Mkkjl+iywEde1xNIlkk229x40xDVhETTuIyEdAd+Bt4BxV3eVumiYiC/0ZXChKLs0mK9I6ARpjGq4aEwfwgqp+U9kGVe3r43hCXmJJHnsjmwQ7DGOMCRpvqqp6ikhS+RMRSRaRm/wYU0hLLNpPVlhSzTsaY0w95U3iuFZVs8qfqGomcK3/QgptiQUF5Esss6ZPCXYoxhgTFN4kjnARkfInIhIONNiODOVTyK7ctCbIkRhjTHB4c4/jc5wb4f92n1/vrmuQYspnAozy5q0zxpj6x5tvv7/hJIsb3edzgIl+iyjEJRaWAtYJ0BjTcNWYOFS1DJjgLg3eMT16A5Brc48bYxoob8aq6iYiH4jIahHZWL54c3ARGSoiv4rIBhG5u5Lto0UkTUSWussYj22jRGS9u4zyWB8lIq+KyDoRWSsiw719sb5w6lnDidE8shvbFYcxpmHypqrqDeBB4J/AKcBVeJdwwoGXgD8D24EFIjJDVVdX2HWaqo6tULaJe86+gAKL3LKZwH3AXlU9zB14MeCdKpLLssiOjA30aY0xJiR406qqsap+BYiqblHVh4CzvCjXD9igqhtVtQiYCpzrZVynA3NUNcNNFnOAoe62q4HHwalGU9V9Xh7TZxJLc20KWWNMg+VN4ih0f9mvF5GxInI+4M23Zltgm8fz7e66ioaLyHK3Oqx9dWU9OiKOF5HFIvK+iLSs7OQicp2ILBSRhWlpaV6E672kov1khVsnQGNMw+RN4vgLEAPcChwLXAGMqraE9z4BUlT1aJyrisk17B8BtAN+VNU+wE/A05XtqKqvqmpfVe3bvHlzH4XrSCwsIIcEVi/9xafHNcaYuqDaxOHep7hEVfNUdbuqXqWqw1X1Zy+OvQNo7/G8nbvuN6qarqqF7tOJOImpurLpQD4w3V3/Ps4ovQGVkF+AShhffTsr0Kc2xpigqzZxqGopMOggj70A6CYinUQkChgBzPDcQURaezwdBpR3x54NDHHHxUoGhgCzVVVxrlIGu/v9Cah4s93v4tyZADMpCfSpjTEm6LxpVbVERGbg/LrfX75SVadXXQRUtURExuIkgXBgkqquEpFxwEJVnQHcKiLDgBIgA2fOD1Q1Q0TG4yQfgHGqmuE+/hvwtog8B6ThtPIKqNgC5yJpf6z15TDGNDzeJI5onCqiUz3WKf+rLqqSqs4EZlZY94DH43uAe6ooOwmYVMn6LcBJXsTtN+3ikwHItcRhjGmAvOk5HvBf9KHunAuu4r5lqdYJ0BjTIHkzA+AbOFcYv6OqV/slojoguWlTknQROVGWOIwxDY83VVWfejyOBs4HdvonnLojqTSHrMj4YIdhjDEB501V1Yeez0XkXWCu3yKqI5KKc9kcXVl/RmOMqd+86QBYUTegha8DqWsSigrIkiQy09ODHYoxxgSUN4MV5opITvmC04/ib/4PLbQlFhRQLFF8Mv3NYIdijDEB5U1VlVXkVyLe7QS4PTejhj2NMaZ+8eaK43wRSfR4niQi5/k3rNAX6yaO/Y0bBTkSY4wJLG/ucTyoqtnlT1Q1C2eujAYtmXAA8qwToDGmgfEmcVS2jzfNeOu1Pw0+E9EycmKsL4cxpmHxJnEsFJFnRaSLuzwLLPJ3YKGuZ+9+JJBDdiNLHMaYhsWbxHELUARMw5nF7wBwsz+DqiuSSrPIirIpZI0xDYs3rar2A3cHIJY6J6kkj32RNhOgMaZh8aZV1RyPKVtx58iY7d+w6obE4v1khlniMMY0LN5UVTVzW1IBoKqZWM9xwOkEmC9xfP3ZhzXvbIwx9YQ3iaNMRDqUPxGRjlQyWm5DFJ/v9OVYsmZpkCMxxpjA8aZZ7X3AXBH5DhDgROB6v0ZVR8TnFQCQ3Sg8yJEYY0zgeHNz/HMR6QMMcFfdpqr7/BtW3RBX5Mw5nh9rvceNMQ2HV6Pjquo+Vf0UWAPcKCKr/BtW3XBkpx4A5MRY73FjTMPhTauqNiJyu4gsAFa5ZUb4PbI64IwLriBG99sUssaYBqXKxCEi14nIN8C3QFPgGmCXqj6sqisCFF/ISyrLIts6ARpjGpDq7nH8C/gJuExVFwKIiLWmqiCxNJfsiLhgh2GMMQFTXeJoDVwEPCMirYD3gMiARFWHJBXnsSbGurUYYxqOKquqVDVdVV9R1ZOBPwFZwB4RWSMijwUswhCXeKCAbBLZsGZ5sEMxxpiA8LZV1XZVfUZV+wLn4gx0aICEggOohPP57OnBDsUYYwKi1vNqqOo6YJwfYqmTyjsBZmppkCMxxpjA8OqKw1QtpqAIgP02E6AxpoGwxHGI2sQkAJBricMY00B4lThEpK2InCAiJ5Uv/g6srjjvwquJ0GJyGlviMMY0DDXe4xCRfwCXAKuB8op8Bb73Y1x1RnKzZiTpErIbxQQ7FGOMCQhvrjjOA7qr6pmqeo67DPPm4CIyVER+FZENIvKHWQRFZLSIpInIUncZ47FtlIisd5dRlZSdISIrvYnD35JKs8mKtE6AxpiGwZtWVRtxOv4V1ubAIhIOvAT8GdgOLBCRGaq6usKu01R1bIWyTYAHgb44VzeL3LKZ7vYLgLzaxONPSSV5bG3UOthhGGNMQHiTOPKBpSLyFR7JQ1VvraFcP2CDqm4EEJGpOH1AKiaOypwOzFHVDLfsHGAo8K6IxAF3ANfh9GYPusTCAjKjk8lMTye5adNgh2OMMX7lTVXVDGA88COwyGOpSVtgm8fz7e66ioaLyHIR+UBE2ntRdjzwDE5Cq5I7SONCEVmYlpbmRbgHL+FAAcUSxayP3vbreYwxJhR4M5HTZD+e/xPgXVUtFJHrgcnAqVXtLCK9gS6qeruIpFR3YFV9FXgVoG/fvn4dnDE+z+lIvzXLvwnKGGNCgTfzcXRzrwZWi8jG8sWLY+8A2ns8b+eu+407HlZ59ddE4Ngayh4P9BWRzcBc4DAR+daLWPwqbr+TOPJsJkBjTAPgTVXVG8AEoAQ4BXgLmOJFuQVANxHpJCJROJM/zfDcQUQ87ygPw5lhEGA2MEREkkUkGRgCzFbVCaraRlVTgEHAOlUd7EUsfpVQKgDk2UyAxpgGwJvE0VhVvwJEVbeo6kPAWTUVUtUSYCxOElgDvKeqq0RknIiUN+e9VURWicgy4FZgtFs2A+dexgJ3GVd+ozwUDT7xNMCmkDXGNAzetKoqFJEwYL2IjMWpMvKq04KqzgRmVlj3gMfje4B7qig7CZhUzbE3A0d6E4e/9e53Iglff0t2tE0ha4yp/7y54vgLEINzRXAscAXwhw55DV1SWTbZkTaFrDGm/vOmVdUCABEpU9Wr/B9S3ZRUkktGRGKwwzDGGL/zplXV8SKyGljrPu8lIi/7PbI6JrFoP5lhScEOwxhj/M6bqqrncHpypwOo6jLARsetIPHAAfZLPN99+d9gh2KMMX7l7dSx2yqssunuKkjId2YCXLRsQZAjMcYY//KmVdU2ETkBUBGJxLlZvqaGMg1O3H6nH2NOZK1n4zXGmDrFmyuOG4CbccaK2gH0dp8bD3EHigHYb73HjTH1nDetqvYBlwcgljrt8HYpAOTUoylkS4pKiYgKD3YYxpgQU2XiEJEXqivoxbDqDcqwS8Zw69c/1qtOgJfPmogKvDfs+mCHYowJIdVdcdwArMSZ82InIAGJqA5L1qx6M4Xspo0bmB9/FCVE8tmMaZw17JJgh2SMCRHV3eNojTMs+enASJxZAP+rqpP9PNR6nZVUkkNWRHyww/CJd2dM4YDEUCKRfJ2+KdjhGGNCSJWJwx3y/BVVPQW4CkgCVovIyIBFV8ckFu8nKywh2GH4xLaWzuuI01yWt25fw97GmIbEm57jfXCa4F4BzMK72f8apMTCArIlic2pvwY7lEO2MakFLcr20D97BaujujNjujcj6RtjGoIqE4c7/PkinPm9vwP6quo1qurNnOENUkJ+AWUSzqzPQmIq9IOWvncPGxp1pGv+No7YuodSieCbnB01FzTGNAjVXXHcj1M91Qt4HFjszg2+QkSWByS6OibenQkwvbSwhj1D22vvTGC/xNMpPZ2xo++gWdlelrXuEOywaq2oqIjSUhvkwBhfq65VVaeARVFPxOQXAZBXx/tybG/mTLfSKa+UhMRE+mSv58ukAXz47iSGX3p1kKPz3uiZr5MXGc3k488huUmzYIdjTL1R3c3xLdUtgQyyrmjp9uGo64ljY5PmNClLZ+QVNwHQY1saZRLOD0X7ghyZ9+56/XG+TjyeX2KO4YHP3gh2OMbUK14Ncmi8c+55IwnXEnIa191OgNlZWWyI7kjXA1tITHKGib959O20KNvDslZ1o7rq9Tee54NOJ9KpZBM9itYyo+2JvPbGc8EOy5h6wxKHD7Vo054kzSKrUd1NHBMnv0iOJNEp/X9XFwmJiRyTtZ61kd2Y+p9XghhdzTIz9vF221aUEsHlG9dx5Z40hDLebtuG7KyQnbbemDrFEoePOVPIejUle0jamuwM0tgx8/c3+Hvu2IdKOD+W5QYjLK/dO/st1kZ25/zt3zP2+r9x1ZW3cP72uayLPIz7rMrKGJ+orjnuCrcVVcXFWlVVI7E4j6zwutsJcFPTZiRoFteMuuV3628cdTutynaxrGXHIEVWs2deHs+nLQdxdOFKHjn/xt/WP3LBTRxRtIYZrQfy79efDmKExtQP1V1xnA2cU8lSvt5UIqkon0xJIjM9Pdih1FpOdvYf7m+US0hMpHfmBtZFdGHymy8GKcKqrV6zlHcP601jCrg65wBx8f8b+iU2Lo5R+zKJoJQp7VOsysqYQ2StqnwsoaCAIolmzqdTgx1Krb319ktkhDWlc0ZapduP3JmBSjgLIkKvn8pja35ke3h7Llr/AyMuHvOH7VdefhPnbZvL+siu3DvTqqyMORTVVVXlikhOJUuuiOQEMsi6pLwT4MZ9u4IcSe1tinPm3mi3L6/S7Xfe+iBtSnewrEVKAKOq2cMvjeOrpAGcmPsLj15/f5X7jR9+M0cVruKTVoN46bWnAhihMfVLdVcc8aqaUMkSr6p1txLfz+LcxLE/OjLIkdTepqZNidVcrr3sxir3OSYzlQ0RnZn42rMBjKxqsz5/n2mHD6SF7uX2Zl2q3Tc2Lo7RWfuJoJh3UjqzN213gKI0pn7xulWViLQQkQ7liz+DqssSS5x/62InwA0x7elauIWmLVpWuc8Ru7JQCWNJjAYwsqpNKM0jS5IYsWY+J5zwpxr3v3zEdVywZS6pEV148Mt3AhChMfWPN6PjDhOR9cAmnMEON+OMkmsqMbD/SQDkxNatvhyvvvI0e8Na0jlrb7X73XHrA7Qr3cbSEKiuumvi4/wScwxD0+dxz9gHvS738EVjObpwJZ+2HMS/XvuHHyM0pn7y5opjPDAAWKeqnYA/AT/7Nao67LhBpxGv2WTXsU6A6yOLAWi/J7vGfXtnbCQ1ogv/fiV4TVsnTX6BDzo7vcMfOv7sWpWNjYvj6txCoijknZRu9bvKqqQo2BGYesibxFGsqulAmIiEqeo3QF8/x1WnJZVlkx1Vt6aQ3dy8KdGaz6XnXFHjvkftcToBLk0MTv/RzIx9vNWqJSVEcNnGX+nQrnOtjzHiomu4YPM8NkZ05oGv3vVDlMGTn5vDoxMfZ8jnUzh9zntkZtSdMcZM3eDN//wsEYkDvgf+IyLPA/v9G1bdllSSS1ZE3Wo/kBrTlq5Fm+nUpVuN+/7llvvpULqVpc2CM4DyfZ+/xdoop3f4LdfffdDHeejisfQ+sILPWgzk+Vef8GGEwbHoxy+5+d1nGfDLT7zY5QxSozqyLPpI7vzK7uUY3/ImcZwL5AO3A58DqXjZAVBEhorIryKyQUT+8D9cREaLSJqILHWXMR7bRonIencZ5a6LEZHPRGStiKwSkZD8355YtJ+ssMRgh+G1KZMnsDO8LZ2zq7+/4an3vlQ2RXTipZcD+yd45uXxfNJqEEcVruLR86tu/eWN2Lg4rtlfQiMKmdqpOzt21s3uSa+/8SwXzXiV8w/E8WGrU4kvy+OqzbOZd1h7+uUvYVbTgbz45gvBDtPUI9UmDhEJBz5V1TJVLVHVyar6glt1VS237EvAGUBP4FIR6VnJrtNUtbe7THTLNgEeBPoD/YAHRSTZ3f9pVT0cOAYYKCJnePlaAyaxsIBcSWDeN3WjDcGqQqcndfvdWV6XOSrDaXa8vEkjv8RUmfLe4dEUcFVO/u96hx+siy68igs2zWVTRCce/uEjH0QZGHt3beO+SU9w0hfvc1/Kqfwc15u++1fy4MYvmffn4Tx+1d9o1S6FB1scRpJmMbH9Yfy6ekWwwzb1RLWJQ1VLgTIROeWxZ9gAACAASURBVJifz/2ADaq6UVWLgKk4Vy/eOB2Yo6oZqpoJzAGGqmq+e48F95iLgXYHEZtfJbh9OeYv+jHIkXhnU4umRGkhwwcP87rMLTfdQ0rJZpY2DVx1VXnv8IvX/8BlF1/rs+M+eMkt9DmwjJnNB/LcK4/57Lj+8PWs9xjz3vOcvGY9r3caSkZ4Euft+ZZpspfp54zhxmvu/N3+xx43kNFblrFXWnD/hp+CFLWpb7ypqsoDVojI6yLyQvniRbm2wDaP59vddRUNdwdP/EBE2ntbVkSScKrMvqrs5CJynYgsFJGFaWmVD6HhL+WdAHOjJKDnPVipcW3oXLyZnr361Kpc7/RNbIlI4cV/PeqnyP5nnNs7fFDegmp7hx+M2Lg4ri0KozH5vNvlCLZs3ejT4x+qAwUFPDfxHwz77A1GNurMp81PpnXxHm5MncW8Pn14ZcRtnHBK1S3L7rr6Dk7Nns8P8f0YP8kGeTSHzpvEMR34O87N8UUeiy98AqSo6tE4VxWTvSkkIhHAu8ALqlrp/3JVfVVV+6pq3+bNm/soXO/EHnCatubVgb4cH74/me1h7eiSs6fWZY/OdJp6rmge6+uwfueLOR8x7fATaK5p3Jrkn76n5587kuEb57EloiPjf/7EL+eorSUrVnDn5Cc5ee4XPNHldFY07s6JOQt5avsPfH36pTw45h4Sk5t6dayn+p5J29LtvJ3Sl++/ne3nyE19V2PiUNXJwHvAz+49jsnuuprsANp7PG/nrvM8drqqlo+YNxE41suyrwLrVTUkp3Xr1soJPbcO9B5fnL4NlTDa76n9iLE33fg3OpdsZEnT2jeHrY1/FWWSKclcsnY+J514ut/O88SYe+lbsJRZzQbybAhUWd29fRlTOgyhWCK4ZMeXzGoSxtTzbmDkyFtqLlxBm/YduWHXNvKJ5bGCvRw4cMAPEZuGwpue4+cAS3FaVCEivUVkhhfHXgB0E5FOIhIFjAB+V05EWns8HQascR/PBoaISLJ7U3yIuw4ReQRIBG7zIoagOHXohTTSA+REh37i2NKiCRFazNDeJx1U+V77NrMtvAPPvfCIjyNz3PX64/wS04ehGfO47+YH/HIOT2NKo4hlP1O7HhnUKqsHX32MZdFHcnbad/w48FSev+JODu894JCOee3IGzln7zyWRh/Ffe+/5KNITUPkTVXVQzg3urMAVHUpUONPTFUtAcbifOGvAd5T1VUiMk5Eyu/C3uo2q10G3AqMdstm4PRYX+Au41Q1Q0TaAffhtNJaXLEJb6hIbtrUnUI29DsBpsa3JqVkCwMGnXpQ5fvklAGwstWht3Cq6I03X+RDd+7wv/cNTOO58865jOGpc9ka3oFx8z8NyDkr2pS6lo+6HEvrsp082P8con04h/0zZ4/hsOJ1fNj2BD744G2fHdc0LN72HK84DkWZNwdX1ZmqepiqdlHVR911D6jqDPfxPap6hKr2UtVTVHWtR9lJqtrVXd5w121XVVHVHhWb8Iaa5NJssiN8/2XqS1/OnsGW8A50zT34ITeuvf5OupSksqRJ9SPT1taihfN4vU1riongso1r6ZRSc8dEX3n82vs4Ln8Jnzc9gacnBL7K6rGFn7M3rCUXbFhK+46+rQaMiYvjjvxSBOWfiTFkZ2f69PimYfAmcawSkcuAcBHpJiIvAnWjnWkQJRbvJysstHuPf79hKWUSTofdhzYjXu+9m9gR3o5nXhjnk7i2bt3IPfs2kRrRmREbv+aW6+/xyXFr41qNIY48pnY7inXrA9f/4b2przO7+QB6H1jB36+/1y/nOO+8S7l424+kRnTh/2a/5ZdzmPrNm8RxC3AEUAi8A2QTwvcXQkXigXyyJIm9O7fVvHOQbG3VhDAt5aSuvQ/pOH0OhCNaxqrWSTXvXIPcnBz+svwbljc6kgt3fs2TY/zz5VmTYWdfwkXr57I9vD2PrPg+YOd9KyEcJYyR6fl+Pc/Dl4zl2IJlfNZsIBPeCr2pgE1o8yZxHK6q96nqce5yv6pak4waJBQcoFQi+PjD0K1H3hDfio6lWzntdO87/lXmmmtup1tJKkuTu6B6aPN03PTl2/wUeyxnpn/Pi1fcWXMBP3rk+vsZlLuAOUnH80gAqqwee+VRFjbuzZ8zfubyK67367mio6N5IDmFeHJ4tW0XNqWu8+v5TP3iTeJ4RkTWiMh4ETnS7xHVE+VTyO4tLghyJJX7ee7XbI7oSJdc30xx22vvFnaGt+XpFw++uuqGqf9kTvJATsqdz/NDRvskrkP1fy170FzTePew4/jhh6/9dp60PTv5sGsvmpWlcVfPg2vhVlv9jz+ZKzcvZldYG+5Z6b/XZuofb/pxnAKcAqQB/xaRFSLi26679VBcvtM9JT82cGM51cbnS3+gRCLpuPfQ7m+U61/aGNFSVrVpclDl73jzH3zc8hSOLVjG8/3OJj4hNO4P9e8/iEvXLSJDmvBs9ia/nefhL99lR3g7zt20gMN7HlrVYW3ce/WdDM75mW8TBvCY9So3XvJqQgVV3a2qLwA34PTp8H+D+jquaYTThDJUOwFua5mMaBnHNUvxyfGuGHUz3Us2sCS5GznZNU8G5em+fz/C1A6n0aNoLU+270XrVpWNTBM899x4L6dn/MhPscdyz0TfV1nN/PQ9ZrbuT4+itdx/WeBvHz5+5Km0LtvJWyl9mP/TdwE/v6l7vOkA2ENEHhKRlUB5i6qQG1gw1Aw9czhhWkp249BMHKkJLWlXtp3zLqx54iZv9dq9hT1hrZgw+Z9elxn3r4d5q9sQOpRu44HIeI44KnC/tmtjfP9z6Viyhfc7n8h7H0zx6bEnag6FRHPZjl00jgl8359OXQ7juh2p5JLAw5mbrVe5qZE3VxyTgExgiKoOVtUJqur9xA0NVEqX7iRpFpvjWzLhhceDHc7vrF62mI2RKXTJ2+nT4x4fmUyYlrKqbTOv9n/yX+N4s+dpNNV0bk9P55RTz/JpPL7Uvn0HRm7ZSCGNeDUujPz9vpnL7NlXnuCn2D4Mzv6Fa6++3SfHPBg3XnkLZ+2bx+LGvXhw2r+CFoepG7xJHKfijEDbRERC8+dziOqbtYZ1kd0Yf+QQzpj1Fg+89DB7d+2ouaCfffjtDIqkEZ321jitSq2MuPRaDi9ex9KkmqurJrzyFK/3PIlGFHJT6mouGXGNT2Pxh7FjbufcXT+wslFP7pn+8iEfLy8nm/e7dCeBHP7S8nAfRHhonjr9SrqUpPJe+xP4+OP6NZ2u8a0qE4eIRIjIk8BWnFFr3wK2iciTIhIZqADrsreGj+WuJR9xatZ81jfqxKs9z+W01Su5Yeo/eWti8MZn3NbK6W9xRKODu5FdnV67t7E3rCUvvVl1ddV/pvybCd2OpoQIxqz+keuu+6vP4/CXx86+hp5Fa/io7Ym88vrzh3SsBz/6N5siOjFsy3z6nXBwQ774UmJiMrfn5qMIz8ZEkJ+XF+yQTIiq7orjKaAJ0FlVj1XVPkAXIAmw5hdeuuOOh5lywU28G13GyI2zSCzN5eOWp3Bv54EM++wNHn7+QTIzfNOyyVsbE1vQpnQHV4w6tKlXKzOwcQvCtYTV7Ssfyv7zz6fzXKvWZEkiV63+ir+OrVsN9BISk7gmK59ISpjcoQO7DvIKcu63s/mkfX+6lKQy7pLaj3brLxdeMJLhO35kXWQ3/vppSI7mY0JAdYnjbOBaVc0tX6GqOcCNwJn+Dqy+Oe6Ek3nqmnv4YciF3Lb4QwblLmJF4+5MOPp8/rT4J8b+52k+nPq63+PYtHEDG6JS6JLvnyqzCy8eTY+idSxJPOwP1VXLlyzgsbASdoa1YdS6Odw/9kG/xOBvl19yDRdt+oFNEZ24f+6HB3WMl7I2kks8F29MDcoN8eo8etHN9D6wgk9aDOS1tycEOxwTgqpLHKqVdAN2p5M9tO7BDdzdfx3P1HNv4JX8nVy6ZTaRWswHbU7j9hZHMPyT13jk2b/77dzvznibAxLj8/sbnnrt3sa+sOa84NG6auvWjdy1ey3rIg/jss1zGH+D/15jIDxxzT30y1/CrKYDeXJC7Ro/THjtab5L6MegvIX85fq7/BThwYuOjubexi2IYT9Ptj2CYZ+9wV//8xzvv/8OhYWFNR/A1HsR1WxbLSJXqurvRkETkSuAtVWUMbVw+tkXUj4t0aP//DuLu3ZgQexRzDvmOD6Z8zEn7FjHOa0P49TTz/PZObe1dKaP71riv9tUJye1Y5oWs6Z9C8AZf+r2ZV+xNO44hu/8iqeuDvyghf5wa+OW3KpZ/OewYzht2SL69Dq2xjIF+flM7diBxuRzY3TLAER5cE4afDo3v/FPvmjZhF8bd+KXmCT+A9w7bz5dCrfQNTudY0vjuPCsC4lPOvQxykzdIlWNLSQibXGmjS3gf1PF9gUaA+eravCbB3mpb9++unDhwmCH4ZUPp77ONyWZ/NiqBzvD29KpZBMvxbekz4ATfHL802dNYVdUc5b/yX8z6QEM+XwK2yNbM/foo7j9+/eY3WQQQzPm8ubwsX49b6CNe+VRXu5+FifnzGfauTWPL3XP64/zRuczuHj7l7wwMrhjcXmrsLCQ2Z/9l7n5O1iXlEBq4/akhTk/CqI1n87FW+iak8bRBRFceMo5tGrfvoYjmrpCRBapat8/rK9pUDoRORVndFyA1ar6lR/i86u6lDjKZWZk8NhH/+btzmdwYu583h926IPepe/dQ7+V6+i1/1emn+Pf+a/unPQEUzoNpX/+YubH9GFQ7gLeGHxJyAwl4kuXfzSBr5KO57p1MxlXzVDoK5fO5+L0PGJ1P7OPOYEmTb3r7xKKvvvyc77cuYZfk2JJjWnDjnCnT3CkFpFSspUuuXvomVfKxf1PJ+Xw7kGO1hysqhKHN2NVfa2qL7pLnUsadVVykyY8dc09nJb5Iz/E9+fOSYfeifC1dyawX+LplO6/+xvlTmvZjUgtYn5MH445sJwX+51ZL5MGwH2HD6JN6Q7e63Y8M2d9VOV+T2/4hYywply4YVWdThoAJ582lPFX3s57w65j0WlnM7txAWO3fsfJOYsolgi+SB7Asx1O4uwdW9i4YUOwwzU+5tVYVSZ4xh11Gt2KN/Beyik8+eyhtULa3iwOgE55pb4IrVpDzxrOiTmLOObAcv7RqkfIjT/lSz17HMXlG1aSSzwvkltpr/K33nqJL5sMoF/+Ev52Q/24x+Op14DjuX/UX5hy3o38/OfzmNc6ljE7vmVfWAseXvFFsMMzPmaJI8R17nYYo1I3E80B3uk1gFkfvnfQx9rYpDlNytIZecVNPoywam8OHc3MoSM5+pjjAnK+YPrrDX/jrLQfWBJ9NA+898chO6a0SCSCEq4+UF17lPqjU4/DeeSK2xiwfzFfJR7HJ1/MCnZIxocscdQBY268k8tWfcseacG/GheQlVn7eaKzs7LYEN2Rrge2kBigVjBR0Y0RkYCcKxQ8+qcr6Fq8gQ87nsibb7/y2/qHXn2M5Y2OZOjenzlv+MggRhh4dzXvSQTFvFAW2E6uxr8scdQRD93yEOfs/Z5FjXtx38zadxScOPlFciSJTun7/BCdAWjerDmjd+1GgUktm5KTncXm1LV81KUPrcp2cd/x5wY7xIA7of8AzkxfzIpGR/DktFeDHY7xEUscdchjg0dwdOFKPm49mPHP1e5+x9ZkZ0KpjpnWgcufxoway/Btc1kX2Y27Zk7i8YWz2BPWivNTl9C+Y+dghxcUj5x6GS3LdvOfZh3Yt9d+uNQHljjqkGatWnN9WgHJmsE7R53E2xNf8LrspqbNSdAsrhkVOuMi1VfjL3SG7Pi05YnMan48vQ6s5MHrqm6mW981adqEkfu2siesFX//fmqwwzE+YImjjhk+8louXz6XPInnjfbN2bplY41lsrOyWB/dIaD3NxqymNhYbiyJJob9KGFcmpYT7JCC7s5LruPowpXManIsP/78Y7DDMYfIEkcddM/t4xi+7VtWR/XgoQWf1rj/21NeJjOsKZ0z0gIQnQE495yLuGH9Aq79dQ6jRvp+FOK66PaoZpQQwT/SAzNi0dLlC3hs+it8vvBbcvJyay5gvNYw2gbWQw8Nu5bN86Yzq8kg/v7yOMbfVPU08JviwgFot8/mVwikO67/v2CHEFLOOHUop330Mp8nncC/P3yb6/3Ywmx96lpGp+1jd/IAyIWwX9bRUvfQpiSdDiWFdItsTJ8WKfTvcSyNG9n8dLVliaOOSkpO5q/Rbbi9bAfvHH4KrV94hJturXxui01NmxKruVx7mf3yNcH1UJ8zmJ+6iUkJCVyRv5/YmFifnyM7O4trUpezL6ITt+YuICK6MRtKDrAtvDHbIlqwOLI5KmGQCRHzVtC6bDdtSjLoWFZM96h4jmvTjWO6HUVkpM1XVxVLHHXYiaedwWX/fJgXe/2Zt3scwcmL5nPEsf3/sN+GmPZ0LdxC0xYnBiFKY/4npWMnLvxpJq+1HMhDn7zBU5f4dtDL4uJiRs2bzrrGfbgh82fuveCGP+yTnpXOvF8XszxzJ6llxWyLiGV9ZDvmhzV1dtgDjXYvonXZbnodSOOlP48mopElEU81DnJYH9TFQQ5r4+5XH+XNbmdxcs7PTDv39/9RXn3laR7ofhrn7/6aCZfeEaQIjfmfoqIiTv12BnsiWvDf1s3o2aOnz459/ccv89/EExiW/SOvnle7ERJ27N3BvPXLWJmzh41axubIJDZEdOHmiFX8/cTLfRZjXXLQgxya0PfEdffxp6yf+C5hAP838bHfbVsfWQxA+z3ZlRU1JuCioqK48UAZecQyfv0PPjvuQ9Nf4b+JJzCgYDEvnXVtrcu3bdGWiweeybgzrmLKmdfwzSnD6F66gUnFnVixY43P4qwP/Jo4RGSoiPwqIhtE5O5Kto8WkTQRWeouYzy2jRKR9e4yymP9sSKywj3mC9KQxrSoxgPdjqdr8Qbe63wqTz3z0G/rNzdvSrTmM3L4VcELzpgKLh92MSfuX8x3cX1577Pph3y8iZ9NYWLSsRxWvI7JAy/wyf2JyIhInu7WjVLCuH3NckpL/T84aF3ht8QhIuHAS8AZQE/gUhGp7Jp0mqr2dpeJbtkmwINAf6Af8KCIJLv7TwCuBbq5y1B/vYa6pPuRvRm1PpVGFPJO7358OcOZCzs1pi1dizbTvn1KcAM0poL7U/rRmAJejiymqKjooI8ze+5sHm/ckWa6j0ldepGY6Lu+Ssd17MUV4etZGd6dJ36a5rPj1nX+vOLoB2xQ1Y2qWgRMBbwdrOd0YI6qZqhqJjAHGCoirYEEVf3ZnQ/9LcB386rWcdfe/DcuXfUNu6Ulz4fnMGXyBHaGt6Vz9t5gh2bMHxx9VC+G7VvC2sjuPDG99uOvAaz6dQX/VwhhlPFcXDRdu/h+0qiHB46gW2kqrxd1ZNWudT4/fl3kz8TRFtjm8Xy7u66i4SKyXEQ+EJHyOSerKtvWfVzTMRGR60RkoYgsTEtrOB3fHr7lIc5O+4EFMcfwpju/ePvdWUGOypjKjT9jNO1KtzGteTd27NhZq7IZ6fu4fus6MiWZvxftZHD/U/wSY2REJE917UIJEdy+arFVWRH8m+OfACmqejTOVcVkXx1YVV9V1b6q2rd58+a+Omyd8PjJl3BU4SpWNupJlBYyfPCwYIdkTKXi4uO5KnMf6WHNeODnqmdPrKiosJBRv3zKhogu3Ji1hCuHXurHKGFASm8uC/+V5eGH8+TPBz8nTn3hz8SxA/Cctb6du+43qpququXDtU4Ejq2h7A73cZXHNM5giDek5dOsbC+HFaXS4+hjgh2SMVW6+aKr6FuwjC+Sj+PL7772qswNn09iQXRvhmfN494LrvdzhI7xAy+la+lGXitsz+oGXmXlz8SxAOgmIp1EJAoYAczw3MG9Z1FuGFDe5m02MEREkt2b4kOA2aq6C8gRkQFua6orgf/68TXUWcNHXsvDW1P5S05Rg5pMydRNdyakIJTxTP72Gve9b/rLzEw4nkH7F/Lc2dcFIDpHZEQkT3ZJoZgo7li1qEFXWfktcahqCTAWJwmsAd5T1VUiMk5EyutObhWRVSKyDLgVGO2WzQDG4ySfBcA4dx3ATThXJxuAVMDmpKzC8Ktu5JyLRwc7DGNqNHjQyQzNXMiS6KN57v2qb5S//MmbvJnUjx5Fa5l00kUBHxbkhE59GBG2lqXhPXhm/vsBPXcosZ7jxpiQsHfPHk5duYwoLearvieQnJT8u+2fff8Zt5QkkVSWxfRuPUgJ0sRYRSVFnPLtZ+wOa85nR7Tm8JZdghJHIFjPcWNMSGvRsiWXpm1kZ3hbHpoz5Xfblq1awt+Ko4ikmBeTEoKWNACiIqL4R+cOFBHF7SvmN8gqK0scxpiQ8X8XXE3PorV80rQPS5YuBmDP3p3csHMzOZLAw6X7GNg3+IN1Dup8LBeHrWFJeE/+Of+DYIcTcJY4jDEhIyoqirHamEIa8ei2xRQVFjJ60VdsDu/IzdnLGfHnC4Md4m8eH3Qpncs28cqBNqzfuynY4QSUJQ5jTEi5YOi5DM5dyLzYPpz39TSWRB/Fxdk/87fzaz9woT9FRUTxREpbCmnEbct/bFBVVpY4jDEh5+EjTyOeHBZHH83gvF94+uzQShrlTurSjwvD1rAo/Ahe+OXDYIcTMJY4jDEhp2uXrly/ez1Dsn7ilUGXhPRsfI8NvIROZZt5uaAVqWmbgx1OQNgMgMaYkPTXy0LzKqOixpHRPNahFSO3hfOXZfP49LSUYIfkd3bFYYwxh+iUbgMYLqtYGH4Ez/9c/zsGWuIwxhgfeGLQCDqWbeFf+S3YtG9rsMPxK0scxhjjA06VVQvyieW2pd/75JjFxTk+OY6v2T0OY4zxkT91O54Ltr/J++G9+df8Dxnbf3iNZUrLSknN3saqrO2szc1kQ34Rm4ui2FqaRAnhnN+qLZe3aUafhJiQGbDUxqoyxhgfyi8sYPDcOWRJAl/06kpKU2cmiLyifNZkbWZ11i7W7c8ltaCMLcWN2V7WlGKifisfTy7tw7PoFFWEhifxTX4zCsqUw2Kiuax1Ey5s1YRmUYH5zV/VWFWWOIwxxsfm/DqP0TsakaLbadIIthbHsVeboOLcHRAto7lk0DEyj86NyugWG0OPhGYckdyRVrG/n3gut6SU/+7N4p1d6SzOySdShCHNErisdVMGN4kn3I9XIZY4LHEYYwLotm/eZLoeTpuwTFKiCugcHUb3uHh6JLaiZ3In4qJian3MtfsLeHdnBu/vySCjuJQ2jSK5pFUTRrRuQsfGjXz+GixxWOIwxgRQSUkJRUVFxMTUPkHUpKisjNn7cnhnVzrfZuSiwKCkOC5r05QzmyUSHe6bdk9VJQ67OW6MMX4QERFBRIR/vmKjwsI4p0US57RIYseBIqbtzuDdXRnctHoLiRHhXNAymctaN+GoeN8nLbArDmOMqRfKVJmXmcc7u9KZuS+bwjLlqLjGvNOrM82jDm7IFrviMMaYeixMhBObxHNik3iyikuYvieTuZl5NIv0/de8JQ5jjKlnkiIjuLpdc65u17zmnQ+C9Rw3xhhTK5Y4jDHG1IolDmOMMbViicMYY0ytWOIwxhhTK5Y4jDHG1IolDmOMMbViicMYY0ytNIghR0QkDdgS7Diq0AzYF+wgqmHxHRqL79BYfIfmUOPrqKp/6EXYIBJHKBORhZWNBRMqLL5DY/EdGovv0PgrPquqMsYYUyuWOIwxxtSKJY7gezXYAdTA4js0Ft+hsfgOjV/is3scxhhjasWuOIwxxtSKJQ5jjDG1YokjAESkvYh8IyKrRWSViPylkn0Gi0i2iCx1lwcCHONmEVnhnvsP8+yK4wUR2SAiy0WkTwBj6+7xviwVkRwRua3CPgF9/0RkkojsFZGVHuuaiMgcEVnv/ptcRdlR7j7rRWRUAON7SkTWun+/j0QkqYqy1X4W/BjfQyKyw+NveGYVZYeKyK/uZ/HuAMY3zSO2zSKytIqygXj/Kv1OCdhnUFVt8fMCtAb6uI/jgXVAzwr7DAY+DWKMm4Fm1Ww/E5gFCDAAmB+kOMOB3Tgdk4L2/gEnAX2AlR7rngTudh/fDfyjknJNgI3uv8nu4+QAxTcEiHAf/6Oy+Lz5LPgxvoeAO734+6cCnYEoYFnF/0v+iq/C9meAB4L4/lX6nRKoz6BdcQSAqu5S1cXu41xgDdA2uFHV2rnAW+r4GUgSkdZBiONPQKqqBnUkAFX9HsiosPpcYLL7eDJwXiVFTwfmqGqGqmYCc4ChgYhPVb9Q1RL36c9AO1+f11tVvH/e6AdsUNWNqloETMV5332quvhERICLgXd9fV5vVfOdEpDPoCWOABORFOAYYH4lm48XkWUiMktEjghoYKDAFyKySESuq2R7W2Cbx/PtBCf5jaDq/7DBfP8AWqrqLvfxbqBlJfuEyvt4Nc4VZGVq+iz401i3Km1SFdUsofD+nQjsUdX1VWwP6PtX4TslIJ9BSxwBJCJxwIfAbaqaU2HzYpzql17Ai8DHAQ5vkKr2Ac4AbhaRkwJ8/hqJSBQwDHi/ks3Bfv9+R506gZBs6y4i9wElwH+q2CVYn4UJQBegN7ALpzooFF1K9VcbAXv/qvtO8edn0BJHgIhIJM4f+D+qOr3idlXNUdU89/FMIFJEmgUqPlXd4f67F/gIp0rA0w6gvcfzdu66QDoDWKyqeypuCPb759pTXn3n/ru3kn2C+j6KyGjgbOBy94vlD7z4LPiFqu5R1VJVLQNeq+K8wX7/IoALgGlV7ROo96+K75SAfAYtcQSAWyf6OrBGVZ+tYp9W7n6ISD+cv016gOKLFZH48sc4N1FXVthtBnCl27pqAJDtcUkcKFX+0gvm++dhBlDeQmUU8N9K9pkNDBGRZLcqZoi7zu9EZChwFzBMVfOr2Mebz4K/4vO8Z3Z+FeddAHQTkU7uFegII0zJYgAAAh5JREFUnPc9UE4D1qrq9so2Bur9q+Y7JTCfQX/e+bflt1YMg3AuGZcDS93lTOAG4AZ3n7HAKpxWIj8DJwQwvs7ueZe5MdznrveMT4CXcFq0rAD6Bvg9jMVJBIke64L2/uEksF1AMU4d8TVAU+ArYD3wJdDE3bcvMNGj7NXABne5KoDxbcCp2y7/DL7i7tsGmFndZyFA8b3tfraW43wBtq4Yn/v8TJxWRKmBjM9d/2b5Z85j32C8f1V9pwTkM2hDjhhjjKkVq6oyxhhTK5Y4jDHG1IolDmOMMbViicMYY0ytWOIwxhhTKxHBDsCY+kpESnGal0YAm4CRqpoV3KiMOXR2xWGM/xSoam9VPRJnwLz/b++OUROIoigMn0uKxFXEMli5B1fhGoQ0ugH3EHAPU6dzAal01iC26UMgci3ee0UEYa7mzaT4v2aK4cFthsMww7mLoQcC/gLBAfTjQ7lIztLukPdyw8zechVI2eWwNrN93unwMsy4wHUEB1CZmT0o1cF3rcb49FSSt5G0qjYYcCOCA6hnlLfElXrrbcdzpbBuJ2lcYS7gLgQHUM+Xu08lPSt1fZVvHD/6/ew9XZz7zteT+IEF/xDBAVTmqYn2VdIy13IfJE3M7NHS3u/ZoAMCQQQH0AN3b5WaTOfufpTUKNVtN5LaIWcDomjHBQCE8MYBAAghOAAAIQQHACCE4AAAhBAcAIAQggMAEEJwAABCzpDJoMFUbqMzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gamma_range = {'start': -13, 'stop': 1, 'num': 15, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 15, 'base': 2.0}\n",
    "\n",
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_dist = []\n",
    "outer_dist = []\n",
    "permutation(data_params, grid_params, inner_dist, outer_dist, classes, runs=20)\n",
    "\n",
    "np.save('output/permutations/outer_dist15.npy', outer_dist)\n",
    "np.save('output/permutations/inner_dist15.npy', inner_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Neural Network\n",
    "\n",
    "DNN Guides:\n",
    "<br><a href=\"https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/\">Optimizers</a>\n",
    "<br><a href=\"https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-i-hyper-parameter-8129009f131b\">DNN Layers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNN(data_params, classes, epochs=20, layer_size=256, num_inner=1, scramble=False, rank_first=True, shuffle=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using NNs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)  \n",
    "    classes: list, required if scramble is True\n",
    "        label classes for the data (should be length of 2)\n",
    "    epochs: int\n",
    "        number of iterations to train model on\n",
    "    layer_size: int\n",
    "        size of hidden layer\n",
    "    num_inner: int\n",
    "        number of inner subjects to test classifier on,\n",
    "        default is 1\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "    rank_first: boolean\n",
    "        whether to use first block in subject to order the rest of the blocks for that subject,\n",
    "        default is True\n",
    "    shuffle: boolean\n",
    "        whether to randomize which block to use in rank-ordering, \n",
    "        default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    if scramble and classes is None:\n",
    "        print('You must pass a list of label classes if scrambling the label data!')\n",
    "        raise ValueError\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    \n",
    "    cols = []\n",
    "    for combo in itertools.combinations(range(len(subjects)), num_inner):\n",
    "        col = ''\n",
    "        for subject in combo:\n",
    "            col += '/' + subjects[subject]\n",
    "        cols.append(col[1:])\n",
    "\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    val_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    bmin, bmax = get_min_max_block_length(data_params['path'], subjects, suffix, data_params['roi'], data_params['conds'])\n",
    "    block_length = bmin\n",
    "    x_data, y_data = generate_dataset(subjects, data_params['path'], suffix, data_params['roi'], data_params['conds'], block_length, rank_first, shuffle)\n",
    "    \n",
    "    for outer_subject in subjects:\n",
    "        \n",
    "        print(f\"Currently on outer subject #{subjects.index(outer_subject)+1}.\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        inner_subjects = [s for s in subjects if s != outer_subject]\n",
    "        for inner_test_subjects in itertools.combinations((inner_subjects), num_inner):\n",
    "            \n",
    "            inner_test_subjects = list(inner_test_subjects)\n",
    "\n",
    "            col = ''\n",
    "            for subject in inner_test_subjects:\n",
    "                col += '/' + subject\n",
    "            col = col[1:]\n",
    "            print(f\"Currently on combination of {col}.\")    \n",
    "            \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = split_dataset(x_data, y_data, inner_test_subjects, outer_subject, scramble, classes)\n",
    "            \n",
    "            y_train = labels_to_int(y_train, classes)\n",
    "            y_test_inner = labels_to_int(y_test_inner, classes)\n",
    "            y_test_outer = labels_to_int(y_test_outer, classes)\n",
    "            \n",
    "            x_train = np.array(x_train)\n",
    "            x_test_inner = np.array(x_test_inner)\n",
    "            x_test_outer = np.array(x_test_outer)\n",
    "            \n",
    "            model = Sequential([\n",
    "                    layers.Dense(layer_size, input_shape=(block_length,), activation=\"relu\"),\n",
    "                    layers.Dense(1, activation=\"sigmoid\")\n",
    "            ])\n",
    "\n",
    "            optimizer = optimizers.Adam(learning_rate=0.001)\n",
    "            model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "            model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test_inner, y_test_inner), verbose=0)\n",
    "            outer_loss, outer_acc = model.evaluate(x_test_outer, y_test_outer, verbose=0)\n",
    "            val_loss, val_acc = model.evaluate(x_test_inner, y_test_inner, verbose=0)\n",
    "                \n",
    "            # logs inner and outer subject accuracy data in dataframe\n",
    "            outer_acc_report.at[outer_subject, col] = outer_acc\n",
    "            val_acc_report.at[outer_subject, col] = val_acc\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print(f\"Last turn took {minutes} minutes and {seconds} seconds.\")\n",
    "    \n",
    "    clear_output()\n",
    "    return outer_acc_report, val_acc_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Runs of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer accuracy mean: 0.5587606430053711\n",
      "Validation accuracy mean: 0.558226466178894\n"
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "data_params = {'path': r'scans/output/PRE/', 'roi': 1, 'conds': [1, 3]}\n",
    "classes = ['untrained_ip', 'trained_ip']\n",
    "\n",
    "'''\n",
    "outer_accs, val_accs = []\n",
    "for i in range(5):\n",
    "    print(f'On run {i+1}.')\n",
    "    outer_acc_report, val_accs = trainNN(data_params, classes, layer_size=256, scramble=False)\n",
    "    outer_accs.extend(df_to_arr(outer_acc_report))\n",
    "'''\n",
    "\n",
    "outer_accs, val_accs = trainNN(data_params, classes, layer_size=256, scramble=False)\n",
    "\n",
    "print(f\"Outer accuracy mean: {np.mean(df_to_arr(outer_accs))}\")\n",
    "print(f\"Validation accuracy mean: {np.mean(df_to_arr(val_accs))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last turn took 0 minutes and 26.890951 seconds.\n",
      "Currently on outer subject #9.\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 271us/sample - loss: 0.7288 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 224us/sample - loss: 0.7058 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 486us/sample - loss: 0.7230 - accuracy: 0.4375\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 314us/sample - loss: 0.7092 - accuracy: 0.4375\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 364us/sample - loss: 0.6799 - accuracy: 0.7500\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 222us/sample - loss: 0.8044 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 991us/sample - loss: 0.7276 - accuracy: 0.5000\n",
      "16/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 243us/sample - loss: 0.6953 - accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "data_params = {'path': r'scans/output/PRE/', 'roi': 1, 'conds': [1, 3]}\n",
    "classes = ['untrained_ip', 'trained_ip']\n",
    "\n",
    "outer_accs_unscrambled = []\n",
    "for _ in range(20):\n",
    "    outer_acc_report, vals_accs = trainNN(data_params, classes, scramble=False)\n",
    "    outer_accs_unscrambled.extend(df_to_arr(outer_acc_report))\n",
    "    np.save('output/nn_outer.npy', outer_accs_unscrambled)\n",
    "    \n",
    "outer_accs_scrambled = []\n",
    "for _ in range(20):\n",
    "    outer_acc_report, val_accs = trainNN(data_params, classes, scramble=True)\n",
    "    outer_accs_scrambled.extend(df_to_arr(outer_acc_report))\n",
    "    np.save('output/nn_outer_s.npy', outer_accs_scrambled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Testing One Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "subjects, suffix = get_subjects(path)\n",
    "\n",
    "x_data, y_data, y_data_scrambled = generate_dataset(subjects, path, suffix, roi, conds, block_length, True, classes, True, False)\n",
    "x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = split_dataset(x_data, y_data, [subjects[1]], subject[0], y_data_scrambled)\n",
    "\n",
    "y_train = labels_to_int(y_train, classes)\n",
    "y_test_inner = labels_to_int(y_test_inner, classes)\n",
    "y_test_outer = labels_to_int(y_test_outer, classes)\n",
    "\n",
    "model = Sequential([\n",
    "        layers.Dense(256, input_shape=(block_length,), activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, validation_data=(x_test_inner, y_test_inner), verbose=2)\n",
    "#outer_test_loss, outer_test_acc = model.evaluate(x_test_outer, y_test_outer)\n",
    "print(model.predict(x_test_outer))\n",
    "print(y_test_outer)\n",
    "\n",
    "#print(f\"Test loss: {outer_test_loss}\")\n",
    "#print(f\"Test accuracy: {outer_test_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Within Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tr_subject_data(path, subject, suffix, roi, conds):\n",
    "    \n",
    "    '''\n",
    "    Extracts individual subject data from the .mat files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of voxel data (x_data) separated by individual TRs and the corresponding labels (y_data)\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    path_to_file = path + subject + suffix\n",
    "    mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "    \n",
    "    test_TRs = []\n",
    "    \n",
    "    for scan in range(len(mat[0])):\n",
    "            \n",
    "        for cond in conds:\n",
    "            \n",
    "            for block in range(len(mat[0][scan][0][cond][0])):\n",
    "\n",
    "                for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "\n",
    "                    tr_data = mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist()\n",
    "                    \n",
    "                    if tr == 0 or tr == len(mat[0][scan][0][cond][0][block][0]) - 1:\n",
    "                        test_TRs.append(len(x_data))\n",
    "                        \n",
    "                    x_data.append(tr_data)\n",
    "                    y_data.append(mat[0][scan][1][cond][0])\n",
    "                               \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_standardized = scaler.fit_transform(x_data)        \n",
    "    \n",
    "    test_x_data = []\n",
    "    test_y_data = []\n",
    "    for i in test_TRs:\n",
    "        test_x_data.append(x_standardized[i])\n",
    "        test_y_data.append(y_data[i])\n",
    "    \n",
    "    train_x_data = []\n",
    "    train_y_data = []\n",
    "    for i in range(len(x_standardized)):\n",
    "        if i not in test_TRs:\n",
    "            train_x_data.append(x_standardized[i])\n",
    "            train_y_data.append(y_data[i])\n",
    "    \n",
    "    data = {'train_x': train_x_data, 'train_y': train_y_data, 'test_x': test_x_data, 'test_y': test_y_data}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tr_dataset(data, scramble, classes):\n",
    "    \n",
    "    train_x, inner_test_x, outer_test_x, train_y, inner_test_y, outer_test_y = None, None, None, None, None, None\n",
    "    \n",
    "    train_x, outer_test_x, train_y, outer_test_y = train_test_split(data['test_x'], data['test_y'], test_size=2, stratify=data['test_y'])\n",
    "    train_x, inner_test_x, train_y, inner_test_y = train_test_split(train_x, train_y, test_size=6, stratify=train_y)\n",
    "    \n",
    "    train_x.extend(data['train_x'])\n",
    "    train_y.extend(data['train_y'])\n",
    "    \n",
    "    if scramble:\n",
    "        scramble_labels(train_y, classes)\n",
    "    \n",
    "    return train_x, inner_test_x, outer_test_x, train_y, inner_test_y, outer_test_y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_within_subjects(data_params, grid_params, runs=50, scramble=False, classes=None):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using SVMs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_params: dict\n",
    "        path: str\n",
    "            the path to the data files\n",
    "        roi: int\n",
    "            0 for V1 data, 1 for MT data\n",
    "        conds: list\n",
    "            list of integers specifying the conditional datasets to extract\n",
    "            (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)   \n",
    "    grid_params: dict\n",
    "        kernels: list\n",
    "            kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "        gamma: dict\n",
    "            dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "        C: dict\n",
    "            dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "            num of values, and the exponential base\n",
    "    runs: int\n",
    "        number of runs to test on for each subject\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, \n",
    "        default is False\n",
    "    classes: list, required if scramble is True\n",
    "        label classes for the data (should be length of 2)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    if scramble and classes is None:\n",
    "        print('You must pass a list of label classes if scrambling the label data!')\n",
    "        raise ValueError\n",
    "    \n",
    "    subjects, suffix = get_subjects(data_params['path'])\n",
    "    \n",
    "    # Sets up DataFrames used to track inner and outer subject test accuracies\n",
    "    cols = [n for n in range(runs)]\n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        print(f\"Currently on subject {subject}.\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        subject_data = extract_tr_subject_data(path, subject, suffix, roi, conds)\n",
    "        x_train, x_test_inner, x_test_outer, y_train, y_test_inner, y_test_outer = split_tr_dataset(subject_data, scramble, classes)\n",
    "        print(f\"Training data size: {len(x_train)}\")\n",
    "        print(f\"Inner testing data size: {len(x_test_inner)}\")\n",
    "        print(f\"Outer testing data size: {len(x_test_outer)}\")\n",
    "              \n",
    "        for run in range(runs):\n",
    "            \n",
    "            if (run+1) % 10 == 0:\n",
    "                print(f\"On run #{run+1} of {runs}.\")\n",
    "            x_train, x_test_inner, x_test_outer, y_train, y_test_inner, y_test_outer = split_tr_dataset(subject_data, scramble, classes)\n",
    "            \n",
    "            # Gets optimal params for training dataset from grid search\n",
    "            opt_params, inner_acc = get_optimal_run(x_train, y_train, x_test_inner, y_test_inner, grid_params['kernels'], grid_params['gamma'], grid_params['C']) \n",
    "\n",
    "            # Trains model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=opt_params['kernel'], gamma=opt_params['gamma'], C=opt_params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            \n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # Logs inner and outer subject accuracy data in DataFrame\n",
    "            inner_acc_report.at[subject, run] = inner_acc\n",
    "            outer_acc_report.at[subject, run] = outer_acc\n",
    "            \n",
    "        clear_output()\n",
    "        \n",
    "        # Prints how long it took for last outer subject test\n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print(f\"Last turn took {minutes} minutes and {seconds} seconds.\")\n",
    "        \n",
    "    return inner_acc_report, outer_acc_report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last turn took 5.0 minutes and 22.441059827804565 seconds.\n"
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 3, 'num': 19, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 15, 'num': 19, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "data_params = {'path': path, 'roi': roi, 'conds': conds}\n",
    "grid_params = {'gamma': gamma_range, 'C': C_range, 'kernels': kernels}\n",
    "\n",
    "inner_acc_report, outer_acc_report = train_within_subjects(data_params, grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
