{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Training Functions\n",
    "\n",
    "<a href=\"https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\">Guide to SVM Training</a>\n",
    "### To-do:\n",
    "<ul>\n",
    "    <li> Refine grid search, try to increase accuracy of outer loop subjects </li>\n",
    "    <li> Permutation tests with scrambled label data </li>\n",
    "    <li> Make data generation process more efficient/less redundant </li>\n",
    "    <li> Shorten/simplify parameter list </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(path):\n",
    "    \n",
    "    '''\n",
    "    Gets a list of subject IDs and the file suffix, given a path to the data files. \n",
    "    \n",
    "    Note: subject ID must be only 2 characters for this to work, and all data files\n",
    "    must have same suffix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to the data files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        a list of subject IDs\n",
    "    str\n",
    "        the suffix to the filenames\n",
    "    '''\n",
    "    \n",
    "    files = os.listdir(path)\n",
    "    subjects = [f[:2] for f in files]\n",
    "    suffix = files[0][2:]\n",
    "        \n",
    "    subjects.sort()\n",
    "    \n",
    "    return subjects, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble_labels(y_data, classes):\n",
    "    \n",
    "    '''\n",
    "    Randomly selects half of the labels in the data to switch to the other class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data: array-like\n",
    "        label data to scramble\n",
    "    classes: list\n",
    "        the two different classes of labels\n",
    "    '''\n",
    "    \n",
    "    y_data_copy = y_data.copy()\n",
    "    for index in np.nditer(np.random.choice(len(y_data), size=len(y_data)//2, replace=False)):\n",
    "        \n",
    "        if y_data[index] == classes[0]:\n",
    "            y_data[index] = classes[1]\n",
    "        else:\n",
    "            y_data[index] = classes[0]\n",
    "    \n",
    "    # Makes sure labels are scrambled properly\n",
    "    num_diff = sum(i != j for i, j in zip(y_data, y_data_copy))  \n",
    "    if num_diff != len(y_data)//2:\n",
    "        raise ValueError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Extracts individual subject data from the .mat files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        directory to data files\n",
    "    subject: str\n",
    "        ID of subject to load data for\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)\n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of voxel data (x_data) separated by individual blocks and the corresponding labels (y_data)\n",
    "    '''\n",
    "    \n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    \n",
    "    path_to_file = path + subject + suffix\n",
    "    mat = scipy.io.loadmat(path_to_file)['roi_scanData'][0][roi]\n",
    "    \n",
    "    ranked_indices = None\n",
    "    \n",
    "    for scan in range(len(mat[0])):\n",
    "            \n",
    "        for cond in conds:\n",
    "            \n",
    "            for block in reversed(range(len(mat[0][scan][0][cond][0]))):\n",
    "\n",
    "                block_data = []\n",
    "                for tr in range(len(mat[0][scan][0][cond][0][block][0])):\n",
    "                    \n",
    "                    # Extract all voxel data from individual TRs\n",
    "                    block_data.extend(mat[0][scan][0][cond][0][block][0][tr][0][0][0].tolist())\n",
    "                    \n",
    "                if rank_first:\n",
    "                    if ranked_indices is None:\n",
    "                        ranked_indices = [i for i in (-np.array(block_data)).argsort()[:block_length]]\n",
    "                    block_data = [block_data[i] if i < len(block_data) else 0 for i in ranked_indices]\n",
    "                elif shuffle:\n",
    "                    random.shuffle(block_data)\n",
    "                else:\n",
    "                    # Filters for most active voxels in each block\n",
    "                    block_data.sort()\n",
    "                    block_data = block_data[-block_length:]\n",
    "                \n",
    "                x_data.append(block_data)\n",
    "                y_data.append(mat[0][scan][1][cond][0])\n",
    "    \n",
    "    data = {'x': x_data, 'y': y_data}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generates training and testing data.\n",
    "'''\n",
    "def generate_data(subjects, inner_test_subjects, outer_test_subject, path, suffix, roi, conds, block_length, rank_first, shuffle):\n",
    "    \n",
    "    '''\n",
    "    Generates training and testing data, which is separated into training data, inside testing data,\n",
    "    and outside testind data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subjects: list\n",
    "        a list of subject IDs to extract data from\n",
    "    inner_test_subject: list\n",
    "        list of indices of the inner test subjects\n",
    "    outer_test_subject: int\n",
    "        the index of the outer test subject\n",
    "    path: str\n",
    "        the path to the data files\n",
    "    suffix: str\n",
    "        ending suffix of the data filename\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        blocks of voxel data for training use\n",
    "    list\n",
    "        training labels\n",
    "    list\n",
    "        inner test subject blocks of voxel data for testing use\n",
    "    list \n",
    "        testing labels for inner test subject\n",
    "    list\n",
    "        outer test subject blocks of voxel data for testing use\n",
    "    list\n",
    "        testing labels for outer test subject\n",
    "    '''\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    x_test_inner = []\n",
    "    y_test_inner = []\n",
    "    \n",
    "    x_test_outer = []\n",
    "    y_test_outer = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "        \n",
    "        subject_data = extract_subject_data(path, subject, suffix, roi, conds, block_length, rank_first, shuffle)\n",
    "        if subject == outer_test_subject:\n",
    "            x_test_outer.extend(subject_data['x'])\n",
    "            y_test_outer.extend(subject_data['y'])\n",
    "        elif subject in inner_test_subjects:\n",
    "            x_test_inner.extend(subject_data['x'])\n",
    "            y_test_inner.extend(subject_data['y'])\n",
    "        else:\n",
    "            x_train.extend(subject_data['x'])\n",
    "            y_train.extend(subject_data['y'])\n",
    "    \n",
    "    x_train_len = len(x_train)\n",
    "    x_test_outer_len = len(x_test_outer)\n",
    "    \n",
    "    data.extend(x_train)\n",
    "    data.extend(x_test_outer)\n",
    "    data.extend(x_test_inner)\n",
    "    \n",
    "    # MinMaxScaler scales each feature to values between 0 and 1 among all x data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_normalized = scaler.fit_transform(data)\n",
    "    x_train, x_test_outer, x_test_inner = x_normalized[:x_train_len], x_normalized[x_train_len:x_train_len+x_test_outer_len], x_normalized[x_train_len+x_test_outer_len:]\n",
    "\n",
    "    y_train = np.stack(y_train, axis=0)\n",
    "    \n",
    "    return x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_run(x_train, y_train, x_test, y_test, kernels, gamma_range, C_range):\n",
    "    \n",
    "    '''\n",
    "    Gets best hyperparameters (kernel, C, and gamma values) that optimize SVM's predictions for given\n",
    "    x and y test dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train: array-like\n",
    "        dataset of block data used to train classifier\n",
    "    y_train: array-like\n",
    "        dataset of label data used to train classifier\n",
    "    x_test: array-like\n",
    "        testing dataset of block data used to optimize hyperparameters on\n",
    "    y_test: array-like\n",
    "        testing dataset of label data used to optimize hyperparameters on\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        best combination of parameters found from grid search\n",
    "    float\n",
    "        best accuracy obtained from testing\n",
    "    '''\n",
    "    \n",
    "    gamma_vals = np.logspace(gamma_range['start'], gamma_range['stop'], gamma_range['num'], base=gamma_range['base'])\n",
    "    C_vals = np.logspace(C_range['start'], C_range['stop'], C_range['num'], base=C_range['base'])\n",
    "\n",
    "    param_grid = ParameterGrid({'kernel': kernels, 'gamma': gamma_vals, 'C': C_vals})\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_params = None\n",
    "    \n",
    "    # Tests each parameter combination to find best one for given testing data\n",
    "    for params in list(param_grid):\n",
    "        \n",
    "        svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "        svclassifier.fit(x_train, y_train)\n",
    "        \n",
    "        curr_acc = svclassifier.score(x_test, y_test)\n",
    "        \n",
    "        if curr_acc > best_acc:\n",
    "            best_acc = curr_acc\n",
    "            best_params = params\n",
    "            \n",
    "    return best_params, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=1, scramble=False, classes=None, rank_first=True, shuffle=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        the path to the data files\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    num_inner: int\n",
    "        number of inner subjects to test classifier on, default is 1\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, default is False\n",
    "    classes: list, optional if scramble is False but required if scramble is True\n",
    "        label classes for the data (should be length of 2)\n",
    "    rank_first: boolean, optional\n",
    "        whether to base ordering of block data based on first block for each subject, \n",
    "        default is True\n",
    "    shuffle: boolean, optional\n",
    "        whether to shuffle the subject data blocks, default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject combination testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(path)\n",
    "    \n",
    "    cols = []\n",
    "    for combo in itertools.combinations(range(len(subjects)), num_inner):\n",
    "        col = ''\n",
    "        for subject in combo:\n",
    "            col += '/' + subjects[subject]\n",
    "        cols.append(col[1:])\n",
    "\n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=cols)\n",
    "    \n",
    "    for outer_subject in subjects:\n",
    "        \n",
    "        print(\"Currently on outer subject #%i.\" % (subjects.index(outer_subject)+1))\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        inner_subjects = [s for s in subjects if s != outer_subject]\n",
    "        for inner_subject_test in itertools.combinations((inner_subjects), num_inner):\n",
    "            \n",
    "            inner_subject_test = list(inner_subject_test)\n",
    "\n",
    "            col = ''\n",
    "            for subject in inner_subject_test:\n",
    "                col += '/' + subject\n",
    "            col = col[1:]\n",
    "            # print(\"Currently on combination of %s.\" % (col))    \n",
    "            \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = generate_data(subjects, inner_subject_test, outer_subject, path, suffix, roi, conds, block_length, rank_first, shuffle)\n",
    "            \n",
    "            if scramble:\n",
    "                scramble_labels(y_train, classes)\n",
    "                \n",
    "            # gets optimal params for training dataset from grid search\n",
    "            params, inner_acc = get_optimal_run(x_train, y_train, x_test_inner, y_test_inner, kernels, gamma_range, C_range) \n",
    "\n",
    "            # train model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_train, y_train)\n",
    "            \n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # logs inner and outer subject accuracy data in dataframe\n",
    "            inner_acc_report.at[outer_subject, col] = inner_acc\n",
    "            outer_acc_report.at[outer_subject, col] = outer_acc\n",
    "\n",
    "        # clear_output()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print('Last turn took %i minutes and %f seconds.' % (minutes, seconds))\n",
    "    \n",
    "    clear_output()\n",
    "    return inner_acc_report, outer_acc_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier/Visualizing Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 16, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 16, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=1, rank_first=True)\n",
    "\n",
    "inner_accs.to_csv('output/rank/inner_accs16_rank.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs16_rank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=2, rank_first=True)\n",
    "\n",
    "inner_accs.to_csv('output/rank/inner_accs32_2inner.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs32_2inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=3, rank_first=True)\n",
    "\n",
    "inner_accs.to_csv('output/rank/inner_accs32_3inner.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs32_3inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=4, rank_first=True)\n",
    "\n",
    "inner_accs.to_csv('output/rank/inner_accs32_4inner.csv')\n",
    "outer_accs.to_csv('output/rank/outer_accs32_4inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 64, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 64, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs64.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs64.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -15, 'stop': 5, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -5, 'stop': 15, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs32_more.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs32_more.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on outer subject #1.\n",
      "Last turn took 1 minutes and 34.397790 seconds.\n",
      "Currently on outer subject #2.\n",
      "Last turn took 1 minutes and 36.878580 seconds.\n",
      "Currently on outer subject #3.\n",
      "Last turn took 1 minutes and 41.925524 seconds.\n",
      "Currently on outer subject #4.\n",
      "Last turn took 1 minutes and 40.051555 seconds.\n",
      "Currently on outer subject #5.\n",
      "Last turn took 1 minutes and 32.375977 seconds.\n",
      "Currently on outer subject #6.\n",
      "Last turn took 1 minutes and 34.229352 seconds.\n",
      "Currently on outer subject #7.\n",
      "Last turn took 1 minutes and 33.147193 seconds.\n",
      "Currently on outer subject #8.\n",
      "Last turn took 1 minutes and 34.036563 seconds.\n",
      "Currently on outer subject #9.\n",
      "Last turn took 1 minutes and 47.338727 seconds.\n",
      "Currently on outer subject #10.\n",
      "Last turn took 1 minutes and 44.918129 seconds.\n",
      "Currently on outer subject #11.\n",
      "Last turn took 1 minutes and 38.649312 seconds.\n",
      "Currently on outer subject #12.\n"
     ]
    }
   ],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 16, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 16, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range)\n",
    "\n",
    "inner_accs.to_csv('output/inner_accs16_reverserank.csv', sep='\\t')\n",
    "outer_accs.to_csv('output/outer_accs16_reverserank.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation(path, roi, conds, block_length, kernels, gamma_range, C_range, inner_dist, outer_dist, runs, classes=None):\n",
    "    \n",
    "    for n in range(runs):\n",
    "        print(f'On run #{n+1}.')\n",
    "        inner_accs, outer_accs = train(path, roi, conds, block_length, kernels, gamma_range, C_range, num_inner=1, scramble=True, classes=classes, rank_first=True)\n",
    "        \n",
    "        vals = []\n",
    "        for column in inner_accs:\n",
    "            vals.extend(inner_accs[column].tolist())\n",
    "        vals = [x for x in vals if str(x) != 'nan']\n",
    "        inner_dist.extend(vals)\n",
    "        \n",
    "        vals = []\n",
    "        for column in outer_accs:\n",
    "            vals.extend(outer_accs[column].tolist())\n",
    "        vals = [x for x in vals if str(x) != 'nan']\n",
    "        outer_dist.extend(vals)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "classes = ['trained_ip', 'untrained_ip']\n",
    "\n",
    "inner_dist = []\n",
    "outer_dist = []\n",
    "\n",
    "permutation(path, roi, conds, block_length, kernels, gamma_range, C_range, inner_dist, outer_dist, 4, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['trained_ip', 'untrained_ip']\n",
    "permutation(path, roi, conds, block_length, kernels, gamma_range, C_range, inner_dist, outer_dist, 4, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   8.,   0.,  14.,   0.,  53.,  31.,  77.,  43.,   0., 180.,\n",
       "         43.,  85.,  27.,  36.,   3.,  19.,   0.,   1.,   3.]),\n",
       " array([0.125 , 0.1625, 0.2   , 0.2375, 0.275 , 0.3125, 0.35  , 0.3875,\n",
       "        0.425 , 0.4625, 0.5   , 0.5375, 0.575 , 0.6125, 0.65  , 0.6875,\n",
       "        0.725 , 0.7625, 0.8   , 0.8375, 0.875 ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(outer_dist, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49565972222222215"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(outer_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outer_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('output/permutations/outer_dist32.npy', outer_dist)\n",
    "np.save('output/permutations/inner_dist32.npy', inner_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_with_all(path, roi, conds, block_length, kernels, gamma_range, C_range, scramble=False):\n",
    "    \n",
    "    '''\n",
    "    Trains and tests the classifier for accuracy using entire dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        the path to the data files\n",
    "    roi: int\n",
    "        0 for V1 data, 1 for MT data\n",
    "    conds: list\n",
    "        list of integers specifying the conditional datasets to extract\n",
    "        (0 for trained_cp, 1 for trained_ip, 2 for untrained_cp, 3 for untrained_ip)    \n",
    "    block_length: int\n",
    "        the number of voxels to standardize every block in the dataset to\n",
    "    kernels: list\n",
    "        kernels to test (recommended options are 'linear', 'rbf', and 'sigmoid')\n",
    "    gamma_range: dict\n",
    "        dict that specifies the range of values of gamma to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    C_range: dict\n",
    "        dict that specifies the range of values of C to test; should include start, stop to range,\n",
    "        num of values, and the exponential base\n",
    "    scramble: boolean, optional\n",
    "        whether or not to scramble the labels when training, default is False\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        data of inner subject testing accuracy\n",
    "    DataFrame\n",
    "        data of outer subject testing accuracy\n",
    "    '''\n",
    "    \n",
    "    subjects, suffix = get_subjects(path)\n",
    "    \n",
    "    inner_acc_report = pd.DataFrame(index=subjects, columns=subjects)\n",
    "    outer_acc_report = pd.DataFrame(index=subjects, columns=subjects)\n",
    "    \n",
    "    for outer_subject in range(len(subjects)):\n",
    "        \n",
    "        print(\"Currently on outer subject #%i.\" % (outer_subject+1))\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for inner_subject in range(len(subjects)):\n",
    "\n",
    "            if inner_subject == outer_subject:\n",
    "                continue\n",
    "\n",
    "            print(\"Currently on inner subject #%i.\" % (inner_subject+1))    \n",
    "            x_train, y_train, x_test_inner, y_test_inner, x_test_outer, y_test_outer = generate_data(subjects, inner_subject, outer_subject, path, suffix, roi, conds, block_length)\n",
    "            \n",
    "            x_whole = np.vstack((x_train, x_test_inner, x_test_outer))\n",
    "            y_whole = np.concatenate((y_train, y_test_inner, y_test_outer))\n",
    "            \n",
    "            if scramble:\n",
    "                scramble_labels(y_train, classes)\n",
    "                \n",
    "            # gets optimal params for training dataset from grid search\n",
    "            params, inner_acc = get_optimal_run(x_whole, y_whole, x_test_inner, y_test_inner, kernels, gamma_range, C_range) \n",
    "            print('Found best params for current inner subject.')\n",
    "            \n",
    "            # train model using optimal params for this set\n",
    "            svclassifier = SVC(kernel=params['kernel'], gamma=params['gamma'], C=params['C'], max_iter=-1)\n",
    "            svclassifier.fit(x_whole, y_whole)\n",
    "            \n",
    "            print('Testing outer subject...')\n",
    "            outer_acc = svclassifier.score(x_test_outer, y_test_outer)\n",
    "            \n",
    "            # logs inner and outer subject accuracy data in dataframe\n",
    "            index = subjects[outer_subject]\n",
    "            col = subjects[inner_subject]\n",
    "            \n",
    "            inner_acc_report.at[index, col] = inner_acc\n",
    "            outer_acc_report.at[index, col] = outer_acc\n",
    "\n",
    "        clear_output()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        exec_time = end_time - start_time\n",
    "        minutes = exec_time // 60\n",
    "        seconds = exec_time % 60\n",
    "        print('Last turn took %i minutes and %f seconds.' % (minutes, seconds))\n",
    "    \n",
    "    clear_output()\n",
    "    return inner_acc_report, outer_acc_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'scans/output/PRE/'\n",
    "roi = 1                            # V1-roi: 0, MT-roi: 1\n",
    "conds = [1, 3]                     # trained_cp: 0, trained_ip: 1, untrained_cp: 2, untrained_ip: 3\n",
    "block_length = 624\n",
    "\n",
    "gamma_range = {'start': -13, 'stop': 1, 'num': 32, 'base': 2.0}\n",
    "C_range = {'start': -3, 'stop': 11, 'num': 32, 'base': 2.0}\n",
    "kernels = ['rbf', 'sigmoid']\n",
    "\n",
    "inner_accs, outer_accs = train_with_all(path, roi, conds, block_length, kernels, gamma_range, C_range)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
